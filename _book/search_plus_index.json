{"./":{"url":"./","title":"Introduction","keywords":"","body":"Introduction "},"docs/ELK/es/es好的博客.html":{"url":"docs/ELK/es/es好的博客.html","title":"Es好的博客","keywords":"","body":"https://blog.csdn.net/zwgdft "},"docs/ELK/es/es概念理解.html":{"url":"docs/ELK/es/es概念理解.html","title":"Es概念理解","keywords":"","body":"es结构和关系型数据库对比 Relational DB -> Databases -> Tables -> Rows -> Columns Elasticsearch -> Indices -> Types -> Documents -> Fields "},"docs/ELK/es/es节点类型.html":{"url":"docs/ELK/es/es节点类型.html","title":"Es节点类型","keywords":"","body":"节点类型 候选主节点（Master-eligible node）    一个节点启动后，就会使用Zen Discovery机制去寻找集群中的其他节点，并与之建立连接。集群中会从候选主节点中选举出一个主节点，主节点负责创建索引、删除索引、分配分片、追踪集群中的节点状态等工作。Elasticsearch中的主节点的工作量相对较轻，用户的请求可以发往任何一个节点，由该节点负责分发和返回结果，而不需要经过主节点转发。   正常情况下，集群中的所有节点，应该对主节点的选择是一致的，即一个集群中只有一个选举出来的主节点。然而，在某些情况下，比如网络通信出现问题、主节点因为负载过大停止响应等等，就会导致重新选举主节点，此时可能会出现集群中有多个主节点的现象，即节点对集群状态的认知不一致，称之为脑裂现象。为了尽量避免此种情况的出现，可以通过discovery.zen.minimum_master_nodes来设置最少可工作的候选主节点个数，建议设置为(候选主节点数 / 2) + 1, 比如，当有三个候选主节点时，该配置项的值为(3/2)+1=2，也就是保证集群中有半数以上的候选主节点。     候选主节点的设置方法是设置node.mater为true，默认情况下，node.mater和node.data的值都为true，即该节点既可以做候选主节点也可以做数据节点。由于数据节点承载了数据的操作，负载通常都很高，所以随着集群的扩大，建议将二者分离，设置专用的候选主节点。当我们设置node.data为false，就将节点设置为专用的候选主节点了。 node.master = true node.data = false 数据节点（Data node）   数据节点负责数据的存储和相关具体操作，比如CRUD、搜索、聚合。所以，数据节点对机器配置要求比较高，首先需要有足够的磁盘空间来存储数据，其次数据操作对系统CPU、Memory和IO的性能消耗都很大。通常随着集群的扩大，需要增加更多的数据节点来提高可用性。   前面提到默认情况下节点既可以做候选主节点也可以做数据节点，但是数据节点的负载较重，所以需要考虑将二者分离开，设置专用的数据节点，避免因数据节点负载重导致主节点不响应。 node.master = false node.data = true 客户端节点（Client node）   按照官方的介绍，客户端节点就是既不做候选主节点也不做数据节点的节点，只负责请求的分发、汇总等等，也就是下面要说到的协调节点的角色。这样的工作，其实任何一个节点都可以完成，单独增加这样的节点更多是为了负载均衡。 node.master = false node.data = false 协调节点（Coordinating node）   协调节点，是一种角色，而不是真实的Elasticsearch的节点，你没有办法通过配置项来配置哪个节点为协调节点。集群中的任何节点，都可以充当协调节点的角色。当一个节点A收到用户的查询请求后，会把查询子句分发到其它的节点，然后合并各个节点返回的查询结果，最后返回一个完整的数据集给用户。在这个过程中，节点A扮演的就是协调节点的角色。毫无疑问，协调节点会对CPU、Memory要求比较高。 分片与集群状态   分片（Shard），是Elasticsearch中的最小存储单元。一个索引（Index）中的数据通常会分散存储在多个分片中，而这些分片可能在同一台机器，也可能分散在多台机器中。这样做的优势是有利于水平扩展，解决单台机器磁盘空间和性能有限的问题，试想一下如果有几十TB的数据都存储同一台机器，那么存储空间和访问时的性能消耗都是问题。   默认情况下，Elasticsearch会为每个索引分配5个分片，但是这并不代表你必须使用5个分片，同时也不说分片越多性能就越好。一切都取决对你的数据量的评估和权衡。虽然跨分片查询是并行的，但是请求分发、结果合并都是需要消耗性能和时间的，所以在数据量较小的情况下，将数据分散到多个分片中反而会降低效率。如果说一定要给一个数据的话，笔者现在的每个分片数据量大概在20GB左右。   关于多分片与多索引的问题。一个索引可以有多个分片来完成存储，但是主分片的数量是在索引创建时就指定好的，且无法修改，所以尽量不要只为数据存储建立一个索引，否则后面数据膨胀时就无法调整了。笔者的建议是对于同一类型的数据，根据时间来分拆索引，比如一周建一个索引，具体取决于数据增长速度。   上面说的是主分片（Primary Shard），为了提高服务可靠性和容灾能力，通常还会分配复制分片（Replica Shard）来增加数据冗余性。比如设置复制分片的数量为1时，就会对每个主分片做一个备份。   通过API（ http://localhost:9200/_cluster/health?pretty ）可以查看集群的状态，通常集群的状态分为三种： Red，表示有主分片没有分配，某些数据不可用。 Yellow，表示主分片都已分配，数据都可用，但是有复制分片没有分配。 Green，表示主分片和复制分片都已分配，一切正常。 部署拓扑   最后，来看两个集群部署的拓扑图，这里我们不考虑单个节点的调优。拓扑图一是一个简单的集群部署，适用于数据量较小的场景。集群中有三个节点，三个都是候选主节点，因此我们可以设置最少可工作候选主节点个数为2。节点1和2同时作为数据节点，两个节点的数据相互备份。这样的部署结构在扩展过程中，通常是先根据需要逐步加入专用的数据节点，最后考虑将数据节点和候选主节点分离，也就发展为了拓扑图二的结构。在拓扑图二中，有三个专用的候选主节点，用来做集群状态维护，数据节点根据需要进行增加，注意只增加专用的数据节点即可。 拓扑图一 拓扑图二 "},"docs/OpsManager/相关资料地址.html":{"url":"docs/OpsManager/相关资料地址.html","title":"相关资料地址","keywords":"","body":"自动化运维管理平台OpsManage 说明： https://github.com/welliamcao/OpsManage/blob/master/README.md 源码：https://github.com/welliamcao/OpsManage docker构建 https://github.com/welliamcao/OpsManage/wiki/Docker%E6%9E%84%E5%BB%BAOpsManage 安装文档 https://blog.csdn.net/miss1181248983/article/details/85157712 "},"docs/PHP/lnmp离线安装.html":{"url":"docs/PHP/lnmp离线安装.html","title":"Lnmp离线安装","keywords":"","body":"lnmp离线安装 项目地址：https://gitee.com/SimplerWorker/ollnmp git 克隆： git clone https://gitee.com/SimplerWorker/ollnmp.git 前言：有时候，项目需要完全离线安装PHP环境，环境安装的时候，各种依赖让我痛苦不已，经过多次试验，终究练就此如来神掌，开源给大家。 环境： centos7.x+nginx1.15+mysql5.7.23+php7.2+redis4.0.0+python3+thinkphp5 and so on 第一步：准备一个centos7.x系统（这里以centos7.2为例） 第二步：挂载一个跟系统同一版本的镜像（everything版本的，yum源会更全） 上传一个centos7.2 everything版本的iso到已经安装好的centos7.2的 /opt 目录下 创建挂载目录： mkdir /media/CentOS7 挂载ISO： mount -t iso9660 -o loop /opt/CentOS-7-x86_64-DVD-1511_7.2.iso /media/CentOS7/ 设置开机自动挂载镜像： echo mount -t iso9660 -o loop /opt/CentOS-7-x86_64-DVD-1511_7.2.iso /media/CentOS7/ >> /etc/rc.local 配置源： mkdir /etc/yum.repos.d/bk mv /etc/yum.repos.d/* /etc/yum.repos.d/bk vi /etc/yum.repos.d/local.repo 添加如下内容[c7-media] name=CentOS-$releasever - Media baseurl=file:///media/CentOS7 gpgcheck=0 enabled=1 保存后退出 生成本地缓存 yum clean all （清除缓存） yum makecache （建立新缓存） 测试是否生效： yum install telnet 将项目下载后，上传到系统里面，例如/root/下 解压ollnmp后，进入ollnmp，执行 ./install lnmp 安装过程中，会要求填写相关信息，如实填写或者全部使用默认即可，遇到卡顿的地方，手动回车下 1、下载CentOS光盘镜像 cd /root && wget http://mirrors.163.com/centos/7/isos/x86_64/CentOS-7-x86_64-Everything-1810.iso 2、挂载光盘镜像 mkdir /mnt/dvd mount -o loop /root/CentOS-7-x86_64-Everything-1810.iso /mnt/dvd 这样就将光盘挂载 /mnt/dvd 目录了。 当然这个挂载命令只是一次性的，系统重启或者自己umount后就没了，需要使用本地源yum安装时需要线执行这个挂载命令。 PS：如果像有多张ISO光盘的CentOS 6之类的版本，可以 mkdir /mnt/dvd2，再参考前面的命令将第二张挂载到 /mnt/dvd2 上。 3、备份yum源配置文件 将/etc/yum.repos.d/ 所有的以.repo结尾的文件全部重命名为：xxxx.repo.backup 4、配置新yum本地源 使用winscp、nano、vim之类的软件编辑 /etc/yum.repos.d/CentOS-Media.repo 添加如下内容： [local-media] name=CentOS-$releasever - Media baseurl=file:///mnt/dvd/ file:///mnt/dvd2/ 如果有第二张光盘将前面dvd2行前面的 # 注释符号去掉 gpgcheck=1 enabled=1 gpgkey=file:///mnt/dvd/RPM-GPG-KEY-CentOS-7 保存 gpgcheck 签名检查可以改成 0 就会不检查。 gpgkey 最后面如果是CentOS-6就把最后面数字改成6 CentOS 8本地源配置文件写法与CentOS6和7不同，配置文件内容如下： [LocalRepo_BaseOS] name=LocalRepository_BaseOS baseurl=file:///mnt/dvd/BaseOS enabled=1 gpgcheck=0 [LocalRepo_AppStream] name=LocalRepository_AppStream baseurl=file:///mnt/dvd/AppStream enabled=1 gpgcheck=0 保存 5、测试yum本地源是否正常工作 执行以下命令，清空以下缓存并创建新的缓存 yum clean all yum makecache 然后 yum install wget 试一下能否正常安装依赖包。 没有报错的话就是正常工作了，当然wget也可能已经安装了，也可以换其他软件包尝试。 如果是要离线安装lnmp一键安装包，需要添加 CheckMirror=n 参数实现，例子 CheckMirror=n ./install.sh lnmp。 "},"docs/docker/docker安装mysql.html":{"url":"docs/docker/docker安装mysql.html","title":"Docker安装Mysql","keywords":"","body":"docker安装mysql 拉取镜像 `docker pull mysql:5.7 运行 $ mkdir /usr/local/mysql $ cd /usr/local/mysql $ docker run -p 3306:3306 --name mysql57 --restart=always -v $PWD/conf:/etc/mysql/conf.d -v $PWD/logs:/logs -v $PWD/data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.7 -p 3306:3306：将容器的 3306 端口映射到主机的 3306 端口。 -v -v $PWD/conf:/etc/mysql/conf.d：将主机当前目录下的 conf/my.cnf 挂载到容器的 /etc/mysql/my.cnf。 -v $PWD/logs:/logs：将主机当前目录下的 logs 目录挂载到容器的 /logs。 -v $PWD/data:/var/lib/mysql ：将主机当前目录下的data目录挂载到容器的 /var/lib/mysql 。 -e MYSQL_ROOT_PASSWORD=123456：初始化 root 用户的密码。 --restart=always 随docker启动一块启动 trouble 连接不上 $docker exec -it 62349aa31687 /bin/bash mysql -uroot -p #授权 mysql> GRANT ALL ON *.* TO 'root'@'%'; #刷新权限 mysql> flush privileges; #更新加密规则： mysql> ALTER USER 'root'@'localhost' IDENTIFIED BY 'password' PASSWORD EXPIRE NEVER; #更新root用户 mysql> ALTER USER 'root'@'%' IDENTIFIED WITH mysql_native_password BY '123456'; #刷新权限 mysql> flush privileges; "},"docs/docker/docker安装zabbix.html":{"url":"docs/docker/docker安装zabbix.html","title":"Docker安装Zabbix","keywords":"","body":"docker pull zabbix/zabbix-server-mysql:centos-4.4-latest 第二步： docker run --name some-zabbix-server-mysql -e DB_SERVER_HOST=\"172.17.0.2\" -e MYSQL_USER=\"root\" -e MYSQL_PASSWORD=\"123456\" -d zabbix/zabbix-server-mysql:centos-4.4-latest 第三步： docker run --name some-zabbix-web-nginx-mysql -p 80:8080 --link some-zabbix-server-mysql:zabbix-server -e DB_SERVER_HOST=\"172.17.0.2\" -e MYSQL_USER=\"root\" -e MYSQL_PASSWORD=\"123456\" -e ZBX_SERVER_HOST=\"172.17.0.3\" -e PHP_TZ=\"Asia/Shanghai\" -d zabbix/zabbix-web-nginx-mysql:centos-4.4-latest "},"docs/docker/docker打包镜像.html":{"url":"docs/docker/docker打包镜像.html","title":"Docker打包镜像","keywords":"","body":"打包tar文件 命令 #打包镜像 docker save -o xxx.tar 镜像名 #加载镜像 docker load -i xxx.tar 删除镜像 docker rmi [image] #或 docker image rm [image] "},"docs/docker/docker离线安装.html":{"url":"docs/docker/docker离线安装.html","title":"Docker离线安装","keywords":"","body":"关闭SELinux： 1、临时关闭（不用重启机器）： setenforce 0 ##设置SELinux 成为permissive模式 ##setenforce 1 设置SELinux 成为enforcing模 2、修改配置文件需要重启机器： 修改/etc/selinux/config 文件 将SELINUX=enforcing改为SELINUX=disabled 重启机器即可 1、docker下载地址 https://download.docker.com/linux/static/stable/x86_64/docker-18.06.3-ce.tgz 2、解压 tar -xvf docker-xxxx.taz 3、将解压出来的docker文件内容移动到 /usr/bin/ 目录下 cp docker/* /usr/bin/ 4、将docker注册为service vim /etc/systemd/system/docker.service 将下列配置加到docker.service中并保存 [Unit] Description=Docker Application Container Engine Documentation=https://docs.docker.com After=network-online.target firewalld.service Wants=network-online.target [Service] Type=notify # the default is not to use systemd for cgroups because the delegate issues still # exists and systemd currently does not support the cgroup feature set required # for containers run by docker ExecStart=/usr/bin/dockerd ExecReload=/bin/kill -s HUP $MAINPID # Having non-zero Limit*s causes performance problems due to accounting overhead # in the kernel. We recommend using cgroups to do container-local accounting. LimitNOFILE=infinity LimitNPROC=infinity LimitCORE=infinity # Uncomment TasksMax if your systemd version supports it. # Only systemd 226 and above support this version. #TasksMax=infinity TimeoutStartSec=0 # set delegate yes so that systemd does not reset the cgroups of docker containers Delegate=yes # kill only the docker process, not all processes in the cgroup KillMode=process # restart the docker process if it exits prematurely Restart=on-failure StartLimitBurst=3 StartLimitInterval=60s [Install] WantedBy=multi-user.target 4、启动 chmod +x /etc/systemd/system/docker.service #添加文件权限并启动docker systemctl daemon-reload #重载unit配置文件 systemctl start docker #启动Docker systemctl enable docker.service #设置开机自启 5、验证 systemctl status docker #查看Docker状态 docker -v #查看Docker版本 "},"docs/docker/docker防火墙问题.html":{"url":"docs/docker/docker防火墙问题.html","title":"Docker防火墙问题","keywords":"","body":"https://blog.csdn.net/cfm_gavin/article/details/88543438 防火墙原因 CentOS7有很多CentOS 6中的常用服务发生了变化。首当其冲 防火墙iptables被firewalld取代。这里有个最大的问题是，firewalld 放行端口后 服务任然不能外网访问，因为要添加端口对应的服务到firewalld中，那么docker容器中的各个映射访问的端口就没法玩，docker容器映射出的端口 服务如何添加？非docker安装，如ftp,那么放行ftp端口后还须： firewall-cmd --add-service=ftp // 即时放行了对应端口，无此步任无法访问，除非禁用 firewall 重新载入 firewall-cmd --reload // 方可生效，ftp 客户端才能使用 由此 采用systemctl关闭firewalld，开启iptables。 1.关闭firewalld [root@~]# systemctl stop firewalld [root@~]# systemctl disable firewalld [root@~]# systemctl status firewalld firewalld.service - firewalld - dynamic firewall daemon Loaded: loaded (/usr/lib/systemd/system/firewalld.service; disabled) Active: inactive (dead) .... 2.开启iptables 首先安装iptables： [root@~]#yum install -y iptables-services [root@~]# systemctl enable iptables ln -s '/usr/lib/systemd/system/iptables.service' '/etc/systemd/system/basic.target.wants/iptables.service' [root@~]# systemctl start iptables [root@~]# systemctl status iptables iptables.service - IPv4 firewall with iptables Loaded: loaded (/usr/lib/systemd/system/iptables.service; enabled) Active: active (exited) since Fri 2016-02-26 13:54:45 UTC; 6s ago Process: 55539 ExecStart=/usr/libexec/iptables/iptables.init start (code=exited, status=0/SUCCESS) Main PID: 55539 (code=exited, status=0/SUCCESS) Feb 26 13:54:45 hwcentos70-01 iptables.init[55539]: iptables: Applying firewall rules: [ OK ] Feb 26 13:54:45 hwcentos70-01 systemd[1]: Started IPv4 firewall with iptables. 此时iptables的命令都可以使用了： [root@~]# iptables -L Chain INPUT (policy ACCEPT) target prot opt source destination Chain FORWARD (policy ACCEPT) target prot opt source destination Chain OUTPUT (policy ACCEPT) target prot opt source destination [root@~]# service iptables save iptables: Saving firewall rules to /etc/sysconfig/iptables:[ OK ] 其他参考 docker 端口映射 及外部无法访问问题 https://www.cnblogs.com/zl1991/p/10531726.html "},"docs/docker_book/Dockerfile.html":{"url":"docs/docker_book/Dockerfile.html","title":"Dockerfile","keywords":"","body":"Dockerfile详解 什么是dockerfile Dockerfile是包含了组合 image命令的文本文件，Docker通过读取Dockerfile生成image docker build 用于构建镜像 docker build -f /opt/dockerfile dockerfile结构 Dockerfile 一般分为四部分：基础镜像信息、维护者信息、镜像操作指令和容器启动时执行指令，’#’ 为 Dockerfile 中的注释。 dockerfile文件说明 Docker以从上到下的顺序运行Dockerfile的指令。为了指定基本映像，第一条指令必须是FROM。一个声明以＃字符开头则被视为注释。 docker build [OPTIONS] -f- PATH FROM ：指定基础镜像，必须为第一个命令 ，尽可能使用官方镜像作为基础镜像，推荐Alpine映像，因为它受到严格控制，大小很小(目前小于5mb)，同时仍然是一个完整的Linux发行版。如：jdk可以选 FROM openjdk:8-jdk-alpine 格式： 　　FROM 　　FROM : 　　FROM @ 示例： 　　FROM mysql:5.6 注： 　　tag或digest是可选的，如果不使用这两个值时，会使用latest版本的基础镜像 MAINTAINER : 维护者信息 格式： MAINTAINER 示例： MAINTAINER Jasper Xu MAINTAINER sorex@163.com MAINTAINER Jasper Xu RUN ：构建镜像时执行的命令 RUN用于在镜像容器中执行命令，其有以下两种命令执行方式： shell执行 格式： RUN exec执行 格式： RUN [\"executable\", \"param1\", \"param2\"] 示例： RUN [\"executable\", \"param1\", \"param2\"] RUN apk update RUN [\"/etc/execfile\", \"arg1\", \"arg1\"] 注：　　RUN指令创建的中间镜像会被缓存，并会在下次构建中使用。如果不想使用这些缓存镜像，可以在构建时指定--no-cache参数，如：docker build --no-cache ADD ：将本地文件添加到容器中，tar类型文件会自动解压(网络压缩资源不会被解压)，可以访问网络资源，类似wget 格式： ADD ... ADD [\"\",... \"\"] 用于支持包含空格的路径 示例： ADD hom* /mydir/ # 添加所有以\"hom\"开头的文件 ADD hom?.txt /mydir/ # ? 替代一个单字符,例如：\"home.txt\" ADD test relativeDir/ # 添加 \"test\" 到 `WORKDIR`/relativeDir/ ADD test /absoluteDir/ # 添加 \"test\" 到 /absoluteDir/ COPY ：功能类似ADD，但是是不会自动解压文件，也不能访问网络资源 CMD 构建容器后调用，也就是在容器启动时才进行调用 格式： CMD [\"executable\",\"param1\",\"param2\"] (执行可执行文件，使用exec执行，推荐方式) CMD [\"param1\",\"param2\"] (设置了ENTRYPOINT，则直接调用ENTRYPOINT添加参数：提供给ENTRYPOINT的默认参数) CMD command param1 param2 (执行shell内部命令，在/bin/sh 中执行) 示例： CMD echo \"This is a test.\" | wc - CMD [\"/usr/bin/wc\",\"--help\"]注： 　　CMD不同于RUN，CMD用于指定在容器启动时所要执行的命令，而RUN用于指定镜像构建时所要执行的命令。 ENTRYPOINT ：配置容器，使其可执行化。配合CMD可省去\"application\"，只使用参数。 格式： ENTRYPOINT [\"executable\", \"param1\", \"param2\"] (可执行文件, 优先) ENTRYPOINT command param1 param2 (shell内部命令) 示例： FROM ubuntu ENTRYPOINT [\"top\", \"-b\"] CMD [\"-c\"]注：　　　ENTRYPOINT与CMD非常类似，不同的是通过docker run执行的命令不会覆盖ENTRYPOINT，而docker run命令中指定的任何参数，都会被当做参数再次传递给ENTRYPOINT。Dockerfile中只允许有一个ENTRYPOINT命令，多指定时会覆盖前面的设置，而只执行最后的ENTRYPOINT指令。 LABEL 用于为镜像添加元数据 格式： LABEL = = = ... 示例： 　　LABEL version=\"1.0\" description=\"这是一个Web服务器\" by=\"IT笔录\" 注： 　　使用LABEL指定元数据时，一条LABEL指定可以指定一或多条元数据，指定多条元数据时不同元数据之间通过空格分隔。推荐将所有的元数据通过一条LABEL指令指定，以免生成过多的中间镜像。 ENV 设置环境变量 格式： ENV #之后的所有内容均会被视为其的组成部分，因此，一次只能设置一个变量 ENV = ... #可以设置多个变量，每个变量为一个\"=\"的键值对，如果中包含空格，可以使用\\来进行转义，也可以通过\"\"来进行标示；另外，反斜线也可以用于续行 示例： ENV myName John Doe ENV myDog Rex The Dog ENV myCat=fluffy EXPOSE 指定于外界交互的端口 格式： EXPOSE [...] 示例： EXPOSE 80 443 EXPOSE 8080 EXPOSE 11211/tcp 11211/udp注：　　EXPOSE并不会让容器的端口访问到主机。要使其可访问，需要在docker run运行容器时通过-p来发布这些端口，或通过-P参数来发布EXPOSE导出的所有端口 VOLUME 用于指定持久化目录 格式： VOLUME [\"/path/to/dir\"] 示例： VOLUME [\"/data\"] VOLUME [\"/var/www\", \"/var/log/apache2\", \"/etc/apache2\"注：　　一个卷可以存在于一个或多个容器的指定目录，该目录可以绕过联合文件系统，并具有以下功能： 1 卷可以容器间共享和重用 2 容器并不一定要和其它容器共享卷 3 修改卷后会立即生效 4 对卷的修改不会对镜像产生影响 5 卷会一直存在，直到没有任何容器在使用它 WORKDIR 工作目录，类似于cd命令 格式： WORKDIR /path/to/workdir 示例： WORKDIR /a (这时工作目录为/a) WORKDIR b (这时工作目录为/a/b) WORKDIR c (这时工作目录为/a/b/c)注：　　通过WORKDIR设置工作目录后，Dockerfile中其后的命令RUN、CMD、ENTRYPOINT、ADD、COPY等命令都会在该目录下执行。在使用docker run运行容器时，可以通过-w参数覆盖构建时所设置的工作目录。 USER 指定运行容器时的用户名或 UID，后续的 RUN 也会使用指定用户。使用USER指定用户时，可以使用用户名、UID或GID，或是两者的组合。当服务不需要管理员权限时，可以通过该命令指定运行用户。并且可以在之前创建所需要的用户 格式:　　 USER user　　 USER user:group　　 USER uid　　 USER uid:gid　　 USER user:gid　　 USER uid:group 示例： USER www 注： 　　使用USER指定用户后，Dockerfile中其后的命令RUN、CMD、ENTRYPOINT都将使用该用户。镜像构建完成后，通过docker run运行容器时，可以通过-u参数来覆盖所指定的用户。 ARG 用于指定传递给构建运行时的变量 格式： ARG [=] 示例： ARG site ARG build_user=www ONBUILD 用于设置镜像触发器 格式：　　ONBUILD [INSTRUCTION] 示例： 　　ONBUILD ADD . /app/src 　　ONBUILD RUN /usr/local/bin/python-build --dir /app/src 注：　　当所构建的镜像被用做其它镜像的基础镜像，该镜像中的触发器将会被钥触发 实例 # This my first nginx Dockerfile # Version 1.0 # Base images 基础镜像 FROM centos #MAINTAINER 维护者信息 MAINTAINER tianfeiyu #ENV 设置环境变量 ENV PATH /usr/local/nginx/sbin:$PATH #ADD 文件放在当前目录下，拷过去会自动解压 ADD nginx-1.8.0.tar.gz /usr/local/ ADD epel-release-latest-7.noarch.rpm /usr/local/ #RUN 执行以下命令 RUN rpm -ivh /usr/local/epel-release-latest-7.noarch.rpm RUN yum install -y wget lftp gcc gcc-c++ make openssl-devel pcre-devel pcre && yum clean all RUN useradd -s /sbin/nologin -M www #WORKDIR 相当于cd WORKDIR /usr/local/nginx-1.8.0 RUN ./configure --prefix=/usr/local/nginx --user=www --group=www --with-http_ssl_module --with-pcre && make && make install RUN echo \"daemon off;\" >> /etc/nginx.conf #EXPOSE 映射端口 EXPOSE 80 #CMD 运行以下命令 CMD [\"nginx\"] 个别概念的区别 RUN和CMD RUN命令是创建Docker镜像（image）的步骤，RUN命令对Docker容器（ container）造成的改变是会被反映到创建的Docker镜像上的。一个Dockerfile中可以有许多个RUN命令。 CMD CMD命令是当Docker镜像被启动后Docker容器将会默认执行的命令。一个Dockerfile中只能有一个CMD命令。通过执行docker run imageimageother_command启动镜像可以重载CMD命令。 CMD和ENTRYPOINT 共同点： 都可以指定shell或exec函数调用的方式执行命令； 当存在多个CMD指令或ENTRYPOINT指令时，只有最后一个生效； 差异1：CMD指令指定的容器启动时命令可以被docker run指定的命令覆盖，而ENTRYPOINT指令指定的命令不能被覆盖，而是将docker run指定的参数当做ENTRYPOINT指定命令的参数。 ​ 差异2：CMD指令可以为ENTRYPOINT指令设置默认参数，而且可以被docker run指定的参数覆盖； 参考：https://blog.csdn.net/wuce_bai/article/details/88997725 ADD和copy ADD和COPY： 共同点：1、把本地文件拷贝到镜像，那么文件必须在上下文中，没有就会找不到路径 ​ 2、只复制目录中的内容，不包括目录本身 区别： COPY: COPY 如果仅仅是把本地的文件拷贝到容器镜像中，COPY 命令是最合适不过的 还支持通配符： COPY check* /testdir/ # 拷贝所有 check 开头的文件 COPY check?.log /testdir/ # ? 是单个字符的占位符，比如匹配文件 check1.log 命令汇总： FROM: 指定基础镜像 RUN： 构建镜像过程中需要执行的命令。可以有多条。 CMD：添加启动容器时需要执行的命令。多条只有最后一条生效。可以在启动容器时被覆盖和修改。 ENTRYPOINT：同CMD，但这个一定会被执行，不会被覆盖修改。 LABEL ：为镜像添加对应的数据。 MLABELAINTAINER：表明镜像的作者。将被遗弃，被LABEL代替。 EXPOSE：设置对外暴露的端口。 ENV：设置执行命令时的环境变量，并且在构建完成后，仍然生效 ARG：设置只在构建过程中使用的环境变量，构建完成后，将消失 ADD：将本地文件或目录拷贝到镜像的文件系统中。能解压特定格式文件，能将URL作为要拷贝的文件 COPY：将本地文件或目录拷贝到镜像的文件系统中。 VOLUME：添加数据卷 USER：指定以哪个用户的名义执行RUN, CMD 和ENTRYPOINT等命令 WORKDIR：设置工作目录 ONBUILD：如果制作的镜像被另一个Dockerfile使用，将在那里被执行Docekrfile命令 STOPSIGNAL：设置容器退出时发出的关闭信号。 HEALTHCHECK：设置容器状态检查。 SHELL：更改执行shell命令的程序。Linux的默认shell是[“/bin/sh”, “-c”]，Windows的是[“cmd”, “/S”, “/C”] 参考： dockerfile常用命令 https://docs.docker.com/engine/reference/builder/ dockerfile最佳实践 https://docs.docker.com/develop/develop-images/dockerfile_best-practices/ "},"docs/docker_book/docker-compose字典.html":{"url":"docs/docker_book/docker-compose字典.html","title":"Docker Compose字典","keywords":"","body":"Docker-Compose命令格式 docker-compose [-f ...] [options] [COMMAND] [ARGS...] 命令选项如下： -f，–file FILE指定Compose模板文件，默认为docker-compose.yml，可以多次指定。 -p，–project-name NAME指定项目名称，默认将使用所在目录名称作为项目名。 -x-network-driver 使用Docker的可拔插网络后端特性（需要Docker 1.9+版本） -x-network-driver DRIVER指定网络后端的驱动，默认为bridge（需要Docker 1.9+版本） -verbose输出更多调试信息 -v，–version打印版本并退出 docker-compose top 显示正在运行的进程 docker-compose top docker-compose up docker-compose up [options] [--scale SERVICE=NUM...] [SERVICE...] 选项包括： -d 在后台运行服务容器 –no-color 不使用颜色来区分不同的服务的控制输出 –no-deps 不启动服务所链接的容器 –force-recreate 强制重新创建容器，不能与–no-recreate同时使用 –no-recreate 如果容器已经存在，则不重新创建，不能与–force-recreate同时使用 –no-build 不自动构建缺失的服务镜像 –build 在启动容器前构建服务镜像 –abort-on-container-exit 停止所有容器，如果任何一个容器被停止，不能与-d同时使用 -t, –timeout TIMEOUT 停止容器时候的超时（默认为10秒） –remove-orphans 删除服务中没有在compose文件中定义的容器 –scale SERVICE=NUM 设置服务运行容器的个数，将覆盖在compose中通过scale指定的参数 启动所有服务 docker-compose up 在后台所有启动服务 docker-compose up -d -f 指定使用的Compose模板文件，默认为docker-compose.yml，可以多次指定。 docker-compose -f docker-compose.yml up -d docker-compose ps docker-compose ps [options] [SERVICE...] 列出项目中目前的所有容器 docker-compose ps docker-compose stop docker-compose stop [options] [SERVICE...] 选项包括： -t, –timeout TIMEOUT 停止容器时候的超时（默认为10秒） 停止正在运行的容器，可以通过docker-compose start 再次启动 docker-compose stop docker-compose -h 查看帮助 docker-compose -h docker-compose down docker-compose down [options] 停止和删除容器、网络、卷、镜像。 选项包括： –rmi type，删除镜像，类型必须是：all，删除compose文件中定义的所有镜像；local，删除镜像名为空的镜像 -v, –volumes，删除已经在compose文件中定义的和匿名的附在容器上的数据卷 –remove-orphans，删除服务中没有在compose中定义的容器 停用移除所有容器以及网络相关 docker-compose down docker-compose logs docker-compose logs [options] [SERVICE...] 查看服务容器的输出。默认情况下，docker-compose将对不同的服务输出使用不同的颜色来区分。可以通过–no-color来关闭颜色。 查看服务容器的输出 docker-compose logs docker-compose build docker-compose build [options] [--build-arg key=val...] [SERVICE...] 构建（重新构建）项目中的服务容器。 选项包括： –compress 通过gzip压缩构建上下环境 –force-rm 删除构建过程中的临时容器 –no-cache 构建镜像过程中不使用缓存 –pull 始终尝试通过拉取操作来获取更新版本的镜像 -m, –memory MEM为构建的容器设置内存大小 –build-arg key=val为服务设置build-time变量 服务容器一旦构建后，将会带上一个标记名。可以随时在项目目录下运行docker-compose build来重新构建服务 docker-compose pull docker-compose pull [options] [SERVICE...] 拉取服务依赖的镜像。 选项包括： –ignore-pull-failures，忽略拉取镜像过程中的错误 –parallel，多个镜像同时拉取 –quiet，拉取镜像过程中不打印进度信息 docker-compose pull docker-compose restart docker-compose restart [options] [SERVICE...] 重启项目中的服务。 选项包括： -t, –timeout TIMEOUT，指定重启前停止容器的超时（默认为10秒） 重启项目中的服务 docker-compose restart docker-compose rm docker-compose rm [options] [SERVICE...] 删除所有（停止状态的）服务容器。 选项包括： –f, –force，强制直接删除，包括非停止状态的容器 -v，删除容器所挂载的数据卷 删除所有（停止状态的）服务容器。推荐先执行docker-compose stop命令来停止容器。 docker-compose rm docker-compose start docker-compose start [SERVICE...] 启动已经存在的服务容器。 docker-compose start docker-compose run docker-compose run [options] [-v VOLUME...] [-p PORT...] [-e KEY=VAL...] SERVICE [COMMAND] [ARGS...] 在指定服务上执行一个命令。 在指定容器上执行一个ping命令。 docker-compose run ubuntu ping www.baidu.com docker-compose scale docker-compose scale web=3 db=2 设置指定服务运行的容器个数。通过service=num的参数来设置数量 docker-compose pause docker-compose pause [SERVICE...] 暂停一个服务容器 docker-compose kill docker-compose kill [options] [SERVICE...] 通过发送SIGKILL信号来强制停止服务容器。 支持通过-s参数来指定发送的信号，例如通过如下指令发送SIGINT信号： docker-compose kill -s SIGINT dokcer-compose config docker-compose config [options] 验证并查看compose文件配置。 选项包括： --resolve-image-digests 将镜像标签标记为摘要 -q, –quiet 只验证配置，不输出。 当配置正确时，不输出任何内容，当文件配置错误，输出错误信息 --services 打印服务名，一行一个 --volumes 打印数据卷名，一行一个 docker-compose create docker-compose create [options] [SERVICE...] 为服务创建容器。 选项包括： –force-recreate：重新创建容器，即使配置和镜像没有改变，不兼容–no-recreate参数 –no-recreate：如果容器已经存在，不需要重新创建，不兼容–force-recreate参数 –no-build：不创建镜像，即使缺失 –build：创建容器前，生成镜像 docker-compose exec docker-compose exec [options] SERVICE COMMAND [ARGS...] 选项包括： -d 分离模式，后台运行命令。 –privileged 获取特权。 –user USER 指定运行的用户。 -T 禁用分配TTY，默认docker-compose exec分配TTY。 –index=index，当一个服务拥有多个容器时，可通过该参数登陆到该服务下的任何服务，例如：docker-compose exec –index=1 web /bin/bash ，web服务中包含多个容器 docker-compose port docker-compose port [options] SERVICE PRIVATE_PORT 显示某个容器端口所映射的公共端口。 选项包括： –protocol=proto，指定端口协议，TCP（默认值）或者UDP –index=index，如果同意服务存在多个容器，指定命令对象容器的序号（默认为1) docker-compose push docker-compose push [options] [SERVICE...] 推送服务依的镜像。 选项包括： –ignore-push-failures 忽略推送镜像过程中的错误 docker-compose unpause docker-compose unpause [SERVICE...] 恢复处于暂停状态中的服务。 docker-compose version docker-compose version 打印版本信息。 模板文件详解 Compose允许用户通过一个docker-compose.yml模板文件（YAML 格式）来定义一组相关联的应用容器为一个项目（project）。 Compose模板文件是一个定义服务、网络和卷的YAML文件。Compose模板文件默认路径是当前目录下的docker-compose.yml，可以使用.yml或.yaml作为文件扩展名。 Docker-Compose标准模板文件应该包含version、services、networks 三大部分，最关键的是services和networks两个部分。 version: '2' services: web: image: dockercloud/hello-world ports: - 8080 networks: - front-tier - back-tier redis: image: redis links: - web networks: - back-tier lb: image: dockercloud/haproxy ports: - 80:80 links: - web networks: - front-tier - back-tier volumes: - /var/run/docker.sock:/var/run/docker.sock networks: front-tier: driver: bridge back-tier: driver: bridge Compose目前有三个版本分别为Version 1，Version 2，Version 3，Compose区分Version 1和Version 2（Compose 1.6.0+，Docker Engine 1.10.0+）。Version 2支持更多的指令。Version 1将来会被弃用。 image image是指定服务的镜像名称或镜像ID。如果镜像在本地不存在，Compose将会尝试拉取镜像。 services: web: image: hello-world build 服务除了可以基于指定的镜像，还可以基于一份Dockerfile，在使用up启动时执行构建任务，构建标签是build，可以指定Dockerfile所在文件夹的路径。Compose将会利用Dockerfile自动构建镜像，然后使用镜像启动服务容器。 build: /path/to/build/dir 也可以是相对路径，只要上下文确定就可以读取到Dockerfile。 build: ./dir 设定上下文根目录，然后以该目录为准指定Dockerfile。 build: context: ../ dockerfile: path/of/Dockerfile build都是一个目录，如果要指定Dockerfile文件需要在build标签的子级标签中使用dockerfile标签指定。 如果同时指定image和build两个标签，那么Compose会构建镜像并且把镜像命名为image值指定的名字。 context context选项可以是Dockerfile的文件路径，也可以是到链接到git仓库的url，当提供的值是相对路径时，被解析为相对于撰写文件的路径，此目录也是发送到Docker守护进程的context build: context: ./dir dockerfile 使用dockerfile文件来构建，必须指定构建路径 build: context: . dockerfile: Dockerfile-alternate dockerfile指令不能跟image同时使用，否则Compose将不确定根据哪个指令来生成最终的服务镜像。 command 使用command可以覆盖容器启动后默认执行的命令。 command: bundle exec thin -p 3000 container_name Compose的容器名称格式是： 可以自定义项目名称、服务名称，但如果想完全控制容器的命名，可以使用标签指定： container_name: app net 设置网络模式。 net: \"bridge\" net: \"none\" net: \"host\" depends_on 在使用Compose时，最大的好处就是少打启动命令，但一般项目容器启动的顺序是有要求的，如果直接从上到下启动容器，必然会因为容器依赖问题而启动失败。例如在没启动数据库容器的时候启动应用容器，应用容器会因为找不到数据库而退出。depends_on标签用于解决容器的依赖、启动先后的问题。 version: '2' services: web: build: . depends_on: - db - redis redis: image: redis db: image: postgres 上述YAML文件定义的容器会先启动redis和db两个服务，最后才启动web 服务。 pid pid: \"host\" 将PID模式设置为主机PID模式，跟主机系统共享进程命名空间。容器使用pid标签将能够访问和操纵其他容器和宿主机的名称空间。 ports ports用于映射端口的标签。 使用HOST:CONTAINER格式或者只是指定容器的端口，宿主机会随机映射端口。 ports: - \"3000\" - \"8000:8000\" - \"49100:22\" - \"127.0.0.1:8001:8001\" 当使用HOST:CONTAINER格式来映射端口时，如果使用的容器端口小于60可能会得到错误得结果，因为YAML将会解析xx:yy这种数字格式为60进制。所以建议采用字符串格式。 extra_hosts 添加主机名的标签，会在/etc/hosts文件中添加一些记录。 extra_hosts: - \"somehost:162.242.195.82\" - \"otherhost:50.31.209.229\" 启动后查看容器内部hosts： 162.242.195.82 somehost 50.31.209.229 otherhost volumes 挂载一个目录或者一个已存在的数据卷容器，可以直接使用 [HOST:CONTAINER]格式，或者使用[HOST:CONTAINER:ro]格式，后者对于容器来说，数据卷是只读的，可以有效保护宿主机的文件系统。 Compose的数据卷指定路径可以是相对路径，使用 . 或者 .. 来指定相对目录。 数据卷的格式可以是下面多种形式： volumes: // 只是指定一个路径，Docker 会自动在创建一个数据卷（这个路径是容器内部的）。 - /var/lib/mysql // 使用绝对路径挂载数据卷 - /opt/data:/var/lib/mysql // 以 Compose 配置文件为中心的相对路径作为数据卷挂载到容器。 - ./cache:/tmp/cache // 使用用户的相对路径（~/ 表示的目录是 /home// 或者 /root/）。 - ~/configs:/etc/configs/:ro // 已经存在的命名的数据卷。 - datavolume:/var/lib/mysql 如果不使用宿主机的路径，可以指定一个volume_driver。 volume_driver: mydriver volumes_from 从另一个服务或容器挂载其数据卷： volumes_from: - service_name - container_name dns 自定义DNS服务器。可以是一个值，也可以是一个列表。 dns：8.8.8.8 dns： - 8.8.8.8 - 9.9.9.9 dns_search 配置DNS搜索域。可以是一个值，也可以是一个列表。 dns_search：example.com dns_search： - domain1.example.com - domain2.example.com entrypoint 在Dockerfile中有一个指令叫做ENTRYPOINT指令，用于指定接入点。 在docker-compose.yml中可以定义接入点，覆盖Dockerfile中的定义： entrypoint: /code/entrypoint.sh env_file 在docker-compose.yml中可以定义一个专门存放变量的文件。 如果通过docker-compose -f FILE指定配置文件，则env_file中路径会使用配置文件路径。 如果有变量名称与environment指令冲突，则以后者为准。格式如下： env_file: .env 或者根据docker-compose.yml设置多个： env_file: - ./common.env - ./apps/web.env - /opt/secrets.env 如果在配置文件中有build操作，变量并不会进入构建过程中。 cap_add 增加指定容器的内核能力（capacity）。 让容器具有所有能力可以指定： cap_add: - ALL cap_drop 去掉指定容器的内核能力（capacity）。 去掉NET_ADMIN能力可以指定： cap_drop: - NET_ADMIN cgroup_parent 创建了一个cgroup组名称为cgroups_1: cgroup_parent: cgroups_1 devices 指定设备映射关系，例如： devices: - \"/dev/ttyUSB1:/dev/ttyUSB0 expose 暴露端口，但不映射到宿主机，只允许能被连接的服务访问。仅可以指定内部端口为参数，如下所示： expose: - \"3000\" - \"8000\" extends 基于其它模板文件进行扩展。例如，对于webapp服务定义了一个基础模板文件为common.yml： # common.yml webapp: build: ./webapp environment: - DEBUG=false - SEND_EMAILS=false 再编写一个新的development.yml文件，使用common.yml中的webapp服务进行扩展： # development.yml web: extends: file: common.yml service: webapp ports: - \"8000:8000\" links: - db environment: - DEBUG=true db: image: mysql 后者会自动继承common.yml中的webapp服务及环境变量定义。 extends限制如下： A、要避免出现循环依赖 B、extends不会继承links和volumes_from中定义的容器和数据卷资源 推荐在基础模板中只定义一些可以共享的镜像和环境变量，在扩展模板中具体指定应用变量、链接、数据卷等信息 external_links 链接到docker-compose.yml外部的容器，可以是非Compose管理的外部容器。 external_links: - redis_1 - project_db_1:mysql - project_db_1:postgresql labels 为容器添加Docker元数据（metadata）信息。例如，可以为容器添加辅助说明信息： labels： com.startupteam.description: \"webapp for a strtup team\" links 链接到其它服务中的容器。使用服务名称（同时作为别名），或者“服务名称:服务别名”（如 SERVICE:ALIAS），例如： links: - db - db:database - redis 使用别名将会自动在服务容器中的/etc/hosts里创建。例如： 172.17.2.186 db 172.17.2.186 database 172.17.2.187 redis log_driver 指定日志驱动类型。目前支持三种日志驱动类型： log_driver: \"json-file\" log_driver: \"syslog\" log_driver: \"none\" log_opt 日志驱动的相关参数。例如： log_driver: \"syslog\"log_opt: syslog-address: \"tcp://192.168.0.42:123\" security_opt 指定容器模板标签（label）机制的默认属性（用户、角色、类型、级别等）。例如，配置标签的用户名和角色名： security_opt: - label:user:USER - label:role:ROLE 环境变量 环境变量可以用来配置Docker-Compose的行为。 COMPOSE_PROJECT_NAME 设置通过Compose启动的每一个容器前添加的项目名称，默认是当前工作目录的名字。 COMPOSE_FILE 设置docker-compose.yml模板文件的路径。默认路径是当前工作目录。 DOCKER_HOST 设置Docker daemon的地址。默认使用unix:///var/run/docker.sock。 DOCKER_TLS_VERIFY 如果设置不为空，则与Docker daemon交互通过TLS进行。 DOCKER_CERT_PATH 配置TLS通信所需要的验证(ca.pem、cert.pem 和 key.pem)文件的路径，默认是 ~/.docker 。 四、使用示例 docker-compose模板文件编写 docker-compose.yaml文件如下： version: '2' services: web1: image: nginx ports: - \"6061:80\" container_name: \"web1\" networks: - dev web2: image: nginx ports: - \"6062:80\" container_name: \"web2\" networks: - dev - pro web3: image: nginx ports: - \"6063:80\" container_name: \"web3\" networks: - pro networks: dev: driver: bridge pro: driver: bridge #volumes: docker-compose.yaml文件指定了三个web服务。 启动应用 创建一个webapp目录，将docker-compose.yaml文件拷贝到webapp目录下，使用docker-compose启动应用。 docker-compose up -d 服务访问 "},"docs/docker_book/docker-compose配置.html":{"url":"docs/docker_book/docker-compose配置.html","title":"Docker Compose配置","keywords":"","body":"docker-compose env_file 使用环境变量 docker run -c -c后的命令是循环，从而保持容器的运行 docker-compose up 该命令会自动检查是否有修改，如果有则会自动重建对应的容器。 "},"docs/docker_book/docker-compse命令.html":{"url":"docs/docker_book/docker-compse命令.html","title":"Docker Compse命令","keywords":"","body":"docker-compose build：构建镜像 docker-compose up -d：构建启动容器 该命令会自动检查是否有修改，如果有则会自动重建对应的容器。 docker-compose down ：停止并删除容器 docker-compose start：启动停止的容器 docker-compose stop ：停止容器 "},"docs/docker_book/dockerfile制作springboot.html":{"url":"docs/docker_book/dockerfile制作springboot.html","title":"Dockerfile制作Springboot","keywords":"","body":"第一步：复制相关东西 第二步：配置dockerfile 基础镜像使用centos FROM centos 维护者信息 MAINTAINER wjwwjw_595@126.com 将jdk包导入 ADD jdk-8u191-linux-x64.tar.gz /home 将项目包导入 ADD monitorServices-1.0.0-SNAPSHOT.jar /home 配置文件导入 COPY config /home 依赖包导入 COPY lib /home 设置工作空间 ENV WORKPATH /home/ WORKDIR $WORKPATH 环境变量配置 ENV JAVA_HOME /home/jdk1.8.0_191 ENV CLASSPATH $JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar ENV PATH $PATH:$JAVA_HOME/bin 暴露端口 EXPOSE 8080 执行启动指令 CMD java -jar -Dloader.path=lib,config /home/monitorServices-1.0.0-SNAPSHOT.jar 第三步：制作镜像 docker build -f Dockerfile -t monitor-service:1.0 . -f：是文件名，默认 dockerfile -t：镜像名 第四部：保存镜像 docker save -o monitor-service.tar monitor-service 导入：docker load -i monitor-service.tar 第五步：运行容器 （可以用docker-compose 编排） docker run -p 8080:8080 --name=monitor-service -itd monitor-service:1.0 (有CMD的就不能有参数/bin/bash) （注意：docker run命令如果指定了参数会把CMD里的参数覆盖 /bin/bash 就是参数 一个Dockerfile仅仅最后一个CMD起作用 ） docker exec -it monitor-service /bin/bash netstat -ntlp 导出容器 docker export -o monitor-service.tar monitor-service 导入镜像 (import 可以重命名) docker import monitor-service.tar monitor-service:latest 注意：运行导入的镜像的时候必须带command，否则启动报如下错误 Error response from daemon: No command specified 具体的command需要在导出容器的时候通过docker ps查看到 docker ps --no-trunc vue： docker build -f Dockerfile -t monitor-web:1.0 . docker run -p 8086:8086 --name=monitor-web -itd monitor-web:1.0 批量导入镜像： ll .tar|awk '{print $NF}'|sed -r 's#(.)#docker load -i \\1#' |bash "},"docs/docker_book/docker实战教程.html":{"url":"docs/docker_book/docker实战教程.html","title":"Docker实战教程","keywords":"","body":"docker实战教程 docker介绍 https://docs.docker.com/develop/ https://docs.docker.com/ 官方文档 https://docs.docker.com/compose/compose-file/compose-file-v3/ https://docs.docker.com/engine/reference/commandline/cli/ https://docs.docker.com/compose/install/ 好参考： https://www.wenjiangs.com/doc/3sfo9ygs8 Docker 属于 Linux 容器的一种封装，提供简单易用的容器使用接口。它是目前最流行的 Linux 容器解决方案。 Docker 将应用程序与该程序的依赖，打包在一个文件里面。运行这个文件，就会生成一个虚拟容器。程序在这个虚拟容器里运行，就好像在真实的物理机上运行一样。有了 Docker，就不用担心环境问题。容器是在操作系统层面上实现虚拟化，直接复用本地主机的操作系统 docker用途 （1）提供一次性的环境。比如，本地测试他人的软件、持续集成的时候提供单元测试和构建的环境。 （2）提供弹性的云服务。因为 Docker 容器可以随开随关，很适合动态扩容和缩容。 （3）组建微服务架构。通过多个容器，一台机器可以跑多个服务，因此在本机就可以模拟出微服务架构。 docker优点 1、解决环境配置难题 2、虚拟机也可以解决环境配置问题,存在的问题1、占用的资源多（系统级）：占用磁盘和内存资源不共享，docker是进程级（资源可以共享）；冗余步骤多（比如登录）；启动慢 Linux 容器不是模拟一个完整的操作系统，而是对进程进行隔离。容器里面的进程来说，它接触到的各种资源都是虚拟的，从而实现与底层系统的隔离 docker版本变化 docker版本变化： Docker从1.13.x版本开始，版本分为企业版EE和社区版CE，版本号也改为按照时间线来发布，比如17.03就是2017年3月。 Docker的linux发行版的软件仓库从以前的https://apt.dockerproject.org和https://yum.dockerproject.org变更为目前的https://download.docker.com, 软件包名字改为docker-ce和docker-ee。 docker安装 安装前准备 关闭 安全模块 selinux，不然docker会自动关闭 临时关闭： setenfore 0 永久关闭（需要重启）：修改/etc/selinux/config 文件 将SELINUX=enforcing改为SELINUX=disabled docker在线安装 centos7版本 1.查看Linux核心版本，3.10版本及以上才可以安装docker。 uname -r 2.更新yum包 yum update 3.查看docker是否曾经安装过 whereis docker 如果安装过，则删除之前的版本 yum remove docker docker-common docker-selinux docker-engine 4.安装需要的软件包， yum-util 提供yum-config-manager功能，另外两个是devicemapper驱动依赖的 yum install -y yum-utils device-mapper-persistent-data lvm2 5.设置yum源 yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo 6.查看docker版本，一般使用稳定版 yum list docker-ce --showduplicates | sort -r 7.安装docker 默认安装最新版本 yum install docker-ce 安装某特定版本需增加版本号（如18.06.3.ce-3.el7） yum install docker-ce-18.06.3.ce 8.启动docker systemctl start docker 9.开机启动 systemctl enable docker 验证安装是否成功 docker version 或 docker info 如下存在Client和Server则成功 docker离线安装 1、下载: https://download.docker.com/linux/static/stable/x86_64/ 2、解压： tar -xvf docker-18.06.1-ce.tgz 3、将解压出来的docker文件内容移动到 /usr/bin/ 目录下 cp docker/* /usr/bin/ 4、将docker注册为service vim /etc/systemd/system/docker.service `[Unit] Description=Docker Application Container Engine Documentation=https://docs.docker.com After=network-online.target firewalld.service Wants=network-online.target [Service] Type=notify //the default is not to use systemd for cgroups because the delegate issues still // exists and systemd currently does not support the cgroup feature set required // for containers run by docker ExecStart=/usr/bin/dockerd ExecReload=/bin/kill -s HUP $MAINPID // Having non-zero Limit*s causes performance problems due to accounting overhead // in the kernel. We recommend using cgroups to do container-local accounting. LimitNOFILE=infinity LimitNPROC=infinity LimitCORE=infinity //Uncomment TasksMax if your systemd version supports it. //Only systemd 226 and above support this version. //TasksMax=infinity TimeoutStartSec=0 //set delegate yes so that systemd does not reset the cgroups of docker containers Delegate=yes // kill only the docker process, not all processes in the cgroup KillMode=process //restart the docker process if it exits prematurely Restart=on-failure StartLimitBurst=3 StartLimitInterval=60s [Install] WantedBy=multi-user.target ` 4、启动 chmod +x /etc/systemd/system/docker.service #添加文件权限并启动docker systemctl daemon-reload #重载unit配置文件 systemctl start docker #启动Docker systemctl enable docker.service #设置开机自启 5、验证 systemctl status docker #查看Docker状态 docker -v #查看Docker版本 docker-compose docker-compose介绍 参考文档：https://docs.docker.com/compose/ ​ Docker Compose是一个用来定义和运行多个Docker应用的工具。一个使用Docker容器的应用，通常由多个容器组成。使用Docker Compose不再需要使用shell脚本来启动容器。 ​ Compose 通过一个配置文件来管理多个Docker容器，在配置文件中，所有的容器通过services来定义，然后使用docker-compose脚本来启动，停止和重启应用，和应用中的服务以及所有依赖服务的容器，非常适合组合使用多个容器进行开发的场景。 ​ 和docker版本的兼容 docker-compose安装 https://docs.docker.com/compose/install/ 从github安装 下载最新的 docker-compose文件 https://github.com/docker/compose/releases/tag/1.25.0 ：到github直接下载 sudo curl -L https://github.com/docker/compose/releases/download/1.16.1/docker-compose-uname -s-uname -m -o /usr/local/bin/docker-compose 若是github访问太慢，可以用daocloud下载 sudo curl -L https://get.daocloud.io/docker/compose/releases/download/1.25.1/docker-compose-uname -s-uname -m -o /usr/local/bin/docker-compose 添加可执行权限 sudo chmod +x /usr/local/bin/docker-compose 测试安装结果 $ docker-compose version 通过python pip 安装 1、安装python-pip yum -y install epel-release yum -y install python-pip 2、安装docker-compose pip install docker-compose 待安装完成后，执行查询版本的命令，即可安装docker-compose docker-compose version docker核心原理 overlay2：存储驱动 docker网络 Docker使用Linux桥接，在宿主机虚拟一个Docker容器网桥(docker0)，Docker启动一个容器时会根据Docker网桥的网段分配给容器一个IP地址，称为Container-IP，同时Docker网桥是每个容器的默认网关。因为在同一宿主机内的容器都接入同一个网桥，这样容器之间就能够通过容器的Container-IP直接通信。 四种网络模式 Docker网络模式 配置 说明 host模式 --net=host 容器和宿主机共享Network namespace。 container模式 --net=container:NAME_or_ID 容器和另外一个容器共享Network namespace。 kubernetes中的pod就是多个容器共享一个Network namespace。 none模式 --net=none 容器有独立的Network namespace，但并没有对其进行任何网络设置，如分配veth pair 和网桥连接，配置IP等。 bridge模式 --net=bridge （默认为该模式） docker network ls #查看网络命令 当创建docker 时自动创建三个网络 bridge模式 当Docker进程启动时，会在主机上创建一个名为docker0的虚拟网桥，此主机上启动的Docker容器会连接到这个虚拟网桥上。虚拟网桥的工作方式和物理交换机类似，这样主机上的所有容器就通过交换机连在了一个二层网络中。 从docker0子网中分配一个IP给容器使用，并设置docker0的IP地址为容器的默认网关。在主机上创建一对虚拟网卡veth pair设备，Docker将veth pair设备的一端放在新创建的容器中，并命名为eth0（容器的网卡），另一端放在主机中，以vethxxx这样类似的名字命名，并将这个网络设备加入到docker0网桥中。可以通过brctl show命令查看。 使用docker run -p时，docker实际是在iptables做了DNAT规则，实现端口转发功能。可以使用iptables -t nat -vnL查看 host模式 相当于Vmware中的桥接模式，与宿主机在同一个网络中，但没有独立IP地址 docker 使用linux的namespaces技术来进行资源隔离，一个Network Namespace提供了一份独立的网络环境，包括网卡、路由、Iptable规则等都与其他的Network Namespace隔离。一个Docker容器一般会分配一个独立的Network Namespace。但如果启动容器的时候使用host模式，那么这个容器将不会获得一个独立的Network Namespace，而是和宿主机共用一个Network Namespace。容器将不会虚拟出自己的网卡，配置自己的IP等，而是使用宿主机的IP和端口不需要进行NAT，host最大的优势就是网络性能比较好，但是docker host上已经使用的端口就不能再用了，网络的隔离性不好。 container模式 这个模式指定新创建的容器和已经存在的一个容器共享一个 Network Namespace，而不是和宿主机共享。新创建的容器不会创建自己的网卡，配置自己的 IP，而是和一个指定的容器共享 IP、端口范围等。同样，两个容器除了网络方面，其他的如文件系统、进程列表等还是隔离的。两个容器的进程可以通过 lo 网卡设备通信。 None 网络模式 使用none模式，Docker容器拥有自己的Network Namespace，但是，并不为Docker容器进行任何网络配置。也就是说，这个Docker容器没有网卡、IP、路由等信息。需要我们自己为Docker容器添加网卡、配置IP等。 这种网络模式下容器只有lo回环网络，没有其他网卡。none模式可以在容器创建时通过--network=none来指定。这种类型的网络没有办法联网，封闭的网络能很好的保证容器的安全性 volume（卷） Docker的数据持久化主要有两种方式 持久化使数据不随着container的结束而结束 bind mount（host的某个指定目录中） volume（/var/lib/docker/volumes docker自己管理volume） bind mount 缺点：不同宿主机不好移植（系统目录结构不一样，不在dockerfile出现） 例子： docker run -it -v $(pwd)/host-dava:/container-data alpine sh 注意 host机器的目录路径必须为全路径(准确的说需要以/或~/开始的路径)，不然docker会将其当做volume而不是bind mount处理 如果host机器上的目录不存在，docker会自动创建该目录 如果container中的目录不存在，docker会自动创建该目录 如果container中的目录已经有内容，那么docker会使用host上的目录将其覆盖掉 volume docker管理，在目录 /var/lib/docker/volumes 将my-volume挂载到container中的/mydata目录 docker run -it -v my-volume:/mydata alpine sh #my-volume不存在，那么docker会自动创建my-volume 在/var/lib/docker/volumes 下 #查看 docker volume inspect my-volume [ { \"CreatedAt\": \"2018-03-28T14:52:49Z\", \"Driver\": \"local\", \"Labels\": null, \"Mountpoint\": \"/var/lib/docker/volumes/my-volume/_data\", \"Name\": \"my-volume\", \"Options\": {}, \"Scope\": \"local\" } ] 也可以不指定host名称 docker run -it -v /mydata alpine sh 如果volume是空的而container中的目录有内容，那么docker会将container目录中的内容拷贝到volume中 如果volume中已经有内容，则会将container中的目录覆盖 Dockerfile中 #Dockerfile VOLUME /foo 在docker运行时，docker会创建一个匿名的volume，并将此volume绑定到container的/foo目录中，如果container的/foo目录下已经有内容，则会将内容拷贝的volume中。也即，Dockerfile中的VOLUME /foo与docker run -v /foo alpine的效果一样 Dockerfile中的VOLUME使每次运行一个新的container时，都会为其自动创建一个匿名的volume，如果需要在不同container之间共享数据，那么我们依然需要通过docker run -it -v my-volume:/foo的方式将/foo中数据存放于指定的my-volume中 匿名卷 /var/lib/docker/volumes/区域 主机上的一个文件映射到容器当中的某个文件，容器向其中写入数据就相当于向主机中对应的文件写入数据 volumes-from 创建新容器时, 使用和另一个容器相同的挂载策略 docker container run --name d2 --volumes-from d1 -d nginx d1有自己的卷，d2集成d1的卷 命令 docker volume -help #查看 $docker volume ls #查看详情 $docker volume inspect #创建 $docker volume crreate # 删除卷 $docker volume rm # 删除没有挂载的卷,闲置的 $docker volume prune docker常用命令 docker模块 images文件和container文件 Docker 把应用程序及其依赖，打包在 image 文件里面。只有通过这个文件，才能生成 Docker 容器。image 文件可以看作是容器的模板。Docker 根据 image 文件生成容器的实例。同一个 image 文件，可以生成多个同时运行的容器实例。image 是二进制文件。实际开发中，一个 image 文件往往通过继承另一个 image 文件，加上一些个性化设置而生成。image 文件是通用的，一台机器的 image 文件拷贝到另一台机器，照样可以使用。 image 文件生成的容器实例，本身也是一个文件，称为容器文件。也就是说，一旦容器生成，就会同时存在两个文件： image 文件和容器文件。 实例 从镜像仓库拉取 hello-world，默认镜像仓库地址：https://hub.docker.com/ $ docker image pull library/hello-world docker image pull:从仓库抓取image文件 library/hello-world：image文件在仓库的位置，library是image文件的组，hello-world是image文件名 由于 Docker 官方提供的 image 文件，都放在library组里面，所以它的是默认组，可以省略。 上面的命令也可以 $ docker image pull hello-world 抓取成功后本机就可以看到image 文件 $ docker image ls 运行image文件 $ docker container run hello-world docker container run:从image文件生成一个container（容器）实例 说明：docker container run命令具有自动抓取功能，如果本地没有image文件，就会从仓库抓取，前面的 docker image pull非必须。 输出这段提示以后，hello world就会停止运行，容器自动终止。 有些容器不会自动终止，终止需要 docker container kill [容器ID] 后台运行的 $ docker container run -it ubuntu /bin/bash :container可以省略 $ docker container ls：查看运行中的容器 $ docker container ls -a ：所有容器 image和container关系 要有Container首先要有Image，也就是说Container是通过image创建的。 Container是在原先的Image之上新加的一层，称作Container layer，这一层是可读可写的（Image是只读的）。 在面向对象的编程语言中，有类跟对象的概念。类是抽象的，对象是类的具体实现。Image跟Container可以类比面向对象中的类跟对象，Image就相当于抽象的类，Container就相当于具体实例化的对象。 Image跟Container的职责区别：Image负责APP的存储和分发，Container负责运行APP。 image和container常用命令 拉取镜像 docker image pull [镜像名称] ：拉取镜像 查看镜像容器 docker image ls ：查看镜像 docker container ls或docker ps ：查看运行中的容器 docker container ls -a或docker ps -a：查看所有容器 运行容器docker run 和start区别 docker container run [镜像名称]：运行镜像，每次运行都会生成一个新的容器（一般运行一次） docker container start [containerID]：启动已有的容器 docker logs [容器ID] ：查看日志 docker container cp ：docker container cp命令用于从正在运行的 Docker 容器里面，将文件拷贝到本机。下面是拷贝到当前目录的写法。 $ docker container cp [containID]:[/path/to/file] . docker run -t -i ubuntu /bin/bash 说明： ​ docker run：启动container，本地没有远程拉取 ​ ubuntu：你想要启动的image ​ -t：进入终端 ​ -i：获得一个交互式的连接，通过获取container的输入 ​ /bin/bash：在container中启动一个bash shell 退出Ctrl+D 或exit 再次进入：1、启动 ： docker start|stop|restart [容器ID或名称] 1）、docker attach [容器ID或名称]:这个退出，容器就关闭了 2）、docker exec -it crazy_lalande /bin/bash ​ docker exec -it：进入容器（运行中的） ​ crazy_lalande ：容器名 ​ /bin/bash：在container中启动一个bash shell 退出容器 退出容器： exit 或 CTRL+D 删除容器 删除容器： docker container rm [容器ID] 删除镜像 ： docker rmi [镜像名] 或docker image rm [镜像名] -f, -force: 强制删除镜像，即便有容器引用该镜像； -no-prune: 不要删除未带标签的父镜像； docker stop 和docker kill 区别 docker stop，支持“优雅退出”。先发送SIGTERM信号，在一段时间之后（10s）再发送SIGKILL信号。Docker内部的应用程序可以接收SIGTERM信号，然后做一些“退出前工作”，比如保存状态、处理当前请求等。 docker kill，发送SIGKILL信号，应用程序直接退出。 Dockerfile 制作自己的image eg： FROM node:8.4 COPY . /app WORKDIR /app RUN npm install --registry=https://registry.npm.taobao.org EXPOSE 3000 含义 FROM node:8.4：该 image 文件继承官方的 node image，冒号表示标签，这里标签是8.4，即8.4版本的 node。 COPY . /app：将当前目录下的所有文件（除了.dockerignore排除的路径），都拷贝进入 image 文件的/app目录。 WORKDIR /app：指定接下来的工作路径为/app。 RUN npm install：在/app目录下，运行npm install命令安装依赖。注意，安装后所有的依赖，都将打包进入 image 文件。 EXPOSE 3000：将容器 3000 端口暴露出来， 允许外部连接这个端口。 创建image文件 $ docker image build -t koa-demo . # 或者 $ docker image build -t koa-demo:0.0.1 . 上面代码中，-t参数用来指定 image 文件的名字，后面还可以用冒号指定标签。如果不指定，默认的标签就是latest。最后的那个点表示 Dockerfile 文件所在的路径，上例是当前路径，所以是一个点。 生成容器 $ docker container run -p 8000:3000 -it koa-demo /bin/bash # 或者 $ docker container run -p 8000:3000 -it koa-demo:0.0.1 /bin/bash 参数含义： -p参数：容器的 3000 端口映射到本机的 8000 端口。 -it参数：容器的 Shell 映射到当前的 Shell，然后你在本机窗口输入的命令，就会传入容器。 koa-demo:0.0.1：image 文件的名字（如果有标签，还需要提供标签，默认是 latest 标签）。 /bin/bash：容器启动以后，内部第一个执行的命令。这里是启动 Bash，保证用户可以使用 Shell。 CMD命令 FROM node:8.4 COPY . /app WORKDIR /app RUN npm install --registry=https://registry.npm.taobao.org EXPOSE 3000 CMD node demos/01.js 最后一行CMD node demos/01.js，它表示容器启动后自动执行node demos/01.js RUN命令在 image 文件的构建阶段执行，执行结果都会打包进入 image 文件；CMD命令则是在容器启动后执行 一个 Dockerfile 可以包含多个RUN命令，但是只能有一个CMD命令 注意，指定了CMD命令以后，docker container run命令就不能附加命令了（比如前面的/bin/bash），否则它会覆盖CMD命令。现在，启动容器可以使用下面的命令。 $ docker container run --rm -p 8000:3000 -it koa-demo:0.0.1 发布image 首先，去 hub.docker.com 或 cloud.docker.com 注册一个账户。然后，用下面的命令登录。 $ docker login 接着，为本地的 image 标注用户名和版本。 $ docker image tag [imageName] [username]/[repository]:[tag] # 实例 $ docker image tag koa-demos:0.0.1 ruanyf/koa-demos:0.0.1 也可以不标注用户名，重新构建一下 image 文件。 $ docker image build -t [username]/[repository]:[tag] . 最后，发布 image 文件。 $ docker image push [username]/[repository]:[tag] dockerfile书写规范 指令忽略大小写，建议使用大写；每一行只支持一条指令，每条指令可以携带多个参数 cmd和ENTRYPOINT的区别 docker save与docker export的区别 *注：用户既可以使用 docker load 来导入镜像存储文件到本地镜像库，也可以使用 docker import 来导入一个容器快照到本地镜像库。这两者的区别在于容器快照文件将丢弃所有的历史记录和元数据信息（即仅保存容器当时的快照状态），而镜像存储文件将保存完整记录，体积也要大。此外，从容器快照文件导入时可以重新指定标签等元数据信息。 docker save docker的命令行接口设计得很优雅，很多命令的帮助直接在后面加--help就可以查看。 docker save的帮助如下： >docker save --help 从命令行帮助可以看出，docker save是用来将一个或多个image打包保存的工具。 例如我们想将镜像库中的postgres和mongo打包，那么可以执行： docker save -o images.tar postgres:9.6 mongo:3.4 打包之后的images.tar包含postgres:9.6和mongo:3.4这两个镜像。 虽然命令行参数要求指定image，实际上也可以对container进行打包，例如： >docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 3623943d369f postgres:9.6 \"docker-entrypoint...\" 3 hours ago Up 3 hours 5432/tcp postgres >docker save -o b.tar postgres >docker save -o c.tar postgres:9.6 >ls -al -rwxrwxrwx 1 root root 277886464 8月 26 14:40 b.tar -rwxrwxrwx 1 root root 277886464 8月 26 14:41 c.tar 通过以上命令可以看到，b.tar和c.tar是完全一模一样的。这说明，docker save如果指定的是container，docker save将保存的是容器背后的image。 将打包后的镜像载入进来使用docker load，例如： docker load -i images.tar 上述命令将会把postgres:9.6和mongo:3.4载入进来，如果本地镜像库已经存在这两个镜像，将会被覆盖。 docker save的应用场景是，如果你的应用是使用docker-compose.yml编排的多个镜像组合，但你要部署的客户服务器并不能连外网。这时，你可以使用docker save将用到的镜像打个包，然后拷贝到客户服务器上使用docker load载入。 docker export 照例查看下docker export的帮助： >docker export --help 从帮助可以看出，docker export是用来将container的文件系统进行打包的。例如： docker export -o postgres-export.tar postgres docker export需要指定container，不能像docker save那样指定image或container都可以。 将打包的container载入进来使用docker import，例如： docker import postgres-export.tar postgres:latest 从上面的命令可以看出，docker import将container导入后会成为一个image，而不是恢复为一个container。 另外一点是，docker import可以指定IMAGE[:TAG]，说明我们可以为镜像指定新名称。如果本地镜像库中已经存在同名的镜像，则原有镜像的名称将会被剥夺，赋给新的镜像。原有镜像将成为孤魂野鬼，只能通过IMAGE ID进行操作。 docker export的应用场景主要用来制作基础镜像，比如你从一个ubuntu镜像启动一个容器，然后安装一些软件和进行一些设置后，使用docker export保存为一个基础镜像。然后，把这个镜像分发给其他人使用，比如作为基础的开发环境。 docker save和docker export的区别 总结一下docker save和docker export的区别： docker save保存的是镜像（image），docker export保存的是容器（container）； docker load用来载入镜像包，docker import用来载入容器包，但两者都会恢复为镜像； docker load不能对载入的镜像重命名，而docker import可以为镜像指定新名称。 Docker-Compose 简介 Docker-Compose项目是Docker官方的开源项目，负责实现对Docker容器集群的快速编排。 Docker-Compose将所管理的容器分为三层，分别是工程（project），服务（service）以及容器（container）。Docker-Compose运行目录下的所有文件（docker-compose.yml，extends文件或环境变量文件等）组成一个工程，若无特殊指定工程名即为当前目录名。一个工程当中可包含多个服务，每个服务中定义了容器运行的镜像，参数，依赖。一个服务当中可包括多个容器实例，Docker-Compose并没有解决负载均衡的问题，因此需要借助其它工具实现服务发现及负载均衡。 Docker-Compose的工程配置文件默认为docker-compose.yml，可通过环境变量COMPOSE_FILE或-f参数自定义配置文件，其定义了多个有依赖关系的服务及每个服务运行的容器。 使用一个Dockerfile模板文件，可以让用户很方便的定义一个单独的应用容器。在工作中，经常会碰到需要多个容器相互配合来完成某项任务的情况。例如要实现一个Web项目，除了Web服务容器本身，往往还需要再加上后端的数据库服务容器，甚至还包括负载均衡容器等。 Compose允许用户通过一个单独的docker-compose.yml模板文件（YAML 格式）来定义一组相关联的应用容器为一个项目（project）。 Docker-Compose项目由Python编写，调用Docker服务提供的API来对容器进行管理。因此，只要所操作的平台支持Docker API，就可以在其上利用Compose来进行编排管理。 源码：https://github.com/docker/compose 通过浏览器访问web1，web2，web3服务: http://127.0.0.1:6061 http://127.0.0.1:6062 http://127.0.0.1:6063 实例 自建wordpress容器 方法一、自建 WordPress 容器 新建一个目录 $ mkdir docker-demo && cd docker-demo $ docker container run \\ --rm \\ --name wordpress \\ --volume \"$PWD/\":/var/www/html \\ php:5.6-apache 上面的命令基于php的 image 文件新建一个容器，并且运行该容器。php的标签是5.6-apache，说明装的是 PHP 5.6，并且自带 Apache 服务器。该命令的三个参数含义如下。 --rm：停止运行后，自动删除容器文件。 --name wordpress：容器的名字叫做wordpress。 --volume \"$PWD/\":/var/www/html：将当前目录（$PWD）映射到容器的/var/www/html（Apache 对外访问的默认目录）。因此，当前目录的任何修改，都会反映到容器里面，进而被外部访问到。 运行上面的命令以后，如果一切正常，命令行会提示容器对外的 IP 地址，请记下这个地址，我们要用它来访问容器。我分配到的 IP 地址是 172.17.0.2。 打开浏览器，访问 172.17.0.2，你会看到下面的提示。 Forbidden You don't have permission to access / on this server. 这是因为容器的/var/www/html目录（也就是本机的docker-demo目录）下面什么也没有，无法提供可以访问的内容。 请在本机的docker-demo目录下面，添加一个最简单的 PHP 文件index.php。 保存以后，浏览器刷新172.17.0.2，应该就会看到熟悉的phpinfo页面了。 拷贝 WordPress 安装包 $ wget https://cn.wordpress.org/wordpress-4.9.4-zh_CN.tar.gz $ tar -xvf wordpress-4.9.4-zh_CN.tar.gz 解压以后，WordPress 的安装文件会在docker-demo/wordpress目录下。 这时浏览器访问http://172.17.0.2/wordpress，就能看到 WordPress 的安装提示了。 官方的 MySQL 容器 $ docker container run \\ -d \\ --rm \\ --name wordpressdb \\ --env MYSQL_ROOT_PASSWORD=123456 \\ --env MYSQL_DATABASE=wordpress \\ mysql:5.7 上面的命令会基于 MySQL 的 image 文件（5.7版本）新建一个容器。该命令的五个命令行参数的含义如下。 -d：容器启动后，在后台运行。 --rm：容器终止运行后，自动删除容器文件。 --name wordpressdb：容器的名字叫做wordpressdb --env MYSQL_ROOT_PASSWORD=123456：向容器进程传入一个环境变量MYSQL_ROOT_PASSWORD，该变量会被用作 MySQL 的根密码。 --env MYSQL_DATABASE=wordpress：向容器进程传入一个环境变量MYSQL_DATABASE，容器里面的 MySQL 会根据该变量创建一个同名数据库（本例是WordPress）。 运行上面的命令以后，正常情况下，命令行会显示一行字符串，这是容器的 ID，表示已经新建成功了。 这时，使用下面的命令查看正在运行的容器，你应该看到wordpress和wordpressdb两个容器正在运行。 $ docker container ls 其中，wordpressdb是后台运行的，前台看不见它的输出，必须使用下面的命令查看。 $ docker container logs wordpressdb 定制 PHP 容器 $ docker container stop wordpress 停掉以后，由于--rm参数的作用，该容器文件会被自动删除。 然后，在docker-demo目录里面，新建一个Dockerfile文件，写入下面的内容。 FROM php:5.6-apache RUN docker-php-ext-install mysqli CMD apache2-foreground 上面代码的意思，就是在原来 PHP 的 image 基础上，安装mysqli的扩展。然后，启动 Apache。 基于这个 Dockerfile 文件，新建一个名为phpwithmysql的 image 文件。 $ docker build -t phpwithmysql . 现在基于 phpwithmysql image，重新新建一个 WordPress 容器。 $ docker container run \\ --rm \\ --name wordpress \\ --volume \"$PWD/\":/var/www/html \\ --link wordpressdb:mysql \\ phpwithmysql 跟上一次相比，上面的命令多了一个参数--link wordpressdb:mysql，表示 WordPress 容器要连到wordpressdb容器，冒号表示该容器的别名是mysql。 这时还要改一下wordpress目录的权限，让容器可以将配置信息写入这个目录（容器内部写入的/var/www/html目录，会映射到这个目录）。 $ chmod -R 777 wordpress 接着，回到浏览器的http://172.17.0.2/wordpress页面，点击\"现在就开始！\"按钮，开始安装。** $ docker container stop wordpress wordpressdb 方法二、采用官方的 WordPress 容器 首先，新建并启动 MySQL 容器。 $ docker container run \\ -d \\ -p 127.0.0.2:8080:80 \\ --rm \\ --name wordpress \\ --env WORDPRESS_DB_PASSWORD=123456 \\ --link wordpressdb:mysql \\ --volume \"$PWD/wordpress\":/var/www/html \\ wordpress $ docker container run \\ -d \\ --rm \\ --name wordpress \\ --env WORDPRESS_DB_PASSWORD=123456 \\ --link wordpressdb:mysql \\ wordpress 基于官方的 WordPress image，新建并启动 WordPress 容器。 上面命令指定wordpress容器在后台运行，导致前台看不见输出，使用下面的命令查出wordpress容器的 IP 地址。 $ docker container inspect wordpress $ docker container stop wordpress wordpressdb 方法三、采用 Docker Compose 工具 # 启动所有服务 $ docker-compose up # 关闭所有服务 $ docker-compose stop 在docker-demo目录下，新建docker-compose.yml文件，写入下面的内容。 mysql: image: mysql:5.7 environment: - MYSQL_ROOT_PASSWORD=123456 - MYSQL_DATABASE=wordpress web: image: wordpress links: - mysql environment: - WORDPRESS_DB_PASSWORD=123456 ports: - \"127.0.0.3:8080:80\" working_dir: /var/www/html volumes: - wordpress:/var/www/html $ docker-compose up 可以访问了 $ docker-compose stop $ docker-compose rm docker部署springboot项目 docker性能分析 du -hs /var/lib/docker/ 命令查看磁盘使用情况 docker system df命令，类似于Linux上的df命令，用于查看Docker的磁盘使用情况: docker system prune命令可以用于清理磁盘，删除关闭的容器、无用的数据卷和网络，以及dangling镜像(即无tag的镜像)。 docker system prune -a命令清理得更加彻底，可以将没有容器使用Docker镜像都删掉。注意，这两个命令会把你暂时关闭的容器，以及暂时没有用到的Docker镜像都删掉了 docker管理工具 Portainer "},"docs/docker_book/docker概念对比.html":{"url":"docs/docker_book/docker概念对比.html","title":"Docker概念对比","keywords":"","body":"Dockerfile中命令 docker导入导出 save和load export 和import 对比 save export 保存内容 镜像（image） 容器（container） 命令 docker save [OPTIONS] IMAGE [IMAGE...] docker export [OPTIONS] CONTAINER eg docker save -o nginx.tar nginx:latest docker export -o nginx-test.tar nginx-test 对应导入命令 load载入镜像包 import载入容器包 镜像是否可以重命名 不可以 可以 包大小 大于容器包 容量小 内容对比 包含镜像历史（可以回滚之前的层）docker images --tree（查看） 丢失镜像所有的历史 使用场景 比如：纯备份，使用docker-compose编排的统一打包 制作基础镜像（容器中安装了新的软件应用等，启动容器后有变化） 导入 docker load -i xxxx.tar docker import - dockertest:1.0 ； dockerservice:1.0 是新镜像的名字，可以随意命名 备注 不需要 导入的镜像必须带command 查看 docker ps --no-trunc docker run -p 8080:8080 --name=monitor-service -itd monitor-service:1.0 docker run -p 8080:8080 --name=monitor-service -itd monitor-service:1.0 /bin/bash(这就是命令) "},"docs/docker_book/linux虚拟网络技术.html":{"url":"docs/docker_book/linux虚拟网络技术.html","title":"Linux虚拟网络技术","keywords":"","body":"Network Namespace Network Namespace 是 Linux 内核提供的功能，是实现网络虚拟化的重要功能，它能创建多个隔离的网络空间，它们有独自网络栈信息。不管是虚拟机还是容器，运行的时候仿佛自己都在独立的网络中。而且不同Network Namespace的资源相互不可见，彼此之间无法通信。如下图所示： Network Namespace ip netns命令 可以借助ip netns命令来完成对 Network Namespace 的各种操作。ip netns命令来自于iproute2安装包，一般系统会默认安装，如果没有的话，读者自行安装。 注意：ip netns命令修改网络配置时需要 sudo 权限。 可以通过ip netns命令完成对Network Namespace 的相关操作，可以通过ip netns help查看命令帮助信息： $ ip netns help Usage: ip netns list ip netns add NAME ip netns set NAME NETNSID ip [-all] netns delete [NAME] ip netns identify [PID] ip netns pids NAME ip [-all] netns exec [NAME] cmd ... ip netns monitor ip netns list-id 默认情况下，Linux系统中是没有任何 Network Namespace的，所以ip netns list命令不会返回任何信息。 创建Network Namespace 下面，我们通过命令创建一个名为ns0的命名空间： $ ip netns add ns0 $ ip netns list ns0 新创建的 Network Namespace 会出现在/var/run/netns/目录下。如果相同名字的 namespace 已经存在，命令会报Cannot create namespace file \"/var/run/netns/ns0\": File exists的错误。 对于每个 Network Namespace 来说，它会有自己独立的网卡、路由表、ARP 表、iptables 等和网络相关的资源。 操作Network Namespace ip命令提供了ip netns exec子命令可以在对应的 Network Namespace 中执行命令。 查看新创建 Network Namespace 的网卡信息 $ ip netns exec ns0 ip addr 1: lo: mtu 65536 qdisc noop state DOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 可以看到，新创建的Network Namespace中会默认创建一个lo回环网卡，此时网卡处于关闭状态。此时，尝试去 ping 该lo回环网卡，会提示Network is unreachable $ ip netns exec ns0 ping 127.0.0.1 connect: Network is unreachable 通过下面的命令启用lo回环网卡： ip netns exec ns0 ip link set lo up 然后再次尝试去 ping 该lo回环网卡： $ ip netns exec ns0 ping -c 3 127.0.0.1 PING 127.0.0.1 (127.0.0.1) 56(84) bytes of data. 64 bytes from 127.0.0.1: icmp_seq=1 ttl=64 time=0.048 ms 64 bytes from 127.0.0.1: icmp_seq=2 ttl=64 time=0.031 ms 64 bytes from 127.0.0.1: icmp_seq=3 ttl=64 time=0.029 ms --- 127.0.0.1 ping statistics --- 3 packets transmitted, 3 received, 0% packet loss, time 1999ms rtt min/avg/max/mdev = 0.029/0.036/0.048/0.008 ms 转移设备 我们可以在不同的 Network Namespace 之间转移设备（如veth）。由于一个设备只能属于一个 Network Namespace ，所以转移后在这个 Network Namespace 内就看不到这个设备了。 其中，veth设备属于可转移设备，而很多其它设备（如lo、vxlan、ppp、bridge等）是不可以转移的。 veth pair veth pair 全称是 Virtual Ethernet Pair，是一个成对的端口，所有从这对端口一 端进入的数据包都将从另一端出来，反之也是一样。 引入veth pair是为了在不同的 Network Namespace 直接进行通信，利用它可以直接将两个 Network Namespace 连接起来。 整个veth的实现非常简单，有兴趣的读者可以参考源代码drivers/net/veth.c的实现。 veth pair 创建veth pair $ sudo ip link add type veth $ ip addr 61: veth0@veth1: mtu 1500 qdisc noop state DOWN group default qlen 1000 link/ether e6:39:e1:e0:3a:a0 brd ff:ff:ff:ff:ff:ff 62: veth1@veth0: mtu 1500 qdisc noop state DOWN group default qlen 1000 link/ether be:41:49:42:23:6a brd ff:ff:ff:ff:ff:ff 可以看到，此时系统中新增了一对veth pair，将veth0和veth1两个虚拟网卡连接了起来，此时这对 veth pair 处于”未启用“状态。 如果我们想指定 veth pair 两个端点的名称，可以使用下面的命令： ip link add vethfoo type veth peer name vethbar 实现Network Namespace间通信 下面我们利用veth pair实现两个不同的 Network Namespace 之间的通信。刚才我们已经创建了一个名为ns0的 Network Namespace，下面再创建一个信息Network Namespace，命名为ns1 $ ip netns add ns1 $ ip netns list ns1 ns0 然后我们将veth0加入到ns0，将veth1加入到ns1，如下所示： $ ip link set veth0 netns ns0 $ ip link set veth1 netns ns1 然后我们分别为这对veth pair配置上ip地址，并启用它们： $ ip netns exec ns0 iplink set veth0 up $ ip netns exec ns0 ip addr add 10.0.1.1/24 dev veth0 $ ip netns exec ns1 iplink set veth1 up $ ip netns exec ns1 ip addr add 10.0.1.2/24 dev veth1 查看这对veth pair的状态 $ ip netns exec ns0 ip addr 61: veth0@if62: mtu 1500 qdisc noqueue state UP group default qlen 1000 link/ether e6:39:e1:e0:3a:a0 brd ff:ff:ff:ff:ff:ff link-netnsid 1 inet 10.0.1.1/24 scope global veth0 valid_lft forever preferred_lft forever inet6 fe80::e439:e1ff:fee0:3aa0/64 scope link valid_lft forever preferred_lft forever $ ip netns exec ns1 ip addr 62: veth1@if61: mtu 1500 qdisc noqueue state UP group default qlen 1000 link/ether be:41:49:42:23:6a brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet 10.0.1.2/24 scope global veth1 valid_lft forever preferred_lft forever inet6 fe80::bc41:49ff:fe42:236a/64 scope link valid_lft forever preferred_lft forever 从上面可以看出，我们已经成功启用了这个veth pair，并为每个veth设备分配了对应的ip地址。我们尝试在ns1中访问ns0中的ip地址： $ ip netns exec ns1 ping -c 3 10.0.1.1 sudo: unable to resolve host zormshogu PING 10.0.1.1 (10.0.1.1) 56(84) bytes of data. 64 bytes from 10.0.1.1: icmp_seq=1 ttl=64 time=0.091 ms 64 bytes from 10.0.1.1: icmp_seq=2 ttl=64 time=0.035 ms 64 bytes from 10.0.1.1: icmp_seq=3 ttl=64 time=0.037 ms --- 10.0.1.1 ping statistics --- 3 packets transmitted, 3 received, 0% packet loss, time 1999ms rtt min/avg/max/mdev = 0.035/0.054/0.091/0.026 ms 可以看到，veth pair成功实现了两个不同Network Namespace之间的网络交互。 veth查看对端 一旦将veth pair的peer段放入另一个Network Namespace，我们在当前Namespace中就看不到它了。那么，我们怎么才能知道这个veth pair的对端在哪里呢？ 可以通过ethtool工具来查看（当Network Namespace很多时，操作会比较麻烦）： $ ip netns exec ns1 ethtool -S veth1 NIC statistics: peer_ifindex: 5 得知另一端的接口设备序列号是5，我们再到另一个命名空间中查看序列号5代表什么设备： $ ip netns exec ns0 ip link | grep 5 veth0 网桥 veth pair打破了 Network Namespace 的限制，实现了不同 Network Namespace 之间的通信。但veth pair有一个明显的缺陷，就是只能实现两个网络接口之间的通信。 如果我们想实现多个网络接口之间的通信，就可以使用下面介绍的网桥（Bridge）技术。 简单来说，网桥就是把一台机器上的若干个网络接口“连接”起来。其结果是，其中一个网口收到的报文会被复制给其他网口并发送出去。以使得网口之间的报文能够互相转发。 网桥的工作原理 网桥对报文的转发基于MAC地址。网桥能够解析收发的报文，读取目标MAC地址的信息，和自己记录的MAC表结合，来决策报文的转发目标网口。 为了实现这些功能，网桥会学习源MAC地址，在转发报文时，网桥只需要向特定的网口进行转发，从而避免不必要的网络交互。 如果它遇到一个自己从未学习到的地址，就无法知道这个报文应该向哪个网口转发，就将报文广播给所有的网口（报文来源的网口除外）。 网桥 网桥的实现 Linux内核是通过一个虚拟的网桥设备（Net Device）来实现桥接的。这个虚拟设备可以绑定若干个以太网接口设备，从而将它们桥接起来。如下图所示： 网桥的位置 如上图所示，网桥设备 br0 绑定了 eth0 和 eth1。 对于网络协议栈的上层来说，只看得到 br0，上层协议栈需要发送的报文被送到 br0，网桥设备的处理代码判断报文该被转发到 eth0 还是 eth1，或者两者皆转发；反过来，从eth0 或 eth1 接收到的报文被提交给网桥的处理代码，在这里会判断报文应该被转发、丢弃还是提交到协议栈上层。 而有时eth0、eth1 也可能会作为报文的源地址或目的地址，直接参与报文的发送与接收，从而绕过网桥。 brctl 和网桥有关的操作可以使用命令 brctl，这个命令来自 bridge-utils 这个包。 创建网桥 # 创建网桥 brctl addbr br0 删除网桥 # 删除网桥 brctl delbr br0 绑定网口 建立一个逻辑网段之后，我们还需要为这个网段分配特定的端口。在Linux 中，一个端口实际上就是一个物理或虚拟网卡。而每个网卡的名称则分别为eth0 ，eth1 ，eth2 。我们需要把每个网卡一一和br0 这个网段联系起来，作为br0 中的一个端口。 # 让eth0 成为br0 的一个端口 brctl addif br0 eth0 # 让eth1 成为br0 的一个端口 brctl addif br0 eth1 # 让eth2 成为br0 的一个端口 brctl addif br0 eth2 iptables/netfilter iptables是Linux实现的软件防火墙，用户可以通过iptables设置请求准入和拒绝规则，从而保护系统的安全。 我们也可以把iptables理解成一个客户端代理，用户通过iptables这个代理，将用户安全设定执行到对应的安全框架中，这个“安全框架”才是真正的防火墙，这个框架的名字叫netfilter。 iptables其实是一个命令行工具，位于用户空间。 iptables/netfilter(以下简称iptables)组成了Linux平台下的包过滤防火墙，可以完成封包过滤、封包重定向和网络地址转换（NAT）等功能。 消息处理链 iptables不仅要处理本机接收到的消息，也要处理本机发出的消息。这些消息需要经过一系列的”关卡“才能被本机应用层接收，或者从本机发出，每个”关卡“担负着不同的工作。这里的”关卡“被称为”链“。 INPUT：进来的数据包应用此规则链中的策规则； OUTPUT：外出的数据包应用此规则链中的规则； FORWARD：转发数据包时应用此规则链中的规则； PREROUTING：对数据包作路由选择前应用此链中的规则（所有的数据包进来的时侯都先由这个链处理）； POSTROUTING：对数据包作路由选择后应用此链中的规则（所有的数据包出来的时侯都先由这个链处理）； 数据包经过各个链的处理过程大致如下图所示： 消息处理链 规则表 从上面我们知道，iptables是按照规则来办事的，这些规则就是网络管理员预定义的条件。规则一般的定义为：如果数据包头符合这样的条件，就这样处理“。这些规则并不是严格按照添加顺序排列在一张规则表中，而是按照功能进行分类，存储在不同的表中，每个表存储一类规则： Filter 主要用来过滤数据，用来控制让哪些数据可以通过，哪些数据不能通过，它是最常用的表。 NAT 用来处理网络地址转换的，控制要不要进行地址转换，以及怎样修改源地址或目的地址，从而影响数据包的路由，达到连通的目的。 Mangle 主要用来修改IP数据包头，比如修改TTL值，同时也用于给数据包添加一些标记，从而便于后续其它模块对数据包进行处理（这里的添加标记是指往内核skb结构中添加标记，而不是往真正的IP数据包上加东西）。 Raw 在Netfilter里面有一个叫做链接跟踪的功能，主要用来追踪所有的连接，而raw表里的rule的功能是给数据包打标记，从而控制哪些数据包不做链接跟踪处理，从而提高性能；优先级最高。 表和链的关系 表和链共同完成了iptables对数据包的处理。但并不是每个链都包含所有类型的表，所以，有些链是天生不具备某些功能的。就像我们去车站乘车的时候，”关卡A“只负责检查身份证，”B关卡”只负责检查行李，而“C关卡”功能比较齐全，即负责检查身份证，又负责检查行李。二者的关系如下图所示： 表和链的关系 总结 今天我们共同学习了一些常见的Linux虚拟网络技术。其中，Linux通过Network Namespace实现了网络的隔离，使网络协议栈之间互不干扰；并通过veth pair和网桥实现了相同主机上多个Network Namespace之间的数据通信；iptables则可以帮助我们实现网络安全和数据包的路由转发功能，从而使主机和主机、容器与容器、容器和宿主机之间可以相互收发消息。在这些技术的共同协作下，才有了现在安全、稳定的虚拟网络。 作者：王勇1991 链接：https://www.jianshu.com/p/f86d4b88777d 来源：简书 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 "},"docs/docker_book/volume.html":{"url":"docs/docker_book/volume.html","title":"Volume","keywords":"","body":"容器卷 参考 https://www.cnblogs.com/edisonchou/p/docker_volumes_introduction.html vlolume的基本使用 1、管理卷 # docker volume create volume-test // 创建一个自定义容器卷 # docker volume ls // 查看所有容器卷 # docker volume inspect volume-test // 查看指定容器卷详情信息 2、三种数据持久化方式 数据从宿主机挂载到容器 1）、volumes（自定义容器卷）：默认位于/var/lib/docker/volumes 目录中（最常用方式） 2)、bind mounts：可以存储在宿主机系统的任意位置（常用）：劣势：在不同的操作系统不可以移植，不同操作系统目录结构不一样，（不能出现在Dockerfile中，出现dockerfile就不可移植） 3）、tmpfs：挂载存储在宿主机系统的内存中，不会写入宿主机的文件系统（不会用） docker commit 3bd0eef03413 demo：v1.3 提交你刚才修改的镜像，新的镜像名称为demo，版本为v1.3 "},"docs/docker_book/知识点扫盲.html":{"url":"docs/docker_book/知识点扫盲.html","title":"知识点扫盲","keywords":"","body":"知识点扫盲 一、docker一般采用 alpine作为最基础镜像 二、更新（容器开启状态，部分命令）：docker container update --restart=always 容器名 "},"docs/git/gitee相关.html":{"url":"docs/git/gitee相关.html","title":"Gitee相关","keywords":"","body":"https://gitee.com/explore ：查看优秀项目 "},"docs/git/github相关.html":{"url":"docs/git/github相关.html","title":"Github相关","keywords":"","body":""},"docs/git/git命令.html":{"url":"docs/git/git命令.html","title":"Git命令","keywords":"","body":"git命令 Git 全局设置: git config --global user.name \"大表哥\" git config --global user.email \"wjw_595@126.com\" 创建 git 仓库: mkdir test cd test git init touch README.md git add README.md git commit -m \"first commit\" git remote add origin git@gitee.com:www.wjw595.com/test.git git push -u origin master 已有仓库? cd existing_git_repo git remote add origin git@gitee.com:www.wjw595.com/test.git git push -u origin master 创建分支 git status //查看状态 创建分支 #创建分支 git checkout -b branchname #查看分支 git branch -a #带*的是当前的 #切换分支 $ git checkout -b zhanghanlun origin/zhanghanlun #切换到origin/zhanghanlun分支命令本地分支为”zhanghanlun” 合并分支 $git status #添加到暂存区 $git add . #提交 $git commit -m \"初始化\" 切到主分支 $git branch #切换到主分支 $git checkout master #branchname分支合并到主分支 $git merge branchname #本地master分支推送到push $git push 本地子分支推动到云端 #origin 远端的意思 当前分支推送到远端 branchname分支中 $git push -u origin branchname 忽略不必要的文件 gitignore不生效.gitignore只能忽略原来没有被跟踪的文件，因此跟踪过的文件是无法被忽略的。因此在网页上可以看到target等目录的存在。 解决方法就是先把本地缓存删除（改变成未track状态），然后再提交: $git rm -r --cached . $git add . $git commit -m 'add .gitignore file' "},"docs/git/git相关工具.html":{"url":"docs/git/git相关工具.html","title":"Git相关工具","keywords":"","body":"工具 tortoisegit 安装后遇到问题 换成 ssh自带的 右键--小乌龟---settings--network--修改ssh client为git的ssh.exe ssh.exe 在git的bin目录 "},"docs/git/windows配置过个git客户端.html":{"url":"docs/git/windows配置过个git客户端.html","title":"Windows配置过个Git客户端","keywords":"","body":"生成秘钥 ssh-keygen -t rsa -C \"wjw_595@126.com\" 把公钥配置到 相应服务器 比如 gitee.com 把私钥拷贝到 C:/Users/你的用户名/.ssh git config --global user.name \"wjw_595\" git config --global user.email \"wjw_595@126.com\" 配置config ssh -T git@github.com "},"docs/git/配置多个ssh秘钥.html":{"url":"docs/git/配置多个ssh秘钥.html","title":"配置多个Ssh秘钥","keywords":"","body":"生成秘钥 ssh-keygen -t rsa -C wjw_595@126.com 取不同的名称： 如： id_rsa_github,id_rsa_gitee 秘钥拷贝到 .ssh 文件下 添加公钥 公钥添加到相应的服务器 添加 config文件(核心) Host gitlab.com HostName gitlab.com PreferredAuthentications publickey IdentityFile ~/.ssh/id_rsa_gitlab # github Host github.com HostName github.com PreferredAuthentications publickey IdentityFile ~/.ssh/id_rsa_github # gitee Host gitee.com HostName gitee.com PreferredAuthentications publickey IdentityFile ~/.ssh/id_rsa 测试 ssh -T git@gitee.com ssh -T git@github.com ssh -T git@gitlab.com "},"docs/git/配置秘钥.html":{"url":"docs/git/配置秘钥.html","title":"配置秘钥","keywords":"","body":"配置秘钥 linux安装配置git 安装 安装git: sudo yum install git 配置git账号 git config --global user.name \"git的用户名\" git config --global user.email \"git的邮箱\" 生成秘钥 ssh-keygen -t rsa -C \"git的邮箱\" 存放目录 /root/.ssh/id_rsa.pub 进入对应的网站配置秘钥 测试 ssh -T git@github.com window配置git秘钥 "},"docs/go语言/go环境安装-win.html":{"url":"docs/go语言/go环境安装-win.html","title":"Go环境安装 Win","keywords":"","body":"官网 安装 安装在c盘 不然后面运行会报错 go version 配置环境变量 在任意盘里新建文件夹GoWorks，里面再新建三个文件夹： bin、src、pkg GOPATH配置： 查看环境变量 go env 代理 #开启go module： go env -w GO111MODULE=on #设置代理： go env -w GOPROXY=https://goproxy.io,direct 查看效果：go env 项目下 go mod init 然后 go build(在当前目录生成) go install 在GOPATH/bin目录生成 go. go mod ,goland参考下面，go mod 相当于下载依赖包 （go mod init） https://www.jianshu.com/p/c6605c89e5b3 代理参考： https://blog.csdn.net/qq_35941092/article/details/104986253 "},"docs/go语言/开发环境.html":{"url":"docs/go语言/开发环境.html","title":"开发环境","keywords":"","body":"工具：goland https://download.jetbrains.com/go/goland-2019.2.3.exe 破解补丁： http://c.biancheng.net/uploads/course/go/Goland_Crack_Sinicization.zip 破解教程：https://www.cnblogs.com/Golanguage/p/12297650.html 入门使用 http://c.biancheng.net/view/6170.html https://blog.csdn.net/weixin_42094659/article/details/104017513 "},"docs/go语言/编译项目.html":{"url":"docs/go语言/编译项目.html","title":"编译项目","keywords":"","body":"go build在当前目录就可以找到可执行的gopro1.exe文件，如果是go install 会在bin目录下出现gopro1.exe 在windows上安装go的时候，需要设置GOROOT和GOPATH变量，GOROOT就是go运行程序的目录，GOPATH就是源码的目录。 在windows变量继承的分割符是“;”（分号） 在cmd下设置临时变量，把我们的代码目录加入到变量 set GOPATH=C:\\project\\gopro1:C:\\gopath cd /d C:\\project\\gopro1 go install gopro1 或者 go build gopro1 "},"docs/grafana/grafana嵌入其他项目.html":{"url":"docs/grafana/grafana嵌入其他项目.html","title":"Grafana嵌入其他项目","keywords":"","body":"本文安装环境CentOS7.x，版本Grafana-5.4.3 Web项目中我使用iframe直接嵌套进去的 但是浏览器缓存清除了或者session失效了，每次进入Web页面看Grafana的时候就需要重新登录，在官方社区查找，并没有太好的执行办法，最后决定把Grafana设置成匿名登录： 修改/etc/grafana/grafana.ini目录下的默认配置文件内容： 然后重启grafana服务（systemctl restart grafana-server）就可以。 "},"docs/idea/MybatisCodeHelper 插件激活.html":{"url":"docs/idea/MybatisCodeHelper 插件激活.html","title":"MybatisCodeHelper 插件激活","keywords":"","body":"https://pan.baidu.com/s/1P1A5kBxah7KOGqGqpeEUEw 提取码：1tmx ：网盘工具中也有 插件复制到 D:\\idea202001\\IntelliJ IDEA 2020.1\\plugins 如：不可以，从磁盘安装 激活： 激活方法：IDEA顶部菜单：Tools -> MybatisCodeHelper -> Activation -> OfflineActivation，在offline key框输入 任意字符串 https://blog.csdn.net/cdypa/article/details/106922272 mybatis-log 破解 下载地址 https://github.com/Link-Kou/intellij-mybaitslog "},"docs/idea/idea-moudle目录结构.html":{"url":"docs/idea/idea-moudle目录结构.html","title":"Idea Moudle目录结构","keywords":"","body":"idea目录结构 structure project Modules Name：项目名称 Souces：这里对Module的开发目录进行文件夹分类，就是说这个module里有什么内容，说明了不同性质的内容放在哪里。 注意，这些不同内容的标记代表了一个标准Java工程的各项内容，IntelliJ就是根据这些标记来识别一个Java工程的各项内容的，比如，它会用javac去编译标记为Sources的源码，打包的时候会把标记为Resources的资源拷贝到jar包中，并且忽略标记为Exluded的内容。左边显示的是在选中内容的预览。 Paths：为模块配置编译器输出路径，还可以指定与模块关联的外部JavaDocs和外部注释的位置。 Dependencies：在此选项卡上，您可以定义模块SDK并形成模块依赖关系列表。 Source 对module的开发目录进行文件夹分类，以让idea明白怎么去对待他们，明确哪些是存放源代码的文件夹，哪些是存放静态文件的文件夹，哪些是存放测试代码的文件夹，哪些是被排除编译的文件夹。 Language level：语言级别列表，使用此列表为模块选择Java语言级别。可用选项对应于JDK版本。 Sources：源代码存放的文件，蓝色。 Tests：设置测试代码存放的文件件，绿色。 Resources：一般对应着Sources文件，一般放配置文件，如：log4j.properties，application.yml。 Test Resources：这个对应着Tests文件夹，存放着Tests代码的配置文件。 Excluded：设置配出编译检查的文件，例如我们在project模块设置的out文件夹。 Paths Compiler output：编译输出路径。 Inherit project compile output path：继承项目编译输出路径 选择此选项以使用为项目指定的路径。即上面在Project选项中设置的out文件路径。 Use module compile output path:使用模块编译输出路径。 Output path：编译输出路径。 Test output path：测试代码编译输出路径。 Exclude output paths： 排除输出路径，选中此复选框可以排除输出目录。 JavaDoc：使用可用控件组合与模块关联的外部JavaDocs存储位置的列表。 External Annotations：外部注释。使用新 和删除 管理与模块关联的外部注释的位置（目录）列表。 Dependencies 在此选项卡上，您可以定义模块SDK并形成模块依赖关系列表。 Module SDK：模块SDK，选择模块SDK。 （要将项目SDK与模块相关联，请选择Project SDK。请注意，如果稍后更改了项目SDK，模块SDK将相应更改。 如果所需SDK不在列表中，请单击“ 新建”，然后选择所需的SDK类型。然后，在打开的对话框中，选择SDK主目录，然后单击确定。 要查看或编辑所选SDK的名称和内容，请单击编辑。（SDK页面将打开。） 依赖列表(勾选表示依赖会传递，即引用该modules的modules也会拥有此依赖) Libraries 在此选项卡上，您可以定义模块SDK并形成模块依赖关系列表。 Facets 表示这个 module 有什么特征，比如 Web，Spring 和 Hibernate 等； Artifacts Artifact 是 maven 中的一个概念，表示某个 module 要如何打包，例如 war exploded、war、jar、ear 等等这种打包形式； 一个 module 有了 Artifacts 就可以部署到应用服务器中了！ 在给项目配置 Artifacts 的时候有好多个 type 的选项，exploed 是什么意思？ explode 在这里你可以理解为展开，不压缩的意思。也就是 war、jar 等产出物没压缩前的目录结构。建议在开发的时候使用这种模式，便于修改了文件的效果立刻显现出来。默认情况下，IDEA 的 Modules 和 Artifacts 的 output 目录 已经设置好了，不需要更改， 打成 war 包 的时候会自动在 WEB-INF 目录 下生产 classes 目录 ，然后把编译后的文件放进去。 SDKS 系统开发工具 ，全局 SDK 配置 。 Global libraries 全局类库，可以配置一些常用的类库。 Problems 问题，在项目异常的时候很有用，可以根据提示进行项目修复（FIXED）。 idea的部署方式 1.编译，IDEA在保存/自动保存后不会做编译，不像Eclipse的保存即编译，因此在运行server前会做一次编译。编译后class文件存放在指定的module编译输出目录下。 2.根据artifact中的设定对目录结构进行创建； 3.拷贝web资源的根目录下的所有文件到artifact的目录下； 4.拷贝编译输出目录下的classes目录到artifact下的WEB-INF下； 5.拷贝lib目录下所需的jar包到artifact下的WEB_INF下； 6.运行server，运行成功后，如有需要，会自动打开浏览器访问指定url。 "},"docs/idea/idea多模块创建.html":{"url":"docs/idea/idea多模块创建.html","title":"Idea多模块创建","keywords":"","body":"idea 创建多模块依赖Maven项目_项目间的依赖设置 https://blog.csdn.net/qq_27435059/article/details/86617581 https://blog.csdn.net/wnf2018/article/details/80655153?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.control&dist_request_id=&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.control 导入多个项目的 先创建一个 empty project 然后导入 moudle "},"docs/idea/idea实现docker远程部署.html":{"url":"docs/idea/idea实现docker远程部署.html","title":"Idea实现Docker远程部署","keywords":"","body":"idea-dockerfile https://my.oschina.net/wuweixiang/blog/2874064 idea： docker-compose https://blog.csdn.net/boling_cavalry/article/details/100064934 正确的： https://www.jb51.net/article/196708.htm "},"docs/idea/idea快捷键.html":{"url":"docs/idea/idea快捷键.html","title":"Idea快捷键","keywords":"","body":"常用快捷键 侧边栏 ctrl+1 方法实现 ctrl+alt+b ：跳到实现 ctrl+b:跳到接口 跳到接口 ctrl+u ：回到接口 ctrl + h：类的继承结构图 导入依赖 alt+enter 导入依赖 ，配置实现 鼠标放在对应的类上 查询 ctrl+shift+n 查询文件 ctrl+n 查询java ctrl+shift+R 全局查找 页面查找 ctrl+f ctrl+shift+f 替换 ctrl+r 返回上一步 ctrl+alter+方向键 返回上一步 最近浏览 ctrl+e 最新浏览的 Ctrl+Shift+E，最近更改的文件 查看类中方法 alt+7 类中方法（左下角 structure） 到达指定行 ctrl+g 到达指定行 格式化 ctrl+alt+L是格式化 调试 f7是进入 f8 单步 f9 下一个断点 ctrl+shift+f8 重新编译部署 Ctrl+shift+F9 重新编译 部署 jrebel http://www.likecs.com/show-112379.html idea自带： https://www.jianshu.com/p/f658fed35786 复制行 Ctrl+D，复制行 idea生成结构树 IDEA生成结构树 在写文档的时候，想把项目输出成文档树的形式，可以使用以下命令 tree >> D:/tree.txt 只有文件夹 tree /f >> D:/tree.txt 包括文件夹和文件 移动快捷键 Idea 对选中的多行代码上下左右移动 一、选中代码 二、代码右移：TAB键 三、代码左移：shift+TAB键 四、代码上移：shift+alt +方向键上 五、代码下移：shift+alt +方## 标题向键下 Idea 整理代码 Shift + Ctrl + F Ctrl + Alt + L 大小写转换 ctr+shift+u 结果如下： D:. ├─.idea │ └─inspectionProfiles ├─etc │ └─sql 附件参考 Ctrl+Shift + Enter，语句完成 “！”，否定完成，输入表达式时按 “！”键 Ctrl+E，最近的文件 Ctrl+Shift+E，最近更改的文件 Shift+Click，可以关闭文件 Ctrl+[ OR ]，可以跑到大括号的开头与结尾 Ctrl+F12，可以显示当前文件的结构 Ctrl+F7，可以查询当前元素在当前文件中的引用，然后按 F3 可以选择 Ctrl+N，可以快速打开类 Ctrl+Shift+N，可以快速打开文件 Alt+Q，可以看到当前方法的声明 Ctrl+P，可以显示参数信息 Ctrl+Shift+Insert，可以选择剪贴板内容并插入 Alt+Insert，可以生成构造器/Getter/Setter等 Ctrl+Alt+V，可以引入变量。例如：new String(); 自动导入变量定义 Ctrl+Alt+T，可以把代码包在一个块内，例如：try/catch Ctrl+Enter，导入包，自动修正 Ctrl+Alt+L，格式化代码 Ctrl+Alt+I，将选中的代码进行自动缩进编排，这个功能在编辑 JSP 文件时也可以工作 Ctrl+Alt+O，优化导入的类和包 Ctrl+R，替换文本 Ctrl+F，查找文本 Ctrl+Shift+Space，自动补全代码 Ctrl+空格，代码提示（与系统输入法快捷键冲突） Ctrl+Shift+Alt+N，查找类中的方法或变量 Alt+Shift+C，最近的更改 Alt+Shift+Up/Down，上/下移一行 Shift+F6，重构 - 重命名 Ctrl+X，删除行 Ctrl+D，复制行 Ctrl+/或Ctrl+Shift+/，注释（//或者/**/） Ctrl+J，自动代码（例如：serr） Ctrl+Alt+J，用动态模板环绕 Ctrl+H，显示类结构图（类的继承层次） Ctrl+Q，显示注释文档 Alt+F1，查找代码所在位置 Alt+1，快速打开或隐藏工程面板 Ctrl+Alt+left/right，返回至上次浏览的位置 Alt+left/right，切换代码视图 Alt+Up/Down，在方法间快速移动定位 Ctrl+Shift+Up/Down，向上/下移动语句 F2 或 Shift+F2，高亮错误或警告快速定位 Tab，代码标签输入完成后，按 Tab，生成代码 Ctrl+Shift+F7，高亮显示所有该文本，按 Esc 高亮消失 Alt+F3，逐个往下查找相同文本，并高亮显示 Ctrl+Up/Down，光标中转到第一行或最后一行下 Ctrl+B/Ctrl+Click，快速打开光标处的类或方法（跳转到定义处） Ctrl+Alt+B，跳转到方法实现处 Ctrl+Shift+Backspace，跳转到上次编辑的地方 Ctrl+O，重写方法 Ctrl+Alt+Space，类名自动完成 Ctrl+Alt+Up/Down，快速跳转搜索结果 Ctrl+Shift+J，整合两行 Alt+F8，计算变量值 Ctrl+Shift+V，可以将最近使用的剪贴板内容选择插入到文本 Ctrl+Alt+Shift+V，简单粘贴 Shift+Esc，不仅可以把焦点移到编辑器上，而且还可以隐藏当前（或最后活动的）工具窗口 F12，把焦点从编辑器移到最近使用的工具窗口 Shift+F1，要打开编辑器光标字符处使用的类或者方法 Java 文档的浏览器 Ctrl+W，可以选择单词继而语句继而行继而函数 Ctrl+Shift+W，取消选择光标所在词 Alt+F7，查找整个工程中使用地某一个类、方法或者变量的位置 Ctrl+I，实现方法 Ctrl+Shift+U，大小写转化 Ctrl+Y，删除当前行 Shift+Enter，向下插入新行 psvm/sout，main/System.out.println(); Ctrl+J，查看更多 Ctrl+Shift+F，全局查找 Ctrl+F，查找/Shift+F3，向上查找/F3，向下查找 Ctrl+Shift+S，高级搜索 Ctrl+U，转到父类 Ctrl+Alt+S，打开设置对话框 Alt+Shift+Inert，开启/关闭列选择模式 Ctrl+Alt+Shift+S，打开当前项目/模块属性 Ctrl+G，定位行 Alt+Home，跳转到导航栏 Ctrl+Enter，上插一行 Ctrl+Backspace，按单词删除 Ctrl+\"+/-\"，当前方法展开、折叠 Ctrl+Shift+\"+/-\"，全部展开、折叠 Ctrl+F2，停止 Alt+Shift+F9，选择 Debug Alt+Shift+F10，选择 Run Ctrl+Shift+F9，编译 Ctrl+Shift+F10，运行 Ctrl+Shift+F8，查看断点 F8，步过 F7，步入 Shift+F7，智能步入 Shift+F8，步出 Alt+Shift+F8，强制步过 Alt+Shift+F7，强制步入 Alt+F9，运行至光标处 Ctrl+Alt+F9，强制运行至光标处 F9，恢复程序 Alt+F10，定位到断点 Ctrl+F8，切换行断点 Ctrl+F9，生成项目 Alt+1，项目 Alt+2，收藏 Alt+6，TODO Alt+7，结构 Ctrl+Shift+C，复制路径 Ctrl+Alt+Shift+C，复制引用，必须选择类名 Ctrl+Alt+Y，同步 Ctrl+~，快速切换方案（界面外观、代码风格、快捷键映射等菜单） Shift+F12，还原默认布局 Ctrl+Shift+F12，隐藏/恢复所有窗口 Ctrl+F4，关闭 Ctrl+Shift+F4，关闭活动选项卡 Ctrl+Tab，转到下一个拆分器 Ctrl+Shift+Tab，转到上一个拆分器 【重构】 Ctrl+Alt+Shift+T，弹出重构菜单 Shift+F6，重命名 F6，移动 F5，复制 Alt+Delete，安全删除 Ctrl+Alt+N，内联 【查找】 Ctrl+F，查找 Ctrl+R，替换 F3，查找下一个 Shift+F3，查找上一个 Ctrl+Shift+F，在路径中查找 Ctrl+Shift+R，在路径中替换 Ctrl+Shift+S，搜索结构 Ctrl+Shift+M，替换结构 Alt+F7，查找用法 Ctrl+Alt+F7，显示用法 Ctrl+F7，在文件中查找用法 Ctrl+Shift+F7，在文件中高亮显示用法 【VCS】 Alt+~，VCS 操作菜单 Ctrl+K，提交更改 Ctrl+T，更新项目 Ctrl+Alt+Shift+D，显示变化 Control+Shift+F9 行手工免启动快速更新 　一、Ctrl+N 　　1、这个快捷键和eclipse中的ctrl+shift+R是类似的，我们使用之后就可以利用类名来找到类文件 　　2、除此之外我们在使用这个快捷键搜索类名的时候也能够对我们的搜索内容自动记性匹配 　　3、有些系统中存在的类我们也可以找到，自己写的类也会显示在搜索的结果中，因此使用这种方法搜索出来的结果比较全面 　　4、一般在匹配的时候系统会优先选择我们自己编写的类 　　二、Ctrl+Shift+N 　　这个安装是使用文件名来进行搜索，因此在搜索的时候只搜索类似的类，但是是可以匹配所有的文件的 　　三、Ctrl+H 　　想要查看类继承关系的用户就可以使用这个快捷键了！搜索出来会显示它的子类 　　四、Ctrl+Alt+B 　　使用：Ctrl+B可以看见其中的父类以及定义的方法，还可以使用ctrl+左键来代替。但是这样的方法不能看见put方法，因此我们最好的解决方法就是使用：Ctrl+Alt+B快捷键，这样就能查找到hashmap中的put方法了！ 　　五、Alt+F7 　　这个快捷键比较特殊，它是用来查找类和方法在哪里被使用的，功能和eclipse中的ctrl+shif+H相似，但是查找速度非常的快 　　六、Ctrl+F/Ctrl+Shift+F 　　和eclipse中的ctrl+H功能一样，我们使用ctrl+F按键之后就可以在整个页面中查找，但是若是使用Ctrl+Shift+F 就是在整个intellij idea中查找。在全局中查找时我们可以明显看见它的查找速度是优于其他的编译器的 　　七、Shift+Shift 　　若是你不能清楚的知道自己查找内容的类别，我们可以使用：Shift+Shift 来查找，它可以查看其中的任意文件，即使你写了一个功能为hello，这样我们在java/js等等文件中都有hello，但是只要使用这个功能还是可以快速的将它从文件夹中找到！ "},"docs/idea/idea插件.html":{"url":"docs/idea/idea插件.html","title":"Idea插件","keywords":"","body":"插件官网：https://plugins.jetbrains.com/plugin/7654-gsonformat/versions Maven Helper：排查maven依赖冲突神器，强力推荐！ Alibaba Java Coding Guidelines:阿里巴巴编程规范 CamelCase：驼峰命名工具，SHIFT + ALT + U可以切换 Free Mybatis plugin：免费版mybatis插件，Mapper.java与Mapper.xml之间跳转 Rainbow Brackets： 彩虹代码块，使代码更清晰 VisualVM Launcher： 使用visualVM启动程序 pojo to json: json转换工具 RestfulToolkit：restfull工具 Convert to JSON 功能，代码中右键类名即可 MyBatis Log Plugin 打印mybatis的sql jclasslib bytecode viewer ：反编译工具 Codota ：语法学习，智能提示 Auto filling Java call arguments ：自动填充参数 Alt+Enter 组合键，调出 \"Auto fill call parameters\" GenerateO2O、GenerateAllSetter ：a--b自动跳出set Rainbow Brackets ：代码块 FindBugs SequenceDiagram ：安装完成后，在某个类的某个函数中，右键 --> Sequence Diagaram 即可调出。 Stack trace to UML ：打开方式 Analyze > Open Stack trace to UML plugin + Generate UML diagrams from stacktrace from debug save action ：自动保存，和google-java-format一块使用 Grep Console：日志显示不同的颜色 CodeGlance ：CodeGlance是一款代码编辑区缩略图插件：可以设置位置 RestfulToolkit：方法路径 Json Parser：json 转换工具 aiXcode ：智能小助手 阿里代码规约检测：Alibaba Java Coding Guidelines 自动生成序列图插件：SequenceDiagram 快捷键提示工具：Key promoter X 代码注解插件： Lombok 代码生成工具：CodeMaker 代码质量检查工具：SonarLint 单元测试测试生成工具：JUnitGenerator Mybatis 工具：Free Mybatis plugin JSON转领域对象工具：GsonFormat 字符串工具：String Manipulation Redis可视化：Iedis K8s工具：Kubernetes 中英文翻译工具：Translation 彩虹颜色括号：Rainbow Brackets google-java-format 和 Save Actions translation：翻译 pojo to json--对象转json （接口调试，参数） 右键对象名：pojo to json gsonFormat --别人的json转pojo ：类里右键--generate--gsonFormat restfultool替代RestfulToolkit（2020不能用） gsonformat Alt + S (win) （2020） https://plugins.jetbrains.com/plugin/7654-gsonformat/versions Java Stream Debugger "},"docs/idea/jrebel热部署破解.html":{"url":"docs/idea/jrebel热部署破解.html","title":"Jrebel热部署破解","keywords":"","body":"下载安装JRebel IDEA 依次打开 File | Settings | Plugins → 搜索JRebel进行安装并重启IDEA 破解服务器 https://github.com/ilanyu/ReverseProxy/releases/latest docker pull ilanyu``/golang-reverseproxy docker run --name jrebel -d --restart=always -p 7777:8888 ilanyu/golang-reverseproxy //更新docker docker container update --restart=always 容器名 生成guid https://www.guidgen.com/ 激活地址 http://1.116.208.30:7777/{ GUID } help->jrebel激活 激活后一定要手动切换到离线模式，可离线180天，可随时重新点下“Renew Offline Seat”刷新激活周期，180天后激活状态会重新刷新 。 启动之前需要添加rebel.xml（你要热部署哪个项目就直接勾选，会自动为你进行配置，rebel.xml里默认配置了两个路径，作用为监控变化） Shift+Ctrl+Alt+/ Ctrl + Shift + F9 "},"docs/idea/代码自动补齐.html":{"url":"docs/idea/代码自动补齐.html","title":"代码自动补齐","keywords":"","body":" 进入 settings --> Editor --> Live Templates， 点击 ”+“ 号 选择 Template Group 输入名称（我这里输入是“user” 选中“user”，点击右边的“+”号，选择 Live Template 代码（模板可自行定义）： 上面方框：sw/swi create switch/case block switch(object){ case OBJECT: break; default: break; } 勾选 Java，点击 OK 即可 "},"docs/idea/热部署.html":{"url":"docs/idea/热部署.html","title":"热部署","keywords":"","body":"devtools 参考： https://www.cnblogs.com/liu2-/p/9118393.html https://blog.csdn.net/qq_24195023/article/details/95049948 或 jrebel https://www.jb51.net/article/174685.htm 需要启动代理服务器：可以部署在服务器上 "},"docs/linux命令/centos7/centos7个版本区别.html":{"url":"docs/linux命令/centos7/centos7个版本区别.html","title":"Centos7个版本区别","keywords":"","body":" wiki "},"docs/linux命令/centos7/centos常用技巧.html":{"url":"docs/linux命令/centos7/centos常用技巧.html","title":"Centos常用技巧","keywords":"","body":"查看版本 cat /etc/redhat-release ifconfig安装包 yum install net-tools 挂载光盘镜像 mkdir /mnt/dvd mount -o loop /root/CentOS-7-x86_64-Everything-1810.iso /mnt/dvd 卸载： umount /mnt/cdrom http://mirrors.163.com/centos/7.8.2003/os/x86_64/Packages/ centos相关的包 注意： centos7 自带python2.7 不能卸载，yum是用python2,7写的 ssh连接自动断开 $ vi /etc/ssh/sshd_config #找到 ClientAliveInterval 0 ClientAliveCountMax 3 #修改为 ClientAliveInterval 60 ClientAliveCountMax 5 #重启 systemctl restart sshd 更新yum源 centos7 yum makecache：更新缓存 报错 There are no enabled repos. 第一步： curl -o /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-7.repo 第二步：yum makecache 或yum update 压缩 zip -r file.zip file/ "},"docs/linux命令/centos7/防火墙iptables.html":{"url":"docs/linux命令/centos7/防火墙iptables.html","title":"防火墙Iptables","keywords":"","body":"CentOS7中使用iptables 1、关闭firewall： 2、安装iptables防火墙 安装 yum install iptables-services 编辑防火墙配置文件 vi /etc/sysconfig/iptables 关闭SELINUX vi /etc/selinux/config SELINUX=enforcing #注释掉 SELINUXTYPE=targeted #注释掉 SELINUX=disabled #增加 setenforce 0 #使配置立即生效 "},"docs/linux命令/extundelete恢复工具.html":{"url":"docs/linux命令/extundelete恢复工具.html","title":"Extundelete恢复工具","keywords":"","body":"extundelete 恢复工具 查看磁盘： df -Th extundelete 对 ext3 与 ext4 文件系统都有效 安装 下载：http://sourceforge.net/projects/extundelete/ wget https://nchc.dl.sourceforge.net/project/extundelete/extundelete/0.2.4/extundelete-0.2.4.tar.bz2 #依赖包 #离线 可以http://www.rpmfind.net/linux/rpm2html/search.php?下载rpm rpm -ivh --nodeps --force xxx（强制安装） #加上 --nodeps 属性，不考虑依赖关系 #--replacefiles 属性 yum -y install gcc+ gcc-c++ e2fsprogs.x86_64 e2fsprogs-devel.x86_64 e2fsprogs-libs #解压 tar -jxvf extundelete-0.2.4.tar.bz2 cd extundelete-0.2.4 ./configure #生成 Makefile文件:./configure 可以指定安装位置./configure --prefix=/usr/local/java/extundelete #编译并安装 make & make install #进入extundelete安装目录:./extundelete -v，图下安装成功 默认在/usr/local/bin 目录下 默认安装： extundelete -v 恢复 前提：如果确定文件被误删，在没有备份的情况下请马上对分区实施写入保护，（预防新的写入覆盖误删的块数据）**mount -o remount,ro /dev/sdb1或者直接umount /dev/sdb1/解挂载目录，*df -h命令可以看出你的数据目录挂载在那个分区下（fdisk磁盘管理）*** 恢复指定文件： extundelete /dev/sdb1 --inode 2 参考： https://www.cnblogs.com/zhangan/p/10917780.html extundelete /dev/sdb1 --inode 2 extundelete /dev/sdb1 --restore-inode 13 根据inode信息进行文件恢复 extundelete /dev/sdb1 --restore-file apache-tomcat-8.0.24.tar.gz 根据文件名进行文件修复 目录恢复操作过程 extundelete /dev/sdb1 --restore-directory /tomcat-app1 根据目录名称恢复目录 4.重新挂载磁盘目录或者reboot重启都是ok的。 "},"docs/linux命令/linux常用技巧.html":{"url":"docs/linux命令/linux常用技巧.html","title":"Linux常用技巧","keywords":"","body":"linux常用技巧 rpm强制升级 --nodeps就是安装时不检查依赖关系 ﻿rpm -ivh --replacefiles --force --nodeps 在做RPM软件适配的时候，经常会出现需要自己安装额外的安装包，包名中的版本号不一致也会出现提示，要安装统一版本号的软件包，并且还会出现对更新软件包的依赖，在已经存在软件包的情况下，按需升级软件包，可以使用升级安装： rpm -Uvh *.rpm 1 如果升级出错，可以执行强制安装实现对软件包的版本更新： rpm -ivh --replacefiles --force --nodeps *.rpm 1 如果想要强制卸载某软件包，可以使用如下命令： rpm -e *.rpm --nodeps rpm -q 软件包名 whereis influxdb ls: /usr/bin/ls /usr/share/man/man1/ls.1.gz 再使用rpm -qf查询系统文件属于哪个软件包(file) rpm -qf /usr/bin/ls rpm -qa | grep xxx -qa代表query，a代表all rpm -qa|grep influxdb 1 注意：在有很多依赖时，不推荐强制卸载，如果非要试一试，要做好系统备份啊~~ 另外，一个使用的查看软件包安装脚本的命令： rpm --script -qp *.rpm [root@localhost ~]# netstat -ntlp //查看当前所有tcp端口· [root@localhost ~]# netstat -ntulp |grep 80 //查看所有80端口使用情况· [root@localhost ~]# netstat -an | grep 3306 //查看所有3306端口使用情况· [root@localhost ~]# netstat -nlp |grep LISTEN //查看当前所有监听端口· netstat -nupl (UDP类型的端口) netstat -ntpl (TCP类型的端口) netstat -anp 显示系统端口使用情况 列出谁在使用某个端口 lsof -i :3306 全显示 netstat -tunlp|grep https://jingyan.baidu.com/article/656db9183861cde381249c87.html 压缩解压缩 zip -r file.zip file/ https://www.cnblogs.com/mingyue5826/p/14281153.html https://www.cnblogs.com/wangluochong/p/7194037.html 查看隐藏文件 ls -al lsof详解 https://blog.csdn.net/kozazyh/article/details/5495532 列出谁在使用某个端口 lsof -i :3306 列出所有的网络连接 lsof -i 列出所有tcp 网络连接信息 lsof -i tcp 查看谁正在使用某个文件 lsof /filepath/file 列出某个程序所打开的文件信息 lsof -c mysql lsof -u username 备注: -u 选项，u其实是user的缩写 linux自建回收站 https://www.cnblogs.com/llxx07/p/6515943.html 当前目录搜索 查询文本中内容 grep 递归搜索文本内容 r递归、 n 行号 # grep -rn \"ipmitool\" i 不区分大小写、r n grep -irn 3306 ./ l显示文件名 grep -ilr 3306 ./ 替换 grep -irn \"192.168.0.1\" ./ grep -irl \"192.168.0.1\" ./ | xargs sed -i \"s/192.168.0.1/192.168.0.2/g\" grep -rn \"localhost:3000\" * grep时加入了-Hna，其分别输出文件路径，行号，及对应的文本内容： grep -rn erlsrv /etc 目录 RemoteWare Server grep -rn \"RemoteWare \" * grep -i pattern files：不区分大小写地搜索,默认情况区分大小写 grep -l pattern files：只列出匹配的文件名 grep -L pattern files：列出不匹配的文件名 grep -w pattern files：只匹配整个单词，而不是字符串的一部分（如匹配\"magic\"，而不是\"magical\"） grep -C number pattern files：匹配的上下文分别显示[number]行 grep pattern1 | pattern2 files：显示匹配 pattern1 或 pattern2 的行 grep pattern1 files | grep pattern2：显示既匹配 pattern1 又匹配 pattern2 的行 明确要求搜索子目录：grep -r 或忽略子目录：grep -d skip 查磁盘信息 df -Th [root@xhrmyy_it system]# df -Th 文件系统 类型 容量 已用 可用 已用% 挂载点 devtmpfs devtmpfs 3.8G 0 3.8G 0% /dev tmpfs tmpfs 3.8G 8.0K 3.8G 1% /dev/shm tmpfs tmpfs 3.8G 389M 3.4G 11% /run tmpfs tmpfs 3.8G 0 3.8G 0% /sys/fs/cgroup /dev/mapper/centos_xhrmyy_it-root xfs 50G 12G 39G 24% / /dev/sda1 xfs 1014M 199M 816M 20% /boot /dev/mapper/centos_xhrmyy_it-home xfs 499G 2.1G 497G 1% /home tmpfs tmpfs 773M 4.0K 773M 1% /run/user/42 tmpfs tmpfs 773M 60K 773M 1% /run/user/0 [root@xhrmyy_it system]# df -Th^C fdisk -l vmstat 执行vmstat命令获得系统CPU负载情况,vmstat 2 10表示2秒钟输出一次共输出10组数据 "},"docs/linux命令/rpm包地址.html":{"url":"docs/linux命令/rpm包地址.html","title":"Rpm包地址","keywords":"","body":"http://www.rpmfind.net/linux/rpm2html/search.php?query=e2fsprogs-devel "},"docs/linux命令/shell/$的含义.html":{"url":"docs/linux命令/shell/$的含义.html","title":"$的含义","keywords":"","body":"Shell中的$0、$1、$2的含义 $0 就是你写的shell脚本本身的名字，$1 是你给你写的shell脚本传的第一个参数，$2 是你给你写的shell脚本传的第二个参数 #!/bin/sh echo \"shell脚本本身的名字: $0\" echo \"传给shell的第一个参数: $1\" echo \"传给shell的第二个参数: $2\" bash Test.sh 1 2 shell脚本本身的名字: Test.sh 传给shell的第一个参数: 1 传给shell的第二个参数: 2 shell 编程 http://c.biancheng.net/shell/program/ "},"docs/linux命令/vmware扩容.html":{"url":"docs/linux命令/vmware扩容.html","title":"Vmware扩容","keywords":"","body":"vmware虚拟机扩容 扩展vmware-centos7硬盘空间 关闭Vmware的centos7系统，才能在VMWare菜单中设置需要增加到的磁盘大小 如果这个选项是灰色的，说明此虚拟机建有快照，把快照全部删除再试试! 或者web界面： 选中虚拟机->虚拟机设置->硬盘->实用工具->扩展->设置最大磁盘大小->点击扩展 对新增加的硬盘进行分区、格式化 我们增加了空间的硬盘是 /dev/sda 分区： [root@localhost]# fdisk /dev/sda　　　　 p　　　　　　　查看已分区数量（我看到有两个 /dev/sda1 /dev/sda2） n　　　　　　　新增加一个分区 p　　　　　　　分区类型我们选择为主分区 　　　　　　 分区号输入3（因为1,2已经用过了,sda1是分区1,sda2是分区2,sda3分区3） 回车　　　　　 默认（起始扇区） 回车　　　　　 默认（结束扇区） t　　　　　　　 修改分区类型 　　　　　　 选分区3 8e　　　　　 　修改为LVM（8e就是LVM） w　　　　　 　写分区表 q　　　　　 　完成，退出fdisk命令 使用partprobe 命令 或者重启机器 格式化分区3命令: mkfs.ext3 /dev/sda3 添加新lvm到已有的lvm组，实现扩容 lvm　　　　　　　　　　　　 进入lvm管理 lvm>pvcreate /dev/sda3　　 这是初始化刚才的分区3 lvm>vgextend centos /dev/sda3 将初始化过的分区加入到虚拟卷组centos (卷和卷组的命令可以通过 vgdisplay ) lvm>vgdisplay -v或者vgdisplay查看free PE /Site lvm>lvextend -l+6143 /dev/mapper/centos-root　　扩展已有卷的容量（6143 是通过vgdisplay查看free PE /Site的大小） lvm>pvdisplay 查看卷容量，这时你会看到一个很大的卷了 lvm>quit 　退出 上面只是卷扩容了，下面是文件系统的真正扩容，输入以下命令： CentOS7下面由于使用的是XFS命令: /dev/mapper/centos-root是df -h查看到根目录的挂载点 xfs_growfs /dev/mapper/centos-root 参考文章： https://blog.csdn.net/Wang_Xin_SH/article/details/77872885?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.control&dist_request_id=192a8808-ed95-4e2d-9a6e-d54b687bcbc5&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.control https://blog.csdn.net/zzchances/article/details/89918277 "},"docs/linux命令/挂载.html":{"url":"docs/linux命令/挂载.html","title":"挂载","keywords":"","body":"linux磁盘相关操作 fdisk -l 查看硬盘情况 fdisk划分分区 fdisk 硬盘设备名 --进入fdisk m显示所有命令 n创建分区，w保存所有操作，q取消 t划分不通类型的分区 分区格式化： 再附加一下对硬盘进行格式化的方法： 要把分区格式化成Linux Ext2格式，用： mkext2fs /dev/hda? 要把分区格式化成FAT32格式，用： mkfs.vfat /dev/hda?　 mkfs.ext3 /dev/hdd1 硬盘只有格式化后才可以使用 挂载硬盘 mount/umount df -h --查看挂载点信息 挂载概念简述： 根文件系统之外的其他文件要想能够被访问，都必须通过“关联”至根文件系统上的某个目录来实现，此关联操作即为“挂载”，此目录即为“挂载点”,解除此关联关系的过程称之为“卸载” 1.挂载：根文件系统外通过关联至根文件系统上的某个目录来实现访问 2.挂载点：mount_point，用于作为另一个文件系统的访问入口； (1) 事先存在； (2) 应该使用未被或不会被其它进程使用到的目录； (3) 挂载点下原有的文件将会被隐藏； 挂载; 根目录创建： 文件 mkdir /mnt 挂载：mount /dev/sdb /mnt 卸载： umount /home (卸载) 如目标忙： fuser -km /home/ (终止) 开机启动挂载 如果我们想实现开机自动挂载某设备，只要修改/etc/fstab文件即可 vim /etc/fstab 要挂载的设备或伪文件系统 挂载点 文件系统类型 挂载选项 转储频率 自检次序 UUID=6efb8a23-bae1-427c-ab10-3caca95250b1 /boot xfs defaults 0 0 要挂载的设备或伪文件系统：设备文件、LABEL(LABEL=\"\")、UUID(UUID=\"\")、伪文件系统名称(proc, sysfs) 挂载点：指定的文件夹 挂载选项：defaults 转储频率： 0：不做备份 1：每天转储 2：每隔一天转储 自检次序： 0：不自检 1：首先自检；一般只有rootfs才用1； /etc/fstab和/etc/mtab的区别 /etc/fstab文件的作用: 记录了计算机上硬盘分区的相关信息，启动 Linux 的时候，检查分区的 fsck 命令，和挂载分区的 mount 命令，都需要 fstab 中的信息，来正确的检查和挂载硬盘。 /etc/mtab文件的作用： 先看它的英文是: This changes continuously as the file /proc/mount changes. In other words, when filesystems are mounted and unmounted, the change is immediately reflected in this file. 记载的是现在系统已经装载的文件系统，包括操作系统建立的虚拟文件等；而/etc/fstab是系统准备装载的。 每当 mount 挂载分区、umount 卸载分区，都会动态更新 mtab，mtab 总是保持着当前系统中已挂载的分区信息，fdisk、df 这类程序，必须要读取 mtab 文件，才能获得当前系统中的分区挂载情况。当然我们自己还可以通过读取/proc/mount也可以来获取当前挂载信息 "},"docs/markdown/gitbook使用.html":{"url":"docs/markdown/gitbook使用.html","title":"Gitbook使用","keywords":"","body":"GitBook + Typora + Git https://blog.csdn.net/qq_43528771/article/details/107949010 注意： 安装node 版本（目前测试就这个版本 不然gitbook 卡死） v10.21.0 官网： https://www.npmjs.com/package/gitbook-cli/v/2.3.2 先安装：要安装3.0.0 的 3.2.3初始化有问题 安装 npm install -g gitbook-cli gitbook -V #等待安装完成 npm config set registry \"https://registry.npm.taobao.org\" 安装Calibre（导出pdf） https://calibre-ebook.com/download_windows 测试导出pdf插件的命令行 ebook-convert --version 使用方法 在当前书籍的目录中执行 gitbook pdf 也可以指定目录和文件名 gitbook pdf ./ ./myBook.pdf --log=debug 创建笔记文件夹 在你想要的位置新建一个文件夹，然后打开命令行，cd到这个文件夹下。 gitbook init 执行完后，文件夹里会多两个文件 README.md（书籍的介绍在这个文件里） SUMMARY.md（书籍的目录结构在这里配置） 生成目录插件 gitbook-plugin-summary #安装 npm i gitbook-plugin-summary --save #book.json 笔记根目录 { \"title\" : \"文档库\", \"theme-default\": { \"showLevel\": true }, \"plugins\": [\"summary\",\"toggle-chapters\", \"theme-comscore\"] } #说明 #summary: 自动生成SUMMARY.md文件 #toggle-chapters: 菜单可以折叠 #theme-comscore: 主题插件, 修改标题和表格颜色 gitbook install gitbook build #执行 gitbook serve 参考：https://www.jianshu.com/p/2160f1ba68a0?utm_campaign https://www.npmjs.com/package/gitbook-plugin-toggle-chapters gitbook-plugin-theme-comscore #中文搜索 npm install gitbook-plugin-search-pro --registry=https://registry.npm.taobao.org/ #自动生成菜单 npm i gitbook-plugin-summary --save # expandable-chapters-small npm install gitbook-plugin-expandable-chapters #主题插件 npm -i install gitbook-plugin-theme-comscore #splitter 侧边栏可调节 npm install gitbook-plugin-splitter #其他插件 http://gitbook.zhangjikai.com/plugins.html 踩坑： 运行 gitbook -V或 gitbook init 时一直卡在 Installing GitBook 3.2.3 一、换node 版本 v10.21.0 或： git bash或者win10的terminal来代替CMD 使用 gitbook init book.json 笔记根目录 { \"title\" : \"文档库\", \"theme-default\": { \"showLevel\": true }, \"plugins\": [\"summary\",\"toggle-chapters\", \"theme-comscore\"] } gitbook serve git add . git commit -m 'init' git push -u origin master git subtree push --prefix=_book origin gh-pages #https://wjw595595.github.io/note/ https://baijiahao.baidu.com/s?id=1666708486591555944&wfr=spider&for=pc https://wjw595595.github.io/e-book/ 常用插件： https://segmentfault.com/a/1190000019806829?utm_source=tag-newest 官方文档 http://gitbook.zhangjikai.com/plugins.html "},"docs/markdown/gitbook最新整理.html":{"url":"docs/markdown/gitbook最新整理.html","title":"Gitbook最新整理","keywords":"","body":"gitbook安装 安装 环境要求 nodejs（v10.21.0） gitbook-cli 2.3.2 gitbook:3.2.3 通过npm安装 npm install gitbook-cli -g #gitbook-cli是gitbook的一个命令行工具, 通过它可以在电脑上安装和管理gitbook的多个版本 gitbook -V #等待安装完成 #可以配置淘宝镜像 #npm config set registry https://registry.npm.taobao.org #npm config get registry #预览书籍 http://localhost:4000/ 创建gitbook仓库 目录结构 http://gitbook.zhangjikai.com/structure.html . ├── book.json ├── README.md ├── SUMMARY.md ├── chapter-1/ | ├── README.md | └── something.md └── chapter-2/ ├── README.md └── something.md .gitignore SUMMARY.md（撰写左边导航栏） README.md（简介） book.json（对gitbook基本的配置，有的时候你一个这样的仓库，可能没有该文件，可自行创建） 命令 命令网址 gitbook init #执行完后，文件夹里会多两个文件 #README.md（书籍的介绍在这个文件里） #SUMMARY.md（书籍的目录结构在这里配置） #生成静态网页并运行服务器 _book目录 localhost:4000 gitbook serve 配置（book.json） 配置文档 { \"title\": \"David的笔记\", \"description\": \"David的笔记,java开发的参考手册\", \"author\": \"david wang\", \"language\": \"zh-hans\", \"gitbook\": \"3.2.3\", \"fontState\": { \"size\": \"2\", \"family\": \"sans\", \"theme\": \"night\" }, \"links\": { \"sidebar\": { /* 主页地址*/ \"home\": \"https://wjw595595.github.io/note/\" } }, \"theme-default\": { \"showLevel\": true }, \"plugins\": [ /*自动生成菜单 */ \"summary\", /*侧边栏可移动 */ \"splitter\", /* -:是卸载，卸载原始英文搜索，换中文 */ \"-lunr\", \"-search\", \"search-pro\", /* 菜单折叠 */ \"expandable-chapters\", /* 样式 */ \"theme-comscore\" ], \"pluginsConfig\": { \"search-pro\": { \"cutWordLib\": \"nodejieba\", \"defineWord\": [ \"搜索\" ] } } } { \"title\" : \"文档库\", \"theme-default\": { \"showLevel\": true }, \"plugins\": [\"summary\",\"expandable-chapters\", \"theme-comscore\"] } 常用插件 插件文档 插件用 npm安装 #中文搜索 npm install gitbook-plugin-search-pro --registry=https://registry.npm.taobao.org/ #自动生成菜单 npm install gitbook-plugin-summary # 菜单折叠 npm install gitbook-plugin-expandable-chapters #主题插件 npm install gitbook-plugin-theme-comscore #splitter 侧边栏可调节 npm install gitbook-plugin-splitter #其他插件 http://gitbook.zhangjikai.com/plugins.html 参考文档： http://gitbook.zhangjikai.com/ 插件推荐 https://segmentfault.com/a/1190000019806829?utm_source=tag-newest 和github整合 github创建项目 note 克隆本地 ，在note中创建 gitbook 目录 在note目录 添加配置 book.json 在gitbook中添加笔记 在note目录运行 npm安装相关插件 运行 note目录运行 gitbook serve 提交代码到github git add . git commit -m 'init' git push -u origin master git subtree push --prefix=_book origin gh-pages #https://.github.io// #如：https://wjw595595.github.io/note/ "},"docs/markdown/markdown练习.html":{"url":"docs/markdown/markdown练习.html","title":"Markdown练习","keywords":"","body":"Hello world "},"docs/markdown/typora 标题自动编号.html":{"url":"docs/markdown/typora 标题自动编号.html","title":"Typora 标题自动编号","keywords":"","body":"[toc] typora markdown 标题自动编号 用 .css 文件实现 markdown 文件的标题自动标号。 在 Typora 界面中，点 File -> Preference... -> Open Theme Folder 会打开一个文件夹（如：C:\\Users\\iTom\\AppData\\Roaming\\Typora\\themes），在这里新建一个叫 base.user.css 的文件，内容见下，然后重启 Typora 即可。 序号从一级标题开始的 base.user.css /** initialize css counter */ #write { counter-reset: h1 } h1 { counter-reset: h2 } h2 { counter-reset: h3 } h3 { counter-reset: h4 } h4 { counter-reset: h5 } h5 { counter-reset: h6 } /** put counter result into headings */ #write h1:before { counter-increment: h1; content: counter(h1) \". \" } #write h2:before { counter-increment: h2; content: counter(h1) \".\" counter(h2) \". \" } #write h3:before, h3.md-focus.md-heading:before /** override the default style for focused headings */ { counter-increment: h3; content: counter(h1) \".\" counter(h2) \".\" counter(h3) \". \" } #write h4:before, h4.md-focus.md-heading:before { counter-increment: h4; content: counter(h1) \".\" counter(h2) \".\" counter(h3) \".\" counter(h4) \". \" } #write h5:before, h5.md-focus.md-heading:before { counter-increment: h5; content: counter(h1) \".\" counter(h2) \".\" counter(h3) \".\" counter(h4) \".\" counter(h5) \". \" } #write h6:before, h6.md-focus.md-heading:before { counter-increment: h6; content: counter(h1) \".\" counter(h2) \".\" counter(h3) \".\" counter(h4) \".\" counter(h5) \".\" counter(h6) \". \" } /** override the default style for focused headings */ #write>h3.md-focus:before, #write>h4.md-focus:before, #write>h5.md-focus:before, #write>h6.md-focus:before, h3.md-focus:before, h4.md-focus:before, h5.md-focus:before, h6.md-focus:before { color: inherit; border: inherit; border-radius: inherit; position: inherit; left:initial; float: none; top:initial; font-size: inherit; padding-left: inherit; padding-right: inherit; vertical-align: inherit; font-weight: inherit; line-height: inherit; } 序号从二级标题开始的 /** initialize css counter */ #write,.md-toc-content,.sidebar-content { counter-reset: h2 } h1 , .outline-h1, .md-toc-item.md-toc-h1 { counter-reset: h2 } h2 ,.outline-h2, .md-toc-item.md-toc-h2{ counter-reset: h3 } h3 , .outline-h3, .md-toc-item.md-toc-h3{ counter-reset: h4 } h4 , .outline-h4, .md-toc-item.md-toc-h4{ counter-reset: h5 } h5 , .outline-h5, .md-toc-item.md-toc-h5{ counter-reset: h6 } /** put counter result into headings */ #write h1:before , .outline-h1>.outline-item>.outline-label:before, .md-toc-item.md-toc-h1>.md-toc-inner:before { counter-increment: h1; content: counter(h1) \". \" } /* 使用h1标题时，去掉前两个h1标题的序号，包括正文标题、目录树和大纲 */ /* nth-of-type中的数字表示获取第几个h1元素，请根据情况自行修改。 */ #write h1:nth-of-type(1):before, .outline-h1:nth-of-type(1)>.outline-item>.outline-label:before, .md-toc-item.md-toc-h1:nth-of-type(1)>.md-toc-inner:before, #write h1:nth-of-type(2):before, .outline-h1:nth-of-type(2)>.outline-item>.outline-label:before, .md-toc-item.md-toc-h1:nth-of-type(2)>.md-toc-inner:before{ counter-reset: h1; content: \"\" } #write h2:before , .outline-h2>.outline-item>.outline-label:before, .md-toc-item.md-toc-h2>.md-toc-inner:before { counter-increment: h2; content: counter(h2) \". \" } #write h3:before, h3.md-focus.md-heading:before ,/** override the default style for focused headings */ .outline-h3>.outline-item>.outline-label:before, .md-toc-item.md-toc-h3>.md-toc-inner:before { counter-increment: h3; content: counter(h2) \".\" counter(h3) \". \" } #write h4:before, h4.md-focus.md-heading:before, .outline-h4>.outline-item>.outline-label:before, .md-toc-item.md-toc-h4>.md-toc-inner:before { counter-increment: h4; content: counter(h2) \".\" counter(h3) \".\" counter(h4) \". \" } #write h5:before, h5.md-focus.md-heading:before , .outline-h5>.outline-item>.outline-label:before, .md-toc-item.md-toc-h5>.md-toc-inner:before { counter-increment: h5; content: counter(h2) \".\" counter(h3) \".\" counter(h4) \".\" counter(h5) \". \" } #write h6:before, h6.md-focus.md-heading:before , .outline-h6>.outline-item>.outline-label:before, .md-toc-item.md-toc-h6>.md-toc-inner:before { counter-increment: h6; content: counter(h2) \".\" counter(h3) \".\" counter(h4) \".\" counter(h5) \".\" counter(h6) \". \" } /** override the default style for focused headings */ #write>h3.md-focus:before, #write>h4.md-focus:before, #write>h5.md-focus:before, #write>h6.md-focus:before, h3.md-focus:before, h4.md-focus:before, h5.md-focus:before, h6.md-focus:before { color: inherit; border: inherit; border-radius: inherit; position: inherit; left:initial; float: none; top:initial; font-size: inherit; padding-left: inherit; padding-right: inherit; vertical-align: inherit; font-weight: inherit; line-height: inherit; } "},"docs/markdown/typora配置图床.html":{"url":"docs/markdown/typora配置图床.html","title":"Typora配置图床","keywords":"","body":"https://zhuanlan.zhihu.com/p/137310314 "},"docs/mq/rabbitmq安装docker .html":{"url":"docs/mq/rabbitmq安装docker .html","title":"Rabbitmq安装Docker ","keywords":"","body":"一、获取镜像 指定版本，该版本包含了web控制页面 docker pull rabbitmq:management 二、运行镜像 方式一：默认guest 用户，密码也是 guest docker run -d --hostname my-rabbit --name rabbit -p 15672:15672 -p 5672:5672 rabbitmq:management 方式二：设置用户名和密码 docker run -d --hostname my-rabbit --name rabbit -e RABBITMQ_DEFAULT_USER=user -e RABBITMQ_DEFAULT_PASS=password -p 15672:15672 -p 5672:5672 rabbitmq:management 三、访问url http://localhost:15672/ rabbitmq 启用日志跟踪 docker run -d -p 5672:5672 -p 15672:15672 --name rabbitmq rabbitmq:management docker exec -it rabbitmq bash rabbitmq-plugins enable rabbitmq_tracing "},"docs/mq/rabbit简单认识.html":{"url":"docs/mq/rabbit简单认识.html","title":"Rabbit简单认识","keywords":"","body":""},"docs/mq/消息队列对比.html":{"url":"docs/mq/消息队列对比.html","title":"消息队列对比","keywords":"","body":" 综上，各种对比之后，有如下建议： 一般的业务系统要引入 MQ，最早大家都用 ActiveMQ，但是现在确实大家用的不多了，没经过大规模吞吐量场景的验证，社区也不是很活跃，所以大家还是算了吧，我个人不推荐用这个了； 后来大家开始用 RabbitMQ，但是确实 erlang 语言阻止了大量的 Java 工程师去深入研究和掌控它，对公司而言，几乎处于不可控的状态，但是确实人家是开源的，比较稳定的支持，活跃度也高； 不过现在确实越来越多的公司会去用 RocketMQ，确实很不错，毕竟是阿里出品，但社区可能有突然黄掉的风险（目前 RocketMQ 已捐给 Apache，但 GitHub 上的活跃度其实不算高）对自己公司技术实力有绝对自信的，推荐用 RocketMQ，否则回去老老实实用 RabbitMQ 吧，人家有活跃的开源社区，绝对不会黄。 所以中小型公司，技术实力较为一般，技术挑战不是特别高，用 RabbitMQ 是不错的选择；大型公司，基础架构研发实力较强，用 RocketMQ 是很好的选择。 如果是大数据领域的实时计算、日志采集等场景，用 Kafka 是业内标准的，绝对没问题，社区活跃度很高，绝对不会黄，何况几乎是全世界这个领域的事实性规范。 ActiveMQ：基于JMS（Java Message Service） RabbitMQ：基于AMQP(Advanced Message Queuing Protocol)协议，erlang语言开发，稳定性好 RocketMQ：基于JMS，阿里巴巴产品，目前交由Apache基金会 Kafka：分布式消息系统，高吞吐量 "},"docs/mybatis-plus/mybatis-plus文档.html":{"url":"docs/mybatis-plus/mybatis-plus文档.html","title":"Mybatis Plus文档","keywords":"","body":"mybatis-plus文档 官网: \">https://mp.baomidou.com/> "},"docs/mysql/mysql问题.html":{"url":"docs/mysql/mysql问题.html","title":"Mysql问题","keywords":"","body":"问题一 mysql too many connections 解决方法 mysql -u root -p 进入mysql #查看连接数 show processlist; #查看连接数，可以发现有很多连接处于sleep状态，这些其实是暂时没有用的，所以可以kill掉 show variables like \"max_connections\"; #修改最大连接数 set GLOBAL max_connections=1000; #这个数值指的是mysql在关闭一个非交互的连接之前要等待的秒数，默认是28800s show global variables like 'wait_timeout'; #修改这个数值，这里可以随意，最好控制在几分钟内 set global wait_timeout=300; set global interactive_timeout=500; 修改这个数值，表示mysql在关闭一个连接之前要等待的秒数，至此可以让mysql自动关闭那些没用的连接，但要注意的是，正在使用的连接到了时间也会被关闭，因此这个时间值要合适 批量kill之前没用的sleep连接，在网上搜索的方法对我都不奏效，因此只好使用最笨的办法，一个一个kill 8、select concat('KILL ',id,';') from information_schema.processlist where user='root'; 先把要kill的连接id都查询出来 然后用列模式 kill 掉 "},"docs/nginx/nginx-windows.html":{"url":"docs/nginx/nginx-windows.html","title":"Nginx Windows","keywords":"","body":"安装 http://nginx.org/en/download.html 解压 点击 nginx.exe 访问：80 端口 修改配置文件 conf/nginx.conf，修改默认端口 start nginx 关闭 (1)输入nginx命令 nginx -s stop(快速停止nginx) 或 nginx -s quit(完整有序的停止nginx) (2)使用taskkill taskkill /f /t /im nginx.exe 查找进程 tasklist /fi \"imagename eq nginx.exe\" 负载均衡 nginx -s reload start nginx ./nginx.exe ./nginx #重新启动 ./nginx -s reload 停止 ./nginx -s stop # 或者 ./nginx -s quit #打开日志 ./nginx -s reopen #版本 nginx -v https://blog.csdn.net/zjsfdx/article/details/89787462 nginx 日志访问 https://www.jb51.net/article/92832.htm "},"docs/nginx/nginx相关配置说明.html":{"url":"docs/nginx/nginx相关配置说明.html","title":"Nginx相关配置说明","keywords":"","body":"https://blog.csdn.net/andyzhaojianhui/article/details/78872415 Nginx提供了rewrite指令，用于对地址进行重写，语法规则： 登录后复制 rewrite \"用来匹配路径的正则\" 重写后的路径 [指令]; 登录后复制 我们实现把**/api/upload**重写为**/upload**的功能，在Nginx的配置文件中配置如下内容： 登录后复制 # 上传路径的映射 location /api/upload { proxy_pass http://127.0.0.1:8082; proxy_connect_timeout 600; proxy_read_timeout 600; rewrite \"^/api/(.*)$\" /$1 break; } location / { proxy_pass http://127.0.0.1:10010; proxy_connect_timeout 600; proxy_read_timeout 600; } 登录后复制 首先，我们映射路径是/api/upload，而下面一个映射路径是 / ，根据最长路径匹配原则，/api/upload优先级更高。也就是说，凡是以/api/upload开头的路径，都会被第一个配置处理。 proxy_pass：反向代理，这次我们代理到8082端口，也就是upload-service服务； rewrite \"^/api/(.)$\" /$1 break，路径重写： (1)\"^/api/(.)$\"：匹配路径的正则表达式，用了分组语法就是(.*)，把/api/以后的所有部分当做1组； （2）/$1：重写的目标路径，这里用$1引用前面正则表达式匹配到的分组（组编号从1开始，也就是api），即/api/后面的所有。这样新的路径就是除去/api/以外的所有，就达到了去除/api前缀的目的； break：指令，常用的有2个，分别是：last、break； （1）last：重写路径结束后，将得到的路径重新进行一次路径匹配； （2）break：重写路径结束后，不再重新匹配路径。 "},"docs/nodejs/nodejs-windows安装.html":{"url":"docs/nodejs/nodejs-windows安装.html","title":"Nodejs Windows安装","keywords":"","body":"windows安装 下载 https://nodejs.org/en/ 直接下一步 https://nodejs.org/zh-cn/download/ node -v npm -v 更改 node全局下载路径 npm config set prefix \"D:\\Program Files\\nodejs\\npm_global\" npm config set cache \"D:\\Program Files\\nodejs\\npm-cache\" npm config set registry \"https://registry.npm.taobao.org\" #查看 npm config ls 配置文件：C:\\Users\\admin.npmrc 环境变量path 添加：D:\\Program Files\\nodejs\\npm_global 修改为淘宝镜像 在文件C:\\Users\\admin.npmrc添加 registry=https://registry.npm.taobao.org 全局安装 npm install -g 局部安装：局部安装就是在当前项目中建立包，在当前项目中起作用 npm install 通过nvm-windows安装 https://github.com/coreybutler/nvm-windows/releases 参考：https://www.jianshu.com/p/96f9317db0b5 ​ 第三个：傻瓜安装 #查看 nvm list available #安装 nvm install 10.24.0 #使用 nvm use 10.24.0 #查看 node -v 安装乱码 因为 安装在了 D:\\Program Files ，目录有空格，移动到别的目录修改 文件安装目录的 settings.txt文件 npm安装失败 settings.txt 修改添加地址： node_mirror: https://npm.taobao.org/mirrors/node/ npm_mirror: https://npm.taobao.org/mirrors/npm/ 参考：https://blog.csdn.net/fenfeidexiatian/article/details/96993384 命令 1,nvm nvm list 是查找本电脑上所有的node版本 nvm list 查看已经安装的版本 nvm list installed 查看已经安装的版本 nvm list available 查看网络可以安装的版本 2,nvm install 安装最新版本nvm 3,nvm use ## 切换使用指定的版本node 4,nvm ls 列出所有版本 5,nvm current显示当前版本 6,nvm alias ## 给不同的版本号添加别名 7,nvm unalias ## 删除已定义的别名 8,nvm reinstall-packages ## 在当前版本node环境下，重新全局安装指定版本号的npm包 9,nvm on 打开nodejs控制 10,nvm off 关闭nodejs控制 11,nvm proxy 查看设置与代理 12,nvm node_mirror [url] 设置或者查看setting.txt中的node_mirror，如果不设置的默认是 https://nodejs.org/dist/ 　　nvm npm_mirror [url] 设置或者查看setting.txt中的npm_mirror,如果不设置的话默认的是： https://github.com/npm/npm/archive/. 13,nvm uninstall 卸载制定的版本 14,nvm use [version] [arch] 切换制定的node版本和位数 15,nvm root [path] 设置和查看root路径 16,nvm version 查看当前的版本 "},"docs/nodejs/nodejs安装.html":{"url":"docs/nodejs/nodejs安装.html","title":"Nodejs安装","keywords":"","body":"先安装gcc 方法一：nvm安装 nvm install --lts ##安装最新稳定版 node –v npm -v 备注： nvm命令： 1、nvm list-remote ：列出所有可安装版本 2、nvm install {版本号} ：安装指定版本 3、nvm ls ：查看已经安装的版本 4、nvm use {版本号} ：使指定版本生效 5、nvm alias default {版本号} ：设置默认版本 方法二：压缩包安装 1、下载 wget https://nodejs.org/dist/v8.5.0/node-v8.5.0-linux-x64.tar.gz 2、tar zxvf node-v8.5.0-linux-x64.tar.gz 3、配置环境变量 vim /etc/profile 编辑环境变量，在末尾添加 export NODE_HOME=\"/usr/local/node-v8.5.0-linux-x64\" export PATH=$PATH:$NODE_HOME/bin 4、刷新 source /etc/profile 5、验证 node -v . ~/.nvm/nvm.sh . ~/.profile //备注，如果其他命令可能会需要 . ~/.bashrc //同上 ﻿tar xvJf node-v12.16.1-linux-x64.tar.xz -C /usr/local "},"docs/nodejs/nvm安装.html":{"url":"docs/nodejs/nvm安装.html","title":"Nvm安装","keywords":"","body":"nvm安装成功后，但命令不可用(command not found) 第一种情况：未安装nvm 第二种情况：安装成功nvm，但输入命令提醒“ command not found” 第一种解决办法： centos/redhat系统直接下载安装nvm curl https://raw.github.com/creationix/nvm/v0.33.11/install.sh | sh 第二种解决办法： 1.进入执行者的家目录下的.nvm隐藏文件夹 cd ~/.nvm 2.查看目录下是否有.bash_profile文件（这是环境变量隐藏文件） [root@Blog .nvm]# ls -a . Dockerfile .github Makefile README.md .. .dockerignore .gitignore .npmrc ROADMAP.md bash_completion .editorconfig install.sh nvm-exec test .bash_profile .git LICENSE.md nvm.sh .travis.yml CONTRIBUTING.md .gitattributes .mailmap package.json update_test_mocks.sh [root@Blog .nvm]# 3.如果没有就创建该文件，然后保存文件 [root@Blog .nvm]# vim .bash_profile export NVM_DIR=\"/root/.nvm\" [ -s \"$NVM_DIR/nvm.sh\" ] && . \"$NVM_DIR/nvm.sh\"4.执行环境变量 [root@Blog .nvm]# souce .bash_profile 5.输入nvm命令，是否还提醒命令不存在？如果有，命令安装成功 [root@Blog ~]# nvm --version 0.33.11 "},"docs/oracle/Centos7下安装ORACLE 11g，弹窗不显示.html":{"url":"docs/oracle/Centos7下安装ORACLE 11g，弹窗不显示.html","title":"Centos7下安装ORACLE 11g，弹窗不显示","keywords":"","body":"Centos7下安装ORACLE 11gR2，弹窗不显示，安装界面显示为灰色。 https://blog.51cto.com/2937761/2369869 解决方法：执行安装时带上一下参数 ./runInstaller -jreLoc /etc/alternatives/jre_1.8.0 安装常见问题： https://blog.51cto.com/10463096/1706533 ISPLAY at least 256 colors解决办法 https://blog.csdn.net/weixin_42774383/article/details/82313242 "},"docs/oracle/centos7安装oracle.html":{"url":"docs/oracle/centos7安装oracle.html","title":"Centos7安装Oracle","keywords":"","body":"centos7安装oracle11 "},"docs/oracle/oracle-rac集群.html":{"url":"docs/oracle/oracle-rac集群.html","title":"Oracle Rac集群","keywords":"","body":"规划 配置规划 系统安装规划: ORACLE_BASE=/data/oracle ORACLE_HOME=/data/oracle/product/11.2.0/db_1 DB_NAME=orcl ORACLE_SID=orcl/ TNS_ADMIN=$ORACLE_HOME/network/admin ORACLE管理账户口令：oracle 数据库存放位置=ASM 是否使用归档方式运行数据库=ARCHIVED 备份方式说明：RMAN 网络规划 物理机创建网络： 物理网卡（物理网口）-创建虚拟交换机（选择上行链路）--添加端口组 在物理机：192.168.210.236创建 vm-rac端口组 虚机通过esxi创建虚拟网络vm-rac eth0 公网、vip、scan 一个网段，私网只要能相互ping通就可以 public-ip： vip scan private-ip "},"docs/oracle/oracle连接.html":{"url":"docs/oracle/oracle连接.html","title":"Oracle连接","keywords":"","body":"sqlplus /nolog sqlplus / as sysdba show user sqlplus system/liumiao123 conn 用户名/密码@127.0.0.1:1521/实例名 "},"docs/oracle/天兔安装实战.html":{"url":"docs/oracle/天兔安装实战.html","title":"天兔安装实战","keywords":"","body":"一、安装docker 关闭selinux： 1、临时关闭：输入命令setenforce 0，重启系统后还会开启。 2、永久关闭：输入命令vi /etc/selinux/config，将SELINUX=enforcing改为SELINUX=disabled，然后保存退出。 yum install –y epel-release yum -y install docker-io 安装docker-compose https://docs.docker.com/compose/install/ 下载： sudo curl -L \"https://github.com/docker/compose/releases/download/1.27.4/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose 赋权限： sudo chmod +x /usr/local/bin/docker-compose 二、安装天兔 相关安装文档： https://blog.csdn.net/qq_31144297/article/details/105436266 下载天兔： docker pull georce/lepus 运行： docker run -d --name=lepus -p 9001:80 -p 3306:3306 \\ -v /opt/mysql:/var/lib/mysql -v /etc/timelocal:/etc/timelocal \\ georce/lepus 访问：xxxx:9001 admin/Lepusadmin docker exec -it lepus bash mysql -uroot -p 直接回车，密码为空，需要自己另外设置密码 修改密码： use mysql update user set password=password('xxx') where user='root' and host='localhost' flush privileges; 1 2 3 记得修改php里的连接密码 ip:port，ip+端口访问，默念用户名密码 admin/Lepusadmin php 代码在 /var/www/html/ 目录，在 /var/www/html/application/views/profile/index.php 这个文件密码的 input 的 readonly去掉才可以修改密码 修改web默念超级用户登录密码 use lepus update admin_user set password=md5('xxx') where user_id=1 三、安装oracle客户端 下载地址：https://www.oracle.com/database/technologies/instant-client/linux-x86-64-downloads.html 下载安装包： oracle-instantclient19.9-basic-19.9.0.0.0-1.x86_64.rpm oracle-instantclient19.9-devel-19.9.0.0.0-1.x86_64.rpm（可以不用安装） oracle-instantclient19.9-sqlplus-19.9.0.0.0-1.x86_64.rpm 1、安装 rpm -ivh oracle-instantclient19.9-basic-19.9.0.0.0-1.x86_64.rpm rpm -ivh oracle-instantclient19.9-sqlplus-19.9.0.0.0-1.x86_64.rpm (rpm qa|grep 包名) (rpm -e 包名)卸载 2、配置环境变量 vi ~/.bash_profile 增加 export ORACLE_HOME=/usr/lib/oracle/19.9/client64 export TNS_ADMIN=/usr/lib/oracle/19.9/client64 export TNS=/usr/lib/oracle/19.9/client64 export NLS_LANG=AMERICAN_AMERICA.AL32UTF8 export LD_LIBRARY_PATH=$ORACLE_HOME/lib:$LD_LIBRARY_PATH PATH=$PATH:$HOME/bin:$ORACLE_HOME/bin:$ORACLE_HOME/lib export PATH 保存 ：x 生效：source ~/.bash_profile 测试： sqlplus username/passwd@SID 问题：bash: sqlplus: command not found ln -s $ORACLE_HOME/bin/sqlplus /usr/bin 四、安装cx_Oracle 客户端 下载地址： https://pypi.org/project/cx-Oracle/5.1.3/#files python2 的只可以安装到7.3 （https://cx-oracle.readthedocs.io/en/latest/user_guide/installation.html） 监控oracle 要安装 cx_Oracle 官网 https://oracle.github.io/python-cx_Oracle/ github地址： https://github.com/oracle/python-cx_Oracle 历史下载地址 https://sourceforge.net/projects/cx-oracle/ 测试安装 python -c \"import cx_Oracle\" 参考： 一、https://www.bbsmax.com/A/kmzLb08E5G/ 二、https://www.cnblogs.com/eikixu/p/10019835.html 三、pip安装 https://pip.pypa.io/en/stable/installing/ 参考：https://www.cnblogs.com/zanao/p/13445993.html https://blog.csdn.net/dream_gf/article/details/81181388 ：安装GLIBC_2.14 天兔安装文档： http://www.lepus.cc/post/52 Python 2.7.9 + 或 Python 3.4+ 以上版本都自带 pip 工具。 http://www.lepus.cc/page/product 问题：报 import cx_Oracle ImportError: libclntsh.so.11.1: cannot open shared object file: No such file or directory 解决办法：先刷新 source ~/.bash_profile 重启 lepus lepus stop lepus start 问题二、docker时间不同步 Error processing tar file(invalid symlink \"/etc/localtime\" -> \"../usr/share/zoneinfo/Asia/Shanghai\" https://blog.csdn.net/lang59/article/details/102795952 docker cp /usr/share/zoneinfo/Asia/Shanghai 2c87bcc41378:/etc/localtime 重启 docker 容器 宿主机和docker容器时间同步方法一： Centos RUN echo \"Asia/shanghai\" > /etc/timezone; Ubuntu RUN cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime 宿主机和docker容器时间同步方法二： RUN ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime 关闭网关 systemctl stop firewalld systemctl stop iptables docker0: iptables: No chain/target/match by that name 在CentOS 6.8下使用类似nginx之类的web server，启动docker时有时会报以下错误： docker0: iptables: No chain/target/match by that name. 解决方法： service docker restart 重启docker后: iptables -L 可以看到iptables里面多出了Chain Docker的选项。 经验为：在启动firewalld之后，iptables被激活，此时没有docker chain，重启docker后被加入到iptable里面。 "},"docs/powerdesigner/模板.html":{"url":"docs/powerdesigner/模板.html","title":"模板","keywords":"","body":" 3C82EAEC-BB5A-4FFB-BCF5-57C96D2AD3C2 wordTemplate ReportToWord 1303635366 Administrator 1368973883 ferry LightBlue_Theme.css Header_LightBlue.html Footer_LightBlue.html 54 18 4 Home_LightBlue.html Light Blue Professional 1 516C18E4-2441-4B09-95C3-614CE211F854 1303635366 Administrator 1303635366 Administrator 新宋体 10 1 4 423 106 15 0 68353469-90B0-46A5-AEFF-FEF9E8A72B5B 1303635366 Administrator 1303635366 Administrator Microsoft Sans Serif 10 4 0 BBBE7584-E433-442F-8BFF-0FE6E664E4A5 wordTemplate 0 1368973883 ferry 1 TEMPLATE PDM ((800,899), (1100,899)) ((549,508), (660,635)) (20998, 29698) 1 1 AE703E54-646B-4EA6-805B-8313F517B710 1303635366 Administrator 1368973981 ferry 1 1 TITLE PDM 表清单 0 B19FDCE3-00B2-4511-8244-7F5D6AF69DC1 1368973822 ferry 1368973822 ferry 1 1 PDM_MODEL_TABL_LIST PDM Table list Table list 表清单 1 1 -50 Name -50 Code 3E06F75B-4E4C-4272-BFE4-491660B9BDDB Table selection 1368973822 ferry 1368973822 ferry 6 53454C3200000000000000000300000000000000000000000000000000000000 0000 DC9595E9-68F8-4E5B-A554-071455C3886F 1368973822 ferry 1368973822 ferry 宋体 12 1 353 106 0 6D9B6DD7-1195-4406-8A18-A92C9AB7C022 1368973822 ferry 1368973822 ferry Times New Roman 10 2 1 4 15 18 1 18 198EC86B-E5CA-483A-9139-774426FB2BEA 1368973822 ferry 1368973822 ferry Times New Roman 10 1 15 18 1 18 D1AFFCF9-64AA-43C1-BB55-42BB7A20E226 1368973822 ferry 1368973822 ferry C497D8D7-9492-4917-BA9A-FC32CD9B09E3 1303635366 Administrator 1303635366 Administrator Arial 10 5 1 423 106 50D107AF-2562-4BCE-BC4D-863D56D59555 1303635366 Administrator 1368973987 ferry 1 1 TITLE PDM 表列清单 0 4BB76E3A-1AD7-44E2-8980-A54978204F9F 1368973826 ferry 1368973826 ferry 1 1 PDM_TABL_TITLE PDM Table %ITEM% Table %ITEM% 表 %ITEM% 1 65D2897B-373C-4A10-B559-EE4AF545EEF7 1368973826 ferry 1368973868 ferry 1 1 PDM_TABL_COLN_LIST PDM Column list of the table %PARENT% Column list of the table %PARENT% 表 &lt;%PARENT%&gt; 的列清单 1 Columns 1 -50 Code -50 Name 37 DataType 20 Primary 20 Mandatory 43 Comment 48FDFA1D-00ED-4ADC-8E5B-1788C343E85C Column selection 1368973826 ferry 1368973826 ferry 10 ; Criterion; ; B0C4F74D-F7F9-4759-BEFE-1A1B5B318717 1368973826 ferry 1368973826 ferry 宋体 12 1 4 353 106 0 2ED5ABFD-7720-4EC6-A240-085FEDA141AA 1368973826 ferry 1368973826 ferry 宋体 12 1 4 15 18 1 18 F1BFB431-E8CE-4853-9C5F-A96AC0185E10 1368973826 ferry 1368973826 ferry 宋体 12 1 15 18 1 18 A5DADC74-A0FE-4245-9FA6-EF8D164C8F35 1368973826 ferry 1368973826 ferry 1F679A51-F44B-4877-96E3-1CCD6DD878D3 1368973826 ferry 1368973826 ferry 宋体 11 1 353 106 0 6C7E2923-00D9-4F8B-B855-51495FD60B09 1303635366 Administrator 1303635366 Administrator Arial 10 5 1 423 106 0 ABC62488-F737-45E6-81F0-62A9F1B12ECA 1303635366 Administrator 1303635366 Administrator Times New Roman 10 1 8 81FE2837-0B41-40F2-882C-3983DA3B2EC2 1303635366 Administrator 1303635366 Administrator 19098 3 77461F31-C8C9-4FF0-99E0-1569B20637C5 1303635366 Administrator 1303635366 Administrator Times New Roman 10 1 2 C9142380-B49F-45F7-BDFD-554F25F6F9A3 1303635366 Administrator 1303635366 Administrator 9549 2 2E344804-2E7F-48D9-92AA-A89CD51F1EC3 1303635366 Administrator 1303635366 Administrator 19098 3 "},"docs/prometheus相关/api.html":{"url":"docs/prometheus相关/api.html","title":"Api","keywords":"","body":"https://prometheus.io/docs/prometheus/latest/querying/api/ 中文翻译 https://www.cnblogs.com/zhoujinyi/p/11955131.html "},"docs/prometheus相关/exporter/ICMP修改ping监控.html":{"url":"docs/prometheus相关/exporter/ICMP修改ping监控.html","title":"ICMP修改Ping监控","keywords":"","body":"https://www.cnblogs.com/moniter/p/12305180.html 用的 blackbox_exporter ping https://github.com/knsd/ping-exporter https://blog.csdn.net/apple_llb/article/details/50494787 https://www.cnblogs.com/xiao987334176/p/12022482.html https://github.com/prometheus/blackbox_exporter/blob/master/example.yml https://github.com/prometheus/blackbox_exporter/blob/master/CONFIGURATION.md https://blog.frognew.com/2018/02/prometheus-blackbox-exporter.html cd /usr/local/bin/blackbox_exporter ./blackbox_exporter --config.file=blackbox.yml & cd /opt/config docker-compose -f docker-compose-monitor.yml restart prometheus https://www.iamle.com/archives/2130.html - job_name: 'ping_all' scrape_interval: 20s metrics_path: /probe params: module: [icmp] #ping static_configs: - targets: ['192.168.210.50','192.168.210.60','192.168.210.101'] labels: group: '北京' - targets: - 192.168.210.70 - 192.168.210.100 labels: group: '上海' relabel_configs: - source_labels: [__address__] regex: (.*)(:80)? target_label: __param_target replacement: ${1} - source_labels: [__param_target] regex: (.*) target_label: ping replacement: ${1} - source_labels: [] regex: .* target_label: __address__ replacement: 192.168.210.80:9115 "},"docs/prometheus相关/exporter/prometheus监控mysql.html":{"url":"docs/prometheus相关/exporter/prometheus监控mysql.html","title":"Prometheus监控Mysql","keywords":"","body":"监控mysql 环境 插件：mysql_exporter 版本： 0.12.1 官方地址：https://github.com/prometheus/mysqld_exporter grafana模板：https://grafana.com/dashboards/7362 数据库版本：5.6以上 安装 压缩包安装 1、安装包上传mysql服务器，解压到指定目录 tar zxvf mysqld_exporter-0.12.1.linux-amd64.tar.gz -C /usr/local 2、重命名 cd /usr/local mv mysqld_exporter-0.12.1.linux-amd64 /usr/local/mysql_exporter 3、登录mysql 创建账户 # 本地访问 mysql> CREATE USER 'exporter'@'localhost' IDENTIFIED BY 'XXXXXXXX'; #或远程访问 mysql> CREATE USER 'exporter'@'%' IDENTIFIED BY 'XXXXXXXX'; 授权： # 可查看主从运行情况查看线程，及所有数据库。 mysql> GRANT PROCESS, REPLICATION CLIENT, SELECT ON *.* TO 'exporter'@'localhost'; #或远程 # 可查看主从运行情况查看线程，及所有数据库。 mysql> GRANT PROCESS, REPLICATION CLIENT, SELECT ON *.* TO 'exporter'@'%'; #刷新数据库 mysql> flush privileges; 4、创建配置文件 vim /usr/local/mysql_exporter/my.cnf #内容 [client] host=localhost port=3306 user=exporter password=123456 5、启动exporter ./mysqld_exporter --config.my-cnf=my.cnf #参数说明 常用参数： # 选择采集innodb --collect.info_schema.innodb_cmp # innodb存储引擎状态 --collect.engine_innodb_status # 指定配置文件 --config.my-cnf=\"my.cnf\" 参考： https://github.com/prometheus/mysqld_exporter 6、添加系统服务 vi /usr/lib/systemd/system/mysql_exporter.service #内容 [Unit] Description=mysql_exporter After=network.target [Service] Type=simple User=mysql Environment=DATA_SOURCE_NAME=exporter:123456@(localhost:3306)/ ExecStart=/usr/local/mysql_exporter/mysqld_exporter --web.listen-address=0.0.0.0:9104 --config.my-cnf /usr/local/mysql_exporter/my.cnf \\ --collect.slave_status \\ --collect.slave_hosts \\ --log.level=error \\ --collect.info_schema.processlist \\ --collect.info_schema.innodb_metrics \\ --collect.info_schema.innodb_tablespaces \\ --collect.info_schema.innodb_cmp \\ --collect.info_schema.innodb_cmpmem Restart=on-failure [Install] WantedBy=multi-user.target #简洁版 [Unit] Description=mysql_exporter [Service] Restart=on-failure ExecStart=/usr/local/mysql_exporter/mysqld_exporter --config.my-cnf /usr/local/mysql_exporter/my.cnf [Install] WantedBy=multi-user.target 7、启动 chown -R root:root /usr/lib/systemd/system/mysql_exporter.service chmod 644 /usr/lib/systemd/system/mysql_exporter.service systemctl daemon-reload systemctl enable mysqld_exporter.service systemctl start mysqld_exporter.service 8、查看捕获的mysql数据 http://192.168.210.60:9104/metrics # HELP go_gc_duration_seconds A summary of the GC invocation durations. # TYPE go_gc_duration_seconds summary go_gc_duration_seconds{quantile=\"0\"} 2.8648e-05 go_gc_duration_seconds{quantile=\"0.25\"} 8.0458e-05 go_gc_duration_seconds{quantile=\"0.5\"} 0.000156041 go_gc_duration_seconds{quantile=\"0.75\"} 0.000201022 go_gc_duration_seconds{quantile=\"1\"} 0.000706424 go_gc_duration_seconds_sum 0.76849535 go_gc_duration_seconds_count 4807 # HELP go_goroutines Number of goroutines that currently exist. # TYPE go_goroutines gauge go_goroutines 10 # HELP go_info Information about the Go environment. # TYPE go_info gauge go_info{version=\"go1.12.7\"} 1 # HELP go_memstats_alloc_bytes Number of bytes allocated and still in use. # TYPE go_memstats_alloc_bytes gauge go_memstats_alloc_bytes 3.24544e+06 # HELP go_memstats_alloc_bytes_total Total number of bytes allocated, even if freed. # TYPE go_memstats_alloc_bytes_total counter go_memstats_alloc_bytes_total 1.3871545528e+10 # HELP go_memstats_buck_hash_sys_bytes Number of bytes used by the profiling bucket hash table. # TYPE go_memstats_buck_hash_sys_bytes gauge go_memstats_buck_hash_sys_bytes 1.584137e+06 ...... ...... ...... mysql_info_schema_innodb_cmpmem_relocation_time_seconds_total{buffer_pool=\"0\",page_size=\"1024\"} 0 mysql_info_schema_innodb_cmpmem_relocation_time_seconds_total{buffer_pool=\"0\",page_size=\"16384\"} 0 mysql_info_schema_innodb_cmpmem_relocation_time_seconds_total{buffer_pool=\"0\",page_size=\"2048\"} 0 mysql_info_schema_innodb_cmpmem_relocation_time_seconds_total{buffer_pool=\"0\",page_size=\"4096\"} 0 mysql_info_schema_innodb_cmpmem_relocation_time_seconds_total{buffer_pool=\"0\",page_size=\"8192\"} 0 # HELP mysql_up Whether the MySQL server is up. # TYPE mysql_up gauge mysql_up 1 # HELP mysql_version_info MySQL version and distribution. # TYPE mysql_version_info gauge mysql_version_info{innodb_version=\"5.6.47\",version=\"5.6.47\",version_comment=\"MySQL Community Server (GPL)\"} 1 # HELP mysqld_exporter_build_info A metric with a constant '1' value labeled by version, revision, branch, and goversion from which mysqld_exporter was built. # TYPE mysqld_exporter_build_info gauge mysqld_exporter_build_info{branch=\"HEAD\",goversion=\"go1.12.7\",revision=\"48667bf7c3b438b5e93b259f3d17b70a7c9aff96\",version=\"0.12.1\"} 1 # HELP process_cpu_seconds_total Total user and system CPU time spent in seconds. # TYPE process_cpu_seconds_total counter process_cpu_seconds_total 245.98 # HELP process_max_fds Maximum number of open file descriptors. # TYPE process_max_fds gauge process_max_fds 1024 # HELP process_open_fds Number of open file descriptors. # TYPE process_open_fds gauge process_open_fds 9 # HELP process_resident_memory_bytes Resident memory size in bytes. # TYPE process_resident_memory_bytes gauge process_resident_memory_bytes 1.5839232e+07 # HELP process_start_time_seconds Start time of the process since unix epoch in seconds. # TYPE process_start_time_seconds gauge process_start_time_seconds 1.60438649694e+09 # HELP process_virtual_memory_bytes Virtual memory size in bytes. # TYPE process_virtual_memory_bytes gauge process_virtual_memory_bytes 1.1798528e+08 # HELP process_virtual_memory_max_bytes Maximum amount of virtual memory available in bytes. # TYPE process_virtual_memory_max_bytes gauge process_virtual_memory_max_bytes -1 # HELP promhttp_metric_handler_requests_in_flight Current number of scrapes being served. # TYPE promhttp_metric_handler_requests_in_flight gauge promhttp_metric_handler_requests_in_flight 1 # HELP promhttp_metric_handler_requests_total Total number of scrapes by HTTP status code. # TYPE promhttp_metric_handler_requests_total counter promhttp_metric_handler_requests_total{code=\"200\"} 4579 promhttp_metric_handler_requests_total{code=\"500\"} 0 promhttp_metric_handler_requests_total{code=\"503\"} 0 常见错误： mysql_up == 0 一般是数据库没有配置好，先检查 配置文件地址 prometheus监控，修改配置 vim prometheus.yml scrape_configs: # 添加作业并命名 - job_name: 'mysql' # 静态添加node static_configs: # 指定监控端 - targets: ['192.168.210.60:9104'] 重启prometheus 查看prometheus监控 http://192.168.210.80:9090/targets 使用promsql查看 mysql_global_status_uptime 使用grafana展示，导入 7362模板 "},"docs/prometheus相关/exporter/prometheus监控snmp.html":{"url":"docs/prometheus相关/exporter/prometheus监控snmp.html","title":"Prometheus监控Snmp","keywords":"","body":"参考： https://www.cnblogs.com/guoxiangyue/p/11778217.html 部署 snmp_exporter 说明：snmp_exporter的配置文件需要自己通过SNMP Exporter Config Generator 项目编译生成 说明：由于Prometheus使用go语言开发的，所以自己编译生成snmp_exporter的配置文件需要go环境 下载snmp_exporter 下载snmp_exporter安装包，下载地址：https://github.com/prometheus/snmp_exporter/releases 下载完成后，上传至机器的 /usr/local 目录下 解压安装包 # tar -zvxf snmp_exporter-0.15.0.linux-arm64.tar.gz -C /usr/local # mv snmp_exporter-0.15.0.linux-arm64/ snmp_exporter 配置snmp_exporter 安装go环境 https://golang.org/dl/ 安装包下载以后，上传至监控主机的 /usr/local 目录下 tar -xvf go1.13.1.linux-amd64.tar.gz 配置环境变量 添加/usr/loacl/go/bin目录到PATH变量中。添加到/etc/profile 或$HOME/.profile都可以 # vim /etc/profile // 在最后一行添加 export GOROOT=/usr/local/go export PATH=$PATH:$GOROOT/bin // wq保存退出后source一下 # source /etc/profile 执行go version，如果显示版本号，则Go环境安装成功。 构建：snmp exporter config Generator 先解决go get慢的问题 建议go版本在1.13以上 ##linux go env -w GO111MODULE=on go env -w GOPROXY=https://goproxy.cn,direct go env #查看配置 windows powershell PS C:\\Users\\mark> $env:GOPROXY = \"https://goproxy.cn\" 修改环境变量； echo \"export GOPROXY=https://goproxy.cn\" >> ~/.profile && source ~/.profile #go下载使用mod模式,下载会在 GOPATH的pkg/mod 目录下 # yum -y install git # yum -y install gcc gcc-g++ make net-snmp net-snmp-utils net-snmp-libs net-snmp-devel # go get github.com/prometheus/snmp_exporter/generator@v0.19.0 # cd $GOPATH/pkg/mod/github.com/prometheus/snmp_exporter\\@v0.19.0/generator # go build # make mibs #这个可以不做 制作generator.yml文件 下载相应的mib库 到 https://github.com/librenms/librenms/tree/master/mibs 下载相应的mib库 http://oidref.com 放在 /root/.snmp/mibs 里面(generator 默认到 这个目录找) # unzip -d /root/.snmp/mibs MIB-V200R010C00SPC600.zip 制作generator.yml配置文件 #cd $GOPATH/pkg/mod/github.com/prometheus/snmp_exporter\\@v0.19.0/generator # vim generator.yml modules: # Default IF-MIB interfaces table with ifIndex. huawei: walk: - 1.3.6.1.2.1.2 - sysUpTime # Same as \"1.3.6.1.2.1.1.3\" - sysDescr # Same as \"1.3.6.1.2.1.1.1\" - sysName # Same as \"1.3.6.1.2.1.1.5\" - 1.3.6.1.2.1.31 - 1.3.6.1.4.1.2011.5.25.31.1.1 version: 2 auth: community: default max_repetitions: 25 # How many objects to request with GET/GETBULK, defaults to 25. # May need to be reduced for buggy devices. retries: 3 # How many times to retry a failed request, defaults to 3. timeout: 5s # Timeout for each individual SNMP request, defaults to 5s. lookups: - source_indexes: [ifIndex] lookup: ifAlias - source_indexes: [ifIndex] # Uis OID to avoid conflict with PaloAlto PAN-COMMON-MIB. lookup: 1.3.6.1.2.1.2.2.1.2 # ifDescr - source_indexes: [ifIndex] # Use OID to avoid conflict with Netscaler NS-ROOT-MIB. lookup: 1.3.6.1.2.1.31.1.1.1.1 # ifName overrides: ifAlias: ignore: true # Lookup metric ifDescr: ignore: true # Lookup metric ifName: ignore: true # Lookup metric ifType: type: EnumAsInfo 生成snmp.yml #可以不export,默认到 /root/.snmp/mibs找 export MIBDIRS=/usr/share/snmp/mibs ./generator generate #在当前目录生成snmp.yml文件 把snmp.yml复制到 /usr/local/snmp_exporter目录 cp snmp.yml /usr/local/snmp_exporter/ #./snmp_exporter Ctrl+C 结束掉 snmp_exporter 进程 参考： 后台运行：nohup ./snmp_exporter --config.file=snmp.yml --web.listen-address=:9116 > default.log 2>&1 & snmp_exporter设置开机启动 # vim /etc/systemd/system/snmp_exporter.service [Unit] Description=snmp_exporter After=network.target Documentation=https://github.com/prometheus/snmp_exporter [Service] ExecStart=/usr/local/snmp_exporter/snmp_exporter \\ --config.file=/usr/local/snmp_exporter/snmp.yml \\ --web.listen-address=:9116 \\ --snmp.wrap-large-counters \\ --log.level=info [Install] WantedBy=multi-user.target # systemctl daemon-reload # systemctl enable snmp_exporter # systemctl start snmp_exporter # systemctl status snmp_exporter 查看 # curl 'http://192.168.210.80:9116/snmp?module=huawei&target=192.168.210.254' 配置prometheus - job_name: 'snmp_exporter' scrape_interval: 1m scrape_timeout: 1m static_configs: - targets: - 192.168.210.254 metrics_path: /snmp params: module: [huawei] relabel_configs: - source_labels: [__address__] target_label: __param_target - source_labels: [__param_target] target_label: instance - target_label: __address__ replacement: 192.168.210.80:9116 #重启prometheus docker-compose -f docker-compose-monitor.yml restart prometheus 其他参考模板 modules: # Default IF-MIB interfaces table with ifIndex. huawei: walk: - interfaces - sysUpTime # Same as \"1.3.6.1.2.1.1.3\" - ifXTable - sysDescr # Same as \"1.3.6.1.2.1.1.1\" - sysName # Same as \"1.3.6.1.2.1.1.5\" - 1.3.6.1.4.1.2011.5.25.31.1.1 #cpu - 1.3.6.1.4.1.25506.2.6.1.1.1.1.6.slot #内存 - 1.3.6.1.4.1.25506.2.6.1.1.1.1.8.slot version: 2 auth: community: public max_repetitions: 25 # How many objects to request with GET/GETBULK, defaults to 25. # May need to be reduced for buggy devices. retries: 3 # How many times to retry a failed request, defaults to 3. timeout: 5s # Timeout for each individual SNMP request, defaults to 5s. lookups: - source_indexes: [ifIndex] lookup: ifAlias - source_indexes: [ifIndex] # Uis OID to avoid conflict with PaloAlto PAN-COMMON-MIB. lookup: 1.3.6.1.2.1.2.2.1.2 # ifDescr - source_indexes: [ifIndex] # Use OID to avoid conflict with Netscaler NS-ROOT-MIB. lookup: 1.3.6.1.2.1.31.1.1.1.1 # ifName overrides: ifAlias: ignore: true # Lookup metric ifDescr: ignore: true # Lookup metric ifName: ignore: true # Lookup metric ifType: type: EnumAsInfo modules: # Default IF-MIB interfaces table with ifIndex. 要有对应的mib库，不然不能生成 snmp.yml ,snmp.yml不能修改，智能通过generator 生成 huawei_mib: walk: - sysUpTime - interfaces - ifXTable - sysDescr - sysName - 1.3.6.1.2.1.31.1.1.1.1 - 1.3.6.1.4.1.2011.5.25.38 - 1.3.6.1.2.1.80 - 1.3.6.1.4.1.2011.5.25.31.1.1.1.1.2 #实体操作状态 - 1.3.6.1.4.1.2011.5.25.31.1.1.1.1.5 #实体CPU使用率 - 1.3.6.1.4.1.2011.5.25.31.1.1.1.1.7 #实体内存使用率 - 1.3.6.1.4.1.2011.5.25.31.1.1.1.1.10 #实体启动时间 - 1.3.6.1.4.1.2011.5.25.31.1.1.1.1.11 #实体温度 - 1.3.6.1.2.1.80.1.2.1.4 #测试的目的地址 version: auth: community: public lookups: #lookups 是prometheus 一个lookup 一个标签 下面是放三个标签 ,以ifindex唯一值 - source_indexes: [ifIndex] lookup: ifAlias - source_indexes: [ifIndex] # Uis OID to avoid conflict with PaloAlto PAN-COMMON-MIB. lookup: 1.3.6.1.2.1.2.2.1.2 # ifDescr - source_indexes: [ifIndex] # Use OID to avoid conflict with Netscaler NS-ROOT-MIB. lookup: 1.3.6.1.2.1.31.1.1.1.1 # ifName overrides: ifAlias: ignore: true # Lookup metric ifDescr: ignore: true # Lookup metric ifName: ignore: true # Lookup metric ifType: type: EnumAsInfo 云地址上 1.116.208.30 WJW...... cd /opt/go/work/pkg/mod/github.com/prometheus/snmp_exporter@v0.19.0/generator ./generator generate #生成snmp.yml 文件 "},"docs/prometheus相关/exporter/好用的exporter.html":{"url":"docs/prometheus相关/exporter/好用的exporter.html","title":"好用的Exporter","keywords":"","body":"http://bubuko.com/infodetail-3524268.html prometheus 一些不错的exporter blackbox_exporter 支持协议：http、dns、tcp、icmp ICMP：监控主机存活状态 module: [icmp] TCP:监控主机端口存活状态module: [tcp_connect] HTTP: module: [http_2xx]监控网站状态 statping 监控网站应用的（状态查看的），同时暴露了prometheus metrics 参考网站：https://github.com/statping/statping sql_exporter 灵活的sql exporter 参考网站：https://github.com/justwatchcom/sql_exporter exporter_exporter 让exporter 支持类似nginx 的proxy 模式，参考网站：https://github.com/QubitProducts/exporter_exporter query-exporter 基于sql 暴露metrics 的类似sql_exporter,参考网站：https://github.com/albertodonato/query-exporter script_exporter 基于scripit 暴露metrics，参考网站：https://github.com/ricoberger/script_exporter systemd_exporter 提供系统systemd的一些metrics，参考网站：https://github.com/povilasv/systemd_exporter blackbox_exporter 一个比较通用的exporter，prometheus 官方出品，参考网站：https://github.com/prometheus/blackbox_exporter json-exporter 基于jsonpath+json api 模式的metrics 暴露，参考网站https://github.com/tolleiv/json-exporter process-exporter 系统进程信息的metrics，参考网站：https://github.com/ncabatoff/process-exporter ebpf_exporter 暴露ebpf 的一些metrics，参考网站：https://github.com/cloudflare/ebpf_exporter ssh_exporter 基于ssh 执行远程命令暴露metrics，参考网站：https://github.com/Nordstrom/ssh_exporter 其他的一些应用积以及db&&中间间的exporter 这类的比较多，各种db的以及redis，memecache，kafka，rabbitmq。。。。。很多 "},"docs/prometheus相关/exporter/安装node_exporter.html":{"url":"docs/prometheus相关/exporter/安装node_exporter.html","title":"安装Node Exporter","keywords":"","body":"#下载,解压安装 https://github.com/prometheus/node_exporter/releases/tag/v1.1.2 tar xvfz node_exporter-1.1.2.linux-amd64.tar.gz -C /usr/local/bin cd /usr/local/bin mv node_exporter-1.1.2.linux-amd64 node_exporter 创建用户组（也可以不创建） sudo groupadd -r prometheus sudo useradd -r -g prometheus -s /sbin/nologin -M -c \"prometheus Daemons\" prometheus //不创建组 就把user和group 去掉 ，注意端口冲突 netstat -an | grep 9100 查找pid：netstat -aon| findstr \"9100\" pid对应的程序：tasklist|findstr \"9100\" 杀死：taskkill /f /t /im 程序名.exe #vim /etc/systemd/system/node_exporter.service [Service] User=node_exporter Group=node_exporter ExecStart=/usr/local/bin/node_exporter/node_exporter\\ --web.listen-address=:9100\\ [Install] WantedBy=multi-user.target [Unit] Description=node_exporter After=network.target 安装： node exporter 官方文档：https://prometheus.io/docs/guides/node-exporter/ https://www.cnblogs.com/roger888/p/10535751.html https://grafana.com/dashboards/8919 https://grafana.com/grafana/dashboards/11074 无代理 Linux无代理snmp： LM-SENSORS-MIB 常用的oid https://blog.csdn.net/weixin_42506599/article/details/105569398 可以参考zabbix模板 https://www.cnblogs.com/hwlong/p/9291337.html "},"docs/prometheus相关/exporter/监控oracle.html":{"url":"docs/prometheus相关/exporter/监控oracle.html","title":"监控Oracle","keywords":"","body":"https://github.com/freenetdigital/prometheus_oracle_exporter/blob/master/README.md "},"docs/prometheus相关/exporter/监控sqlserver.html":{"url":"docs/prometheus相关/exporter/监控sqlserver.html","title":"监控Sqlserver","keywords":"","body":"https://github.com/rongfengliang/prometheus-mssql-exporter https://www.cnblogs.com/rongfengliang/p/12767914.html "},"docs/prometheus相关/exporter/监控windows.html":{"url":"docs/prometheus相关/exporter/监控windows.html","title":"监控Windows","keywords":"","body":"https://www.cnblogs.com/gered/p/13523379.html https://github.com/prometheus-community/windows_exporter 9182 dashboard: 10467 无代理 https://blog.csdn.net/liuhuango123/article/details/52253953 工具： ManageEngine MibBrowser（适用与有现成的.mib库文件） Paessler SNMP Tester（测试OID） FreeSnmp（使用Walk探测OID） MIB库：HOST-RESOURCES-MIB 配置snmp "},"docs/prometheus相关/promQL函数.html":{"url":"docs/prometheus相关/promQL函数.html","title":"PromQL函数","keywords":"","body":"https://yunlzheng.gitbook.io/prometheus-book/parti-prometheus-ji-chu/promql/prometheus-promql-functions https://www.jianshu.com/p/c1eeb818a36c/ https://www.cnblogs.com/wayne-liu/p/9273492.html Promql函数 rate() rate函数，rate用来计算两个 间隔时间内发生的变化率（一段时间内平均每秒的增量）。 专门用来搭配Counters类型的数据，rate(指标名{筛选条件}[时间间隔]) 比如 查看1分钟内非idle的cpu使用率 rate(node_cpu_seconds_total{mode!=\"idle\"}[1m]) irate() rate与irate的区别 irate和rate都会用于计算某个指标在一定时间间隔内的变化速率。但是它们的计算方法有所不同：irate取的是在指定时间范围内的最近两个数据点来算速率，而rate会取指定时间范围内所有数据点，算出一组速率，然后取平均值作为结果。 所以官网文档说：irate适合快速变化的计数器（counter），而rate适合缓慢变化的计数器（counter）。 根据以上算法我们也可以理解，对于快速变化的计数器，如果使用rate，因为使用了平均值，很容易把峰值削平。除非我们把时间间隔设置得足够小，就能够减弱这种效应。 https://www.cnblogs.com/orange-lsc/p/12825562.html#irate step对于查询结果的影响 Prometheues在对PromQL表达式求值的逻辑是这样的 对于[start, end]时间区间，从start开始，以step为长度，把时间区间分成若干段 对每个段进行求值 举例：start=10,end=20,step=2，那么就会有ts=10,ts=12,ts=14,ts=16,ts=18,ts=206段，然后为这6个段进行求值。求值方式视乎表达式中Time series selector的类型而定。 "},"docs/prometheus相关/prometheus基础概念.html":{"url":"docs/prometheus相关/prometheus基础概念.html","title":"Prometheus基础概念","keywords":"","body":"文档 https://github.com/wjw595595/prometheus-book/blob/master/quickstart/why-monitor.md prometheus基础知识 概念 prometheus是一个开源的服务监控系统和事件序列数据库 监控：监控服务器、数据库、应用程序 官方网站：https://prometheus.io 项目托管：https://github.com/prometheus https://prometheus.io/docs/instrumenting/exporters/prometheus server prometheus的核心，负责实现对监控数据的获取、存储以及查询 exporter 将监控的数据采集起来，通过http服务的形式暴露出去，prometheus server 会定时去拉取这些暴露的数据进行监控 如：mysql_exporter,snmp_exporter 监控应用程序：可以在程序中集成官方的sdk，自己埋点暴露出需要监控的指标 PushGateway 是一个独立的服务，大部分场景用pull模式，（prometheus server拉取exporter提供的数据），如何想使用push模式，可以将数据push给 PushGateway，由pushgateway统一提供给 Server service Discovery 服务发现功能，在微服务场景监控很重要，服务发现可以动态的去发现服务信息，无需手动修改配置，官方推荐用Consul作为服务发现， Nacos目前不支持，（可以定时拉取信息同步到文件中） 三剑客 prometheus ，grafana，alertManager alertManager负责异常告警，可以对接钉钉等多种信息通知 alertManager架构图 从左上开始，Prometheus 发送的警报到 Alertmanager; 警报会被存储到 AlertProvider 中，Alertmanager 的内置实现就是包了一个 map，也就是存放在本机内存中，这里可以很容易地扩展其它 Provider; Dispatcher 是一个单独的 goroutine，它会不断到 AlertProvider 拉新的警报，并且根据 YAML 配置的 Routing Tree 将警报路由到一个分组中; 分组会定时进行 flush (间隔为配置参数中的 group_interval), flush 后这组警报会走一个 Notification Pipeline 链式处理; Notification Pipeline 为这组警报确定发送目标，并执行抑制逻辑，静默逻辑，去重逻辑，发送与重试逻辑，实现警报的最终投递; promQL 查询结果有三种类型： 1、瞬时向量(Instant vector)：http_requests_total 2、区间向量(Range vector)：http_requests_total[5m] 3、标量(Scalar)（没有时间序列）：count(http_requests_total) 指标(Metric) {=, ...} Prometheus定义了4种不同的指标类型 (metric type)：Counter（计数器）、Gauge（仪表盘）、Histogram（直方图）、Summary（摘要） 在time-series中的每一个点称为一个样本（sample），样本由以下三部分组成： 指标(metric)：metric name和描述当前样本特征的labelsets; 时间戳(timestamp)：一个精确到毫秒的时间戳; 样本值(value)： 一个float64的浮点型数据表示当前样本的值。 https://fuckcloudnative.io/prometheus/ https://www.cnblogs.com/lhrbest/p/14355265.html "},"docs/prometheus相关/prometheus官网教程.html":{"url":"docs/prometheus相关/prometheus官网教程.html","title":"Prometheus官网教程","keywords":"","body":"https://prometheus.io/ http://prometheus.io/community 文档 https://yunlzheng.gitbook.io/prometheus-book/ https://fuckcloudnative.io/prometheus/ 架构 监控vcenter https://www.qedev.com/cloud/70676.html https://github.com/pryorda/vmware_exporter https://fuckcloudnative.io/prometheus/ API文档 https://www.cnblogs.com/zhoujinyi/p/11955131.html https://prometheus.io/docs/prometheus/latest/querying/api/ "},"docs/prometheus相关/prometheus的relabel_configs的理解.html":{"url":"docs/prometheus相关/prometheus的relabel_configs的理解.html","title":"Prometheus的Relabel Configs的理解","keywords":"","body":"https://blog.csdn.net/wtan825/article/details/93651164 "},"docs/prometheus相关/prometheus监控expoter.html":{"url":"docs/prometheus相关/prometheus监控expoter.html","title":"Prometheus监控Expoter","keywords":"","body":" 监控内容 地址 端口 dashboard mysql oracle sqlserver linux windows https://www.kubernetes.org.cn/7086.html 9182 prometheus 9090 snmp if-mib：11169（端口）；端口详情（ 12492）；接口流量（1124）SNMP-Network(网络设备监控 11368) 7567 11589 ping 9115 9965 ：注意参数地址 metrics_path: /probe telegraf 交换机（思科）：12476, dell服务器：12106 "},"docs/prometheus相关/prometh踩坑集锦.html":{"url":"docs/prometheus相关/prometh踩坑集锦.html","title":"Prometh踩坑集锦","keywords":"","body":"https://hiddenpps.blog.csdn.net/article/details/107724335 "},"docs/prometheus相关/prome启动参数.html":{"url":"docs/prometheus相关/prome启动参数.html","title":"Prome启动参数","keywords":"","body":"--storage.tsdb.retention=90d 该参数决定何时删除旧数据，默认为15天。 在启动脚本里更改--storage.tsdb.retention=90d可以延长，或者启动时带上这个参数即可。 "},"docs/prometheus相关/yaml配置.html":{"url":"docs/prometheus相关/yaml配置.html","title":"Yaml配置","keywords":"","body":"https://soulchild.cn/1965.html relabel_configs https://blog.csdn.net/u012806692/article/details/79206964 https://www.cnblogs.com/faberbeta/p/13553810.html "},"docs/prometheus相关/监控oracle/oracle--DG监控脚本.html":{"url":"docs/prometheus相关/监控oracle/oracle--DG监控脚本.html","title":"Oracle  DG监控脚本","keywords":"","body":"conn sys/123456@oracle01 as sysdba column dest_name format a30 column destination format a20 column MEMBER format a45 column destination format a20 column TABLESPACE_NAME format a10 column FREE_RATE format a10 alter session set nls_date_format='yyyy-mm-dd hh24:mi:ss'; set wrap off; prompt ** 实 例 状 态 **; select instance_name,version,status,database_status from v$instance; prompt ** 数 据 库 状 态 *; select name,log_mode,open_mode from v$database; prompt ** 控 制 文 件 状 态 *; column name format a50 select status,name from v$controlfile; prompt ** 日 志 文 件 状 态 *; select GROUP#,status,type,member from v$logfile; prompt* 归 档 目 的 地 状 态 *; select dest_name ,status,database_mode,destination from v$archive_dest_status where dest_id in ('1','2'); set heading off; prompt ** 数 据 库 已 连 续 运 行 天 数* select round(a.atime-b.startup_time)||' days ' from(select sysdate atime from dual) a,v$instance b; set heading on; prompt* 会 话 数 *; select sessions_current,sessions_highwater from v$license; prompt** active sessions count **; select count() \"Active session count\" from v$session where status='ACTIVE'; prompt** total sessions count **•; select count() \"Total session count\" from v$session; prompt** top 30 big objects name **; column OWNER format a10 column SEGMENT_NAME format a35 column SEGMENT_TYPE format a15 column SIZES format a10 SELECT FROM ( select OWNER, SEGMENT_NAME, SEGMENT_TYPE, round(BYTES / 1024 / 1024 / 1024,3)||'G' AS SIZES from dba_segments ORDER BY BYTES DESC) WHERE ROWNUM** WANGGOUuser data size **; select sum(bytes)/1024/1024/1024||'G' \"User Data Size\" from dba_segments where owner='WANGOU'; prompt* SUP data size **; select sum(bytes)/1024/1024/1024||'G' \"User Data Size\" from dba_segments where owner='SUP'; prompt* DB size **; select sum(bytes)/1024/1024/1024||'G' \"DB Size\" from dba_segments; prompt* total tablespace size **; select sum(bytes)/1024/1024/1024||'G' \"Total Tablespace Size\" from dba_data_files; prompt* last day archive log count *; select sequence#, completion_time from v$archived_log where completion_time>= trunc(sysdate-1) and completion_time prompt** 表空间监控**; SELECT D.TABLESPACE_NAME, SPACE \"SUM_SPACE(M)\", BLOCKS \"SUM_BLOCKS(K)\", SPACE - NVL (FREE_SPACE, 0) \"USED_SPACE(M)\", ROUND( (1 - NVL (FREE_SPACE, 0) / SPACE) 100, 2) \"USED_RATE(%)\", FREE_SPACE \"FREE_SPACE(M)\" FROM ( SELECT TABLESPACE_NAME, ROUND (SUM (BYTES) / (1024 1024), 2) SPACE, SUM (BLOCKS) BLOCKS FROM DBA_DATA_FILES GROUP BY TABLESPACE_NAME) D, ( SELECT TABLESPACE_NAME, ROUND (SUM (BYTES) / (1024 1024), 2) FREE_SPACE FROM DBA_FREE_SPACE GROUP BY TABLESPACE_NAME) F WHERE D.TABLESPACE_NAME = F.TABLESPACE_NAME(+) UNION ALL --如果有 SELECT D.TABLESPACE_NAME, SPACE \"SUM_SPACE(M)\", BLOCKS SUM_BLOCKS, USED_SPACE \"USED_SPACE(M)\", ROUND (NVL (USED_SPACE, 0) / SPACE 100, 2) \"USED_RATE(%)\", NVL (FREE_SPACE, 0) \"FREE_SPACE(M)\" FROM ( SELECT TABLESPACE_NAME, ROUND (SUM (BYTES) / (1024 1024), 2) SPACE, SUM (BLOCKS) BLOCKS FROM DBA_TEMP_FILES GROUP BY TABLESPACE_NAME) D, ( SELECT TABLESPACE_NAME, ROUND (SUM (BYTES_USED) / (1024 1024), 2) USED_SPACE, ROUND (SUM (BYTES_FREE) / (1024 1024), 2) FREE_SPACE FROM V$TEMP_SPACE_HEADER GROUP BY TABLESPACE_NAME) F WHERE D.TABLESPACE_NAME = F.TABLESPACE_NAME(+) ORDER BY 1; prompt ** 表 空 间OFFLINE(显 示 为 空 正 常) **; select tablespace_name ,status from dba_tablespaces where status='OFFLINE'; prompt ** SEQUENCE 同步数 **; select max(sequence#)from v$log_history; conn sys/123456@oracle01 as sysdba prompt ** 备库SEQUENCE 同步数 *; select max(sequence#)from v$log_history; prompt ** 备库日志未应用(显 示 为 空 正 常) *; select sequence#,applied from v$archived_log where applied='yes'; prompt ** 备库日志应用(显示最近十个日志) *; select * from(select sequence#,applied from v$archived_log order by sequence# desc) where rownum 参考： https://www.cnblogs.com/kingle-study/p/10997563.html oracle_exporter https://github.com/iamseth/oracledb_exporter#installation "},"docs/prometheus相关/监控场景/监控linux.html":{"url":"docs/prometheus相关/监控场景/监控linux.html","title":"监控Linux","keywords":"","body":"方式一：有代理 node_exporter :原理读取linux /proc目录信息 方式二：无代理 SSH、SNMP、Telnet 方式 SSH：SSH公共/私有密钥的方式，禁止root用户 "},"docs/snmp/MIB/MIB工具.html":{"url":"docs/snmp/MIB/MIB工具.html","title":"MIB工具","keywords":"","body":"ManageEngine_MibBrowser_FreeTool (推荐) https://download.manageengine.com/products/mibbrowser-free-tool/9229779/ManageEngine_MibBrowser_FreeTool_64bit.exe 下载地址：http://97727.251.fileflash.com/info/ 右侧download 或：https://www.softpedia.com/get/Internet/Other-Internet-Related/ManageEngine-MibBrowser-Free-Tool.shtml 把相关 mibs放入 安装目录 mibs中、 安装的时候记得不要安装在系统盘，以免出现mib无法加载错误。 导入会自动导入同一个包的依赖，不在一个文件夹不能导入 FreeSnmp 直接抓取 不需要mib文件，不好修改团体名 默认public （使用Walk探测OID） ManageEngine MibBrowser （适用与有现成的.mib库文件） Paessler SNMP Tester getif 使用参考 https://blog.csdn.net/qq_38228830/article/details/102941064 MibBrowser (推荐) https://www.ks-soft.net/download/mibbrowser.zip "},"docs/snmp/MIB/常用oid.html":{"url":"docs/snmp/MIB/常用oid.html","title":"常用Oid","keywords":"","body":"H3C交换机，如何获取CPU内存OID cpu： 1.3.6.1.4.1.25506.2.6.1.1.1.1.6 已用内存： 1.3.6.1.4.1.25506.2.6.1.1.1.1.8 总内存： .1.3.6.1.4.1.25506.2.6.1.1.1.1.10 cisco 1.3.6.1.4.1.9.2.1.56.0 #cpu 5秒使用率 1.3.6.1.4.1.9.2.1.57.0 #cpu 1分钟使用率 1.3.6.1.4.1.9.2.1.58.0 #cpu 5分钟使用率 内存： 1.3.6.1.4.1.9.9.48.1.1.1.5 #已使用 1.3.6.1.4.1.9.9.48.1.1.1.6 #剩余 Cisco NX-OS/ACI [[inputs.snmp.field]] name = \"CPU1m\" oid = \"1.3.6.1.4.1.9.9.109.1.1.1.1.7.1\" [[inputs.snmp.field]] name = \"MemUsed\" oid = \"1.3.6.1.4.1.9.9.109.1.1.1.1.12.1\" [[inputs.snmp.field]] name = \"MemFree\" oid = \"1.3.6.1.4.1.9.9.109.1.1.1.1.13.1\" hw 1.3.6.1.4.1.2011.5.25.31.1.1.1.1.5 #OID再加上索引值 可CPU使用率 1.3.6.1.4.1.2011.6.3.4.1.2.0.0.0 CPU utilization for five seconds 1.3.6.1.4.1.2011.6.3.4.1.3.0.0.0 CPU utilization for one minute 1.3.6.1.4.1.2011.6.3.4.1.4.0.0.0 CPU utilization for five minutes 思科、华为交换机OID获取 https://blog.csdn.net/weixin_34088838/article/details/92604104 "},"docs/snmp/MIB/服务器管理.html":{"url":"docs/snmp/MIB/服务器管理.html","title":"服务器管理","keywords":"","body":"Linux #mib库 SNMPv2-MIB LM-SENSORS-MIB CPU Statistics Load 1 minute Load: .1.3.6.1.4.1.2021.10.1.3.1 5 minute Load: .1.3.6.1.4.1.2021.10.1.3.2 15 minute Load: .1.3.6.1.4.1.2021.10.1.3.3 CPU percentage of user CPU time: .1.3.6.1.4.1.2021.11.9.0 raw user cpu time: .1.3.6.1.4.1.2021.11.50.0 percentages of system CPU time: .1.3.6.1.4.1.2021.11.10.0 raw system cpu time: .1.3.6.1.4.1.2021.11.52.0 percentages of idle CPU time: .1.3.6.1.4.1.2021.11.11.0 raw idle cpu time: .1.3.6.1.4.1.2021.11.53.0 raw nice cpu time: .1.3.6.1.4.1.2021.11.51.0 Memory Statistics Total Swap Size: .1.3.6.1.4.1.2021.4.3.0 Available Swap Space: .1.3.6.1.4.1.2021.4.4.0 Total RAM in machine: .1.3.6.1.4.1.2021.4.5.0 Total RAM used: .1.3.6.1.4.1.2021.4.6.0 Total RAM Free: .1.3.6.1.4.1.2021.4.11.0 Total RAM Shared: .1.3.6.1.4.1.2021.4.13.0 Total RAM Buffered: .1.3.6.1.4.1.2021.4.14.0 Total Cached Memory: .1.3.6.1.4.1.2021.4.15.0 Disk Statistics The snmpd.conf needs to be edited. Add the following (assuming a machine with a single ‘/' partition): disk / 100000 (or) includeAllDisks 10% for all partitions and disks The OIDs are as follows: Path where the disk is mounted: .1.3.6.1.4.1.2021.9.1.2.1 Path of the device for the partition: .1.3.6.1.4.1.2021.9.1.3.1 Total size of the disk/partition (kBytes): .1.3.6.1.4.1.2021.9.1.6.1 Available space on the disk: .1.3.6.1.4.1.2021.9.1.7.1 Used space on the disk: .1.3.6.1.4.1.2021.9.1.8.1 Percentage of space used on disk: .1.3.6.1.4.1.2021.9.1.9.1 Percentage of inodes used on disk: .1.3.6.1.4.1.2021.9.1.10.1 System Uptime: .1.3.6.1.2.1.1.3.0 参考： https://support.atera.com/hc/en-us/articles/220109447-How-To-Monitor-Linux-Servers-Using-SNMP windows #mib库 HOST-RESOURCES-MIB HOST-RESOURCES-TYPES HOST-RESOURCES-MIB主要包括： hrSystem：主要包括系统启动时间、当前进程数、最大支持进程数等等。 hrstorage：主要包括物理内存大小，各个分区、虚拟内存的大小和使用情况 hrdevice：硬件设备情况、每个cpu的负载情况等 hrswrun：操作系统类型的标志、进程列表（进程的状态、名字、路径、参数等） hrSWRunPerf：每个进程占用的内存、以及占用的CPU时间（累计） hrSWinstalled：系统安装的软件信息 RFC1213MIB主要包括（跟服务器相关的）: .iso.org.dod.internet.mgmt.mib-2.udp.udpTable:服务器上的UDP端口占用情况。 .iso.org.dod.internet.mgmt.mib-2.tcp.tcpConnTable：服务器上的TCP连接情况 ———————————————— "},"docs/snmp/MIB/私有mib库.html":{"url":"docs/snmp/MIB/私有mib库.html","title":"私有Mib库","keywords":"","body":"锐捷： .1.3.6.1.4.1.4881 华为： .1.3.6.1.4.1.2011 .1.3.6.1.4.1.25506 juniper .1.3.6.1.4.1.3224 nokia .1.3.6.1.4.1.2620 天融信防火墙： .1.3.6.1.4.1.14331 "},"docs/snmp/MIB/获取设备mib文件.html":{"url":"docs/snmp/MIB/获取设备mib文件.html","title":"获取设备Mib文件","keywords":"","body":"命令 snmpwalk -v 1/2c -c community IP .1>IP.mib community ：团体名 IP ：ip地址 .1 查询所有 IP.mib ：输出到的文件名 -Cc：去掉重复 eg： snmpwalk -v2c -c public 192.168.210.254 .1 > /etc/telegraf/192.168.210.254.mib #-Cc：去掉重复 snmpwalk -v2c -c public -Cc 192.168.210.254 .1 >/etc/telegraf/192.168.210.254.mib 注意:一般来说使用snmpwalk -v 1/2c -c community IP .1>IP.mib命令采集设备MIB信息后，文件IP.mib应该包含该设备的所有MIB信息, 但是从实际反应的情况来看，某些设备产商由于SNMP实现支持不是很标准，故存在只能获取到公有MIB信息（即1.3.6.1.2.1开头的信息）的情况，此时请再使用命令snmpwalk -v 1/2c -c community IP .1.3.6.1.4.1>IP.private.mib采集设备私有MIB信息，并和前面采集到的IP.mib一同发给研发。 #两个都要 snmpwalk -v 1/2c -c community IP .1.3.6.1.4.1>IP.private.mib 小结：所谓MIB信息的完整性，即判断snmpwalk命令输出的文件信息中是否包含iso.3.6.1.2.1开头的OID信息（公有MIB信息），又是否包含iso.3.6.1.4.1开头的OID信息（私有MIB信息），甚至还可能包含iso.3.6.1.6.1开头的OID信息（该部分信息可有可无，目前暂时未用到） "},"docs/snmp/ifOperStatus和ifAdminStatus.html":{"url":"docs/snmp/ifOperStatus和ifAdminStatus.html","title":"IfOperStatus和IfAdminStatus","keywords":"","body":"配置状态就是你配置这个端口是什么状态，比如是“up” or “down”。 例如：你配置端口的状态是“up”，ifAdminStatus是“up”。 但是如果这个端口没有插线，那么ifOperStatus是“down”。 备注： 链路状态是up–>管理状态一定是up。 管理状态是down–>链路状态一定是down。 ifAdminStatus的值为up(1) ，而ifOperStatus的值down(2) ，则该接口处于故障状态。如果对象if_AdminStatus、ifOperStatus的值均为up(1) ，则接口处于正常状态；如果对象ifAdminStatus、ifOperStatus的值均为down(2) ，则接口处于停机状态；如果对象ifAdminStatus、ifOperStatus的值均为Testing(3) ，则接口处于测试状态 "},"docs/snmp/net-snmp/net-snmp-mibs库加载.html":{"url":"docs/snmp/net-snmp/net-snmp-mibs库加载.html","title":"Net Snmp Mibs库加载","keywords":"","body":"mib默认加载路径 1. $HOME/.snmp/mibs 2. /usr/local/share/snmp/mibs #查看 [root@localhost ~]# net-snmp-config --default-mibdirs /root/.snmp/mibs:/usr/share/snmp/mibs 修改默认路径 1.如果系统安装了net-snmp-config: # net-snmp-config --default-mibdirs net-snmp-config --snmpconfpath 显示;snmp.conf 的路径 net-snmp 正确加载mib （如果不能正确加载mib文件的话，就会出现\"Unknown Object Identifier\"这样的错误。） 放在 mibs路径下（/root/.snmp/mibs:/usr/share/snmp/mibs ：两个路径一个） https://my.oschina.net/u/4295888/blog/3340243 如果要net-snmp自动加载我们下载的新MIB文件，有两种方法: 方法一: 放到snmp.conf中。 用 net-snmp-config --snmpconfpath可以确定snmp.conf文件的位置 [root@Kickstart-O ~]# net-snmp-config --snmpconfpath /etc/snmp:/usr/share/snmp:/usr/lib/snmp:/root/.snmp:/var/net-snmp 将所要加载的MIB的Module名称加到snmpd.conf中，如下例： mibs +CISCO-RHINO-MIB mibs +SOME-OTHER-SPIFFY-MIB 如果图省事也可以这样，当然我们不建议这样。 mibs +ALL 因为这样有可能会提示如下错误 # snmpwalk -v2c public 192.168.1.100 Warning: Module MAU-MIB was in /usr/share/snmp/mibs//DOT3-MAU-MIB.txt now is /usr/share/snmp/mibs//RFC2668-MIB.txt Warning: Module DISMAN-EVENT-MIB was in /usr/share/snmp/mibs//EVENT-MIB.txt now is /usr/share/snmp/mibs//DISMAN-EVENT-MIB.txt Warning: Module P-BRIDGE-MIB was in /usr/share/snmp/mibs//P-BRIDGE-MIB.txt now is /usr/share/snmp/mibs//P-BRIDGE.txt 可以将标准错误文件转向来屏蔽这些警告信息 # snmpwalk -v2c public 192.168.1.100 2>/dev/null SNMPv2-MIB::sysDescr.0 = STRING: Linux server1 2.4.34-pre2 #170 Fri Sep 15 20:10:21 CEST 2006 mips SNMPv2-MIB::sysObjectID.0 = OID: NET-SNMP-TC::linux DISMAN-EVENT-MIB::sysUpTimeInstance = Timeticks: (706980) 1:57:49.80 方法二: 使用系统变量(定义MIBS变量) # MIBS=+CISCO-RHINO-MIB:SOME-OTHER-SPIFFY-MIB # export MIBS #导入MIBS "},"docs/snmp/net-snmp/net-snmp离线安装.html":{"url":"docs/snmp/net-snmp/net-snmp离线安装.html","title":"Net Snmp离线安装","keywords":"","body":"http://www.net-snmp.org/ http://www.net-snmp.org/download.html 离线安装包 rpm包下载地址：http://rpmfind.net/ lm_sensors-libs-3.1.1-17.el6.x86_64.rpmnet-snmp-libs-5.5-60.el6.x86_64.rpm net-snmp-5.5-60.el6.x86_64.rpm net-snmp-utils-5.5-60.el6.x86_64.rpm 在线安装 yum install net-snmp net-snmp-utils snmpwalk安装与使用教程 https://blog.csdn.net/sun8890446/article/details/80811878 windows版本： https://iweb.dl.sourceforge.net/project/net-snmp/net-snmp%20binaries/5.7-binaries/net-snmp-5.7.0-1.x86.exe "},"docs/snmp/net-snmp/snmp命令.html":{"url":"docs/snmp/net-snmp/snmp命令.html","title":"Snmp命令","keywords":"","body":"snmp命令 snmptable -v 2c -c public 192.168.210.254 1.3.6.1.2.1.2.2 snmpwalk -v 2c -c public 192.168.210.254 1.3.6.1.2.1.2.2.1.3 http://www.h3c.com/cn/d*201109/725296*30005_0.htm 交换机配置SNMP 配置 进入系统模式 system-view 启用：snmp-agent 关闭：undo snmp-agent 第一步连接h3c三层交换机 第二步进入特权模式 #system 第三步增加一个snmp团体名称 #snmp-agent community read community-name # read 为只读模式，write 为读写模式 #display snmp community #查看当前团体名称 #undo snmp-agent community read community-name "},"docs/snmp/net-snmp/查看udp端口.html":{"url":"docs/snmp/net-snmp/查看udp端口.html","title":"查看Udp端口","keywords":"","body":"查看UDP端口 windows nc -vuz 172.16.10.248 123 linux ncat -vuz 102.19.193.223 161 # 先在服务器上测试客户端的udp端口是不 返回 open 就是可以 linux安装： yum install -y nc windows https://eternallybored.org/misc/netcat/ 下载 把 nc.exe 放到 C:\\Windows\\System32 cmd nc -h "},"docs/snmp/snmp-网络端口.html":{"url":"docs/snmp/snmp-网络端口.html","title":"Snmp 网络端口","keywords":"","body":"snmp 网络接口 http://www.360doc.com/content/20/1117/12/18945873_946291788.shtml "},"docs/snmp/telegraf抓取.html":{"url":"docs/snmp/telegraf抓取.html","title":"Telegraf抓取","keywords":"","body":"https://github.com/influxdata/telegraf/tree/master/plugins/inputs/snmp_legacy "},"docs/snmp/windows和linux开启snmp服务.html":{"url":"docs/snmp/windows和linux开启snmp服务.html","title":"Windows和Linux开启Snmp服务","keywords":"","body":"开启snmp服务 linux开启 安装net-snmp yum install net-snmp net-snmp-utils 修改配置 #vim /etc/snmp/snmpd.conf com2sec notConfigUser default（吮许那台主机采集数据） public(共同体名字) group notConfigGroup v1 notConfigUser group notConfigGroup v2c notConfigUser view systemview included .1 access notConfigGroup \"\" any noauth exact systemview none none syslocation Unknown (edit /etc/snmp/snmpd.conf) syscontact Root wjw@163.com 重启snmpd服务 systemctl start snmpd 检查 #lsof -i :161 #netstat -nlup | grep \":161\" 或 #netstat -anp |grep snmpd windows打开 services.msc 中 snmp -->右键属性 -》安全配置团体名 和访问的地址 "},"docs/snmp/交换机端口类型.html":{"url":"docs/snmp/交换机端口类型.html","title":"交换机端口类型","keywords":"","body":"FastEthernet（百兆）、GigabitEthernet（千兆）和TenGigabitEthernet(万兆) ethernet（6）：百兆接口（10M） Fast Ethernet Interfaces（62）：百兆 gigabitethernet（117）：千兆接口 ethernet不能配置IP，是因为这个接口是二层口，所以不能设置IP fastethernet interface GigabitEthernet1/0/46 （进入千兆46端口 注解 上联另一个交换的百兆 1口 端口类型 直连终端 46口加入vlan 11 端口46上 接收 发送 的的所有报文将被镜像到端口 1/0/1上)﻿ 在局域网以太交换机中，最多，也直接的物理接口当然就是以太网接口（可能是RJ-45双绞线类型的，也可能是各种光纤类型的）了。但从所支持的以太网标准来分，现在主流的以太网接口主要有（以前传统的纯10 Mbps接口现在基本上没有了）： n 快速以太网接口（Fast Ethernet Interfaces）：最高支持100Mbps的接入速率。在配置的接口类型名称为fastethernet，可简写为fa； n 千兆以太网接口（Gigabit Ethernet Interfaces）：最高支持1000Mbps的接入速率。在配置中的接口类型名称为gigabitethernet，可简写为gi； n 10G以太网端口（10-Gigabit Ethernet Interfaces）：最高支持10000Mbps的接入速率。在配置中端口类型名称为tengigabitethernet，可简写为te。 默认情况下，所有以太网接口都是启用的。10/100Mbps自适应快速以太网接口会自动协商连接速率和双工模式；10/100/1000Mbps自适应千兆以太网接口会自动协商接入速率、双工模式和流量控制；1000Mbps千兆以太网接口仅协商流量控制，不协商接入速率。自适应模式接口的自动协商功能可自动选择通信双方端口可以承受的最高接入速率，如果为一个接口指定了明确的接入速率，则该接口默认以半双工模式工作，除非明确地设置它以全双工模式工作。 在进入接口配置模式后，你必须明确指定：接口类型（Interface type，如fastethernet、gigabitethernet、tengigabitethernet）、插槽号（Slot number，接口模块安装在哪个插槽中，是从0开始编号的）、接口号（Interface number，接口在接口模块中的编号，是从1开始编号的，交换机前面板中的接口号编排方向是从左到右依次增加的）。如果是在交换机堆叠中，则在最前面还要加上堆叠成员号（1~9）。可以使用show命令显示指定接口或者所有接口信息 "},"docs/snmp/协议比较.html":{"url":"docs/snmp/协议比较.html","title":"协议比较","keywords":"","body":"ICMP（ping） IPMI zabbix监控硬件，系统等 WMI：监控是使用代理 SSH：是使用脚本 "},"docs/snmp/监控dell物理服务器.html":{"url":"docs/snmp/监控dell物理服务器.html","title":"监控Dell物理服务器","keywords":"","body":"https://www.pianshen.com/article/5635384601/ "},"docs/snmp/监控工具.html":{"url":"docs/snmp/监控工具.html","title":"监控工具","keywords":"","body":"nmon Linux 监控 "},"docs/snmp/相关产品对应的mib库.html":{"url":"docs/snmp/相关产品对应的mib库.html","title":"相关产品对应的Mib库","keywords":"","body":"[toc] Dell R720 相关mib文件 IDRAC-MIB IDRAC-MIB-SMIv2 windows 相关mib文件 HOST-RESOURCES-TYPES HOST-RESOURCES-MIB #参考 常用的oid https://blog.csdn.net/liuhuango123/article/details/52253953 具体mib说明 一、hostmib.mib库 系统运行时间：返回数值以秒为单位 OID：.1.3.6.1.2.1.25.1.1.0 系统当前时间： OID：.1.3.6.1.2.1.25.1.2.0 主机会话数 OID：.1.3.6.1.2.1.25.1.5.0 系统进程数 OID：.1.3.6.1.2.1.25.1.6.0 系统物理内存 OID：.1.3.6.1.2.1.25.2.2.0 (4088864) 标识： OID：.1.3.6.1.2.1.25.2.3.1.3.1 C:\\ Label: Serial Number 665445ee OID：.1.3.6.1.2.1.25.2.3.1.3.2 D:\\ Label: Serial Number d852e62c OID：.1.3.6.1.2.1.25.2.3.1.3.3 E:\\ Label: Serial Number 57c15850 OID：.1.3.6.1.2.1.25.2.3.1.3.4 F:\\ Label: Serial Number b17429e7 OID：.1.3.6.1.2.1.25.2.3.1.3.5 Virtual Memory OID：.1.3.6.1.2.1.25.2.3.1.3.6 Physical Memory 每个箸/块的大小 OID：.1.3.6.1.2.1.25.2.3.1.4.1 (4096) OID：.1.3.6.1.2.1.25.2.3.1.4.2 (4096) OID：.1.3.6.1.2.1.25.2.3.1.4.3 (4096) OID：.1.3.6.1.2.1.25.2.3.1.4.4 (4096) OID：.1.3.6.1.2.1.25.2.3.1.4.5 (65536) OID：.1.3.6.1.2.1.25.2.3.1.4.6 (65536) 一个磁盘分为多少块/箸,总大小 OID：.1.3.6.1.2.1.25.2.3.1.5.1 (20972849) OID：.1.3.6.1.2.1.25.2.3.1.5.2 (47186913) OID：.1.3.6.1.2.1.25.2.3.1.5.3 (27001240) OID：.1.3.6.1.2.1.25.2.3.1.5.4 (26934972) OID：.1.3.6.1.2.1.25.2.3.1.5.5 (127748) OID：.1.3.6.1.2.1.25.2.3.1.5.6 (63888) 磁盘空间大小=簇*簇数 已经使用的块/箸 OID：.1.3.6.1.2.1.25.2.3.1.6.1 (7389539) OID：.1.3.6.1.2.1.25.2.3.1.6.2 (2737261) OID：.1.3.6.1.2.1.25.2.3.1.6.3 (31264) OID：.1.3.6.1.2.1.25.2.3.1.6.4 (1678515) OID：.1.3.6.1.2.1.25.2.3.1.6.5 (59945) OID：.1.3.6.1.2.1.25.2.3.1.6.6 (45513) 备注：在我这台主机的数据中 可以看到的盘符是C:D: E: F:；同时可以得到虚拟内存信息,物理内存的信息 C: 盘大小为4096×20972849=85904789504bytes or 80GB C: 盘以用空间4096×7389539=7566887936bytes or 7.04GB C：盘使用率为7.04/80*100% = 8% 使用类似的方法可以计算出其它盘符的使用率和空间数据 物理内存占用率：(65536*45513/1024)/4088864*100%=71.24% Cpu占用率（以上一分钟统计，不同的电脑的处理器不一样，需要使用walk来查看大概有几线程，其表头为.1.3.6.1.2.1.25.3.3.1.2，我这为4线程） OID：.1.3.6.1.2.1.25.3.3.1.2.2 （3） OID：.1.3.6.1.2.1.25.3.3.1.2.3 （2） OID：.1.3.6.1.2.1.25.3.3.1.2.4 （1） OID：.1.3.6.1.2.1.25.3.3.1.2.5 （2） ———————————————— 版权声明：本文为CSDN博主「liuhuango123」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。 原文链接：https://blog.csdn.net/liuhuango123/article/details/52253953 linux对应 相关mib文件 #mib库 LM-SENSORS-MIB lm_sensors，是一款基于linux系统的硬件监控的软件。可以监控主板，CPU的工作电压，温度等数据。 https://blog.csdn.net/apple_llb/article/details/50494787?utm_medium=distribute.pc_relevant.none-task-blog-baidujs_title-1&spm=1001.2101.3001.4242 #常用oid 具体mib说明 服务器负载： 1 minute Load: .1.3.6.1.4.1.2021.10.1.3.1 5 minute Load: .1.3.6.1.4.1.2021.10.1.3.2 15 minute Load: .1.3.6.1.4.1.2021.10.1.3.3 CPU信息： percentage of user CPU time: .1.3.6.1.4.1.2021.11.9.0 raw user cpu time: .1.3.6.1.4.1.2021.11.50.0 percentages of system CPU time: .1.3.6.1.4.1.2021.11.10.0 raw system cpu time: .1.3.6.1.4.1.2021.11.52.0 percentages of idle CPU time: .1.3.6.1.4.1.2021.11.11.0 raw idle cpu time: .1.3.6.1.4.1.2021.11.53.0 raw nice cpu time: .1.3.6.1.4.1.2021.11.51.0 内存使用： Total Swap Size: .1.3.6.1.4.1.2021.4.3.0 Available Swap Space: .1.3.6.1.4.1.2021.4.4.0 Total RAM in machine: .1.3.6.1.4.1.2021.4.5.0 Total RAM used: .1.3.6.1.4.1.2021.4.6.0 Total RAM Free: .1.3.6.1.4.1.2021.4.11.0 Total RAM Shared: .1.3.6.1.4.1.2021.4.13.0 Total RAM Buffered: .1.3.6.1.4.1.2021.4.14.0 Total Cached Memory: .1.3.6.1.4.1.2021.4.15.0 硬盘使用： Path where the disk is mounted: .1.3.6.1.4.1.2021.9.1.2.1 Path of the device for the partition: .1.3.6.1.4.1.2021.9.1.3.1 Total size of the disk/partion (kBytes): .1.3.6.1.4.1.2021.9.1.6.1 Available space on the disk: .1.3.6.1.4.1.2021.9.1.7.1 Used space on the disk: .1.3.6.1.4.1.2021.9.1.8.1 Percentage of space used on disk: .1.3.6.1.4.1.2021.9.1.9.1 Percentage of inodes used on disk: .1.3.6.1.4.1.2021.9.1.10.1 系统运行时间： .1.3.6.1.2.1.1.3.0 SNMP System Group： sysDescr 1.3.6.1.2.1.1.1 sysObjectID 1.3.6.1.2.1.1.2 sysUpTime 1.3.6.1.2.1.1.3 sysContact 1.3.6.1.2.1.1.4 sysName 1.3.6.1.2.1.1.5 sysLocation 1.3.6.1.2.1.1.6 sysServices 1.3.6.1.2.1.1.7 SNMP Interfaces Group： ifNumber 1.3.6.1.2.1.2.1 ifTable 1.3.6.1.2.1.2.2 ifEntry 1.3.6.1.2.1.2.2.1 ifIndex 1.3.6.1.2.1.2.2.1.1 ifDescr 1.3.6.1.2.1.2.2.1.2 ifType 1.3.6.1.2.1.2.2.1.3 ifMtu 1.3.6.1.2.1.2.2.1.4 ifSpeed 1.3.6.1.2.1.2.2.1.5 ifPhysAddress 1.3.6.1.2.1.2.2.1.6 ifAdminStatus 1.3.6.1.2.1.2.2.1.7 ifOperStatus 1.3.6.1.2.1.2.2.1.8 ifLastChange 1.3.6.1.2.1.2.2.1.9 ifInOctets 1.3.6.1.2.1.2.2.1.10 ifInUcastPkts 1.3.6.1.2.1.2.2.1.11 ifInNUcastPkts 1.3.6.1.2.1.2.2.1.12 ifInDiscards 1.3.6.1.2.1.2.2.1.13 ifInErrors 1.3.6.1.2.1.2.2.1.14 ifInUnknownProtos 1.3.6.1.2.1.2.2.1.15 ifOutOctets 1.3.6.1.2.1.2.2.1.16 ifOutUcastPkts 1.3.6.1.2.1.2.2.1.17 ifOutNUcastPkts 1.3.6.1.2.1.2.2.1.18 ifOutDiscards 1.3.6.1.2.1.2.2.1.19 ifOutErrors 1.3.6.1.2.1.2.2.1.20 ifOutQLen 1.3.6.1.2.1.2.2.1.21 ifSpecific 1.3.6.1.2.1.2.2.1.22 SNMP IP Group ipForwarding 1.3.6.1.2.1.4.1 ipDefaultTTL 1.3.6.1.2.1.4.2 ipInReceives 1.3.6.1.2.1.4.3 ipInHdrErrors 1.3.6.1.2.1.4.4 ipInAddrErrors 1.3.6.1.2.1.4.5 ipForwDatagrams 1.3.6.1.2.1.4.6 ipInUnknownProtos 1.3.6.1.2.1.4.7 ipInDiscards 1.3.6.1.2.1.4.8 ipInDelivers 1.3.6.1.2.1.4.9 ipOutRequests 1.3.6.1.2.1.4.10 ipOutDiscards 1.3.6.1.2.1.4.11 ipOutNoRoutes 1.3.6.1.2.1.4.12 ipReasmTimeout 1.3.6.1.2.1.4.13 ipReasmReqds 1.3.6.1.2.1.4.14 ipReasmOKs 1.3.6.1.2.1.4.15 ipReasmFails 1.3.6.1.2.1.4.16 ipFragsOKs 1.3.6.1.2.1.4.17 ipFragsFails 1.3.6.1.2.1.4.18 ipFragCreates 1.3.6.1.2.1.4.19 ipAddrTable 1.3.6.1.2.1.4.20 ipAddrEntry 1.3.6.1.2.1.4.20.1 ipAdEntAddr 1.3.6.1.2.1.4.20.1.1 ipAdEntIfIndex 1.3.6.1.2.1.4.20.1.2 ipAdEntNetMask 1.3.6.1.2.1.4.20.1.3 ipAdEntBcastAddr 1.3.6.1.2.1.4.20.1.4 ipAdEntReasmMaxSize 1.3.6.1.2.1.4.20.1.5 SNMP ICMP Group icmpInMsgs 1.3.6.1.2.1.5.1 icmpInErrors 1.3.6.1.2.1.5.2 icmpInDestUnreachs 1.3.6.1.2.1.5.3 icmpInTimeExcds 1.3.6.1.2.1.5.4 icmpInParmProbs 1.3.6.1.2.1.5.5 icmpInSrcQuenchs 1.3.6.1.2.1.5.6 icmpInRedirects 1.3.6.1.2.1.5.7 icmpInEchos 1.3.6.1.2.1.5.8 icmpInEchoReps 1.3.6.1.2.1.5.9 icmpInTimestamps 1.3.6.1.2.1.5.10 icmpInTimestampReps 1.3.6.1.2.1.5.11 icmpInAddrMasks 1.3.6.1.2.1.5.12 icmpInAddrMaskReps 1.3.6.1.2.1.5.13 icmpOutMsgs 1.3.6.1.2.1.5.14 icmpOutErrors 1.3.6.1.2.1.5.15 icmpOutDestUnreachs 1.3.6.1.2.1.5.16 icmpOutTimeExcds 1.3.6.1.2.1.5.17 icmpOutParmProbs 1.3.6.1.2.1.5.18 icmpOutSrcQuenchs 1.3.6.1.2.1.5.19 icmpOutRedirects 1.3.6.1.2.1.5.20 icmpOutEchos 1.3.6.1.2.1.5.21 icmpOutEchoReps 1.3.6.1.2.1.5.22 icmpOutTimestamps 1.3.6.1.2.1.5.23 icmpOutTimestampReps 1.3.6.1.2.1.5.24 icmpOutAddrMasks 1.3.6.1.2.1.5.25 icmpOutAddrMaskReps 1.3.6.1.2.1.5.26 SNMP TCP Group： tcpRtoAlgorithm 1.3.6.1.2.1.6.1 tcpRtoMin 1.3.6.1.2.1.6.2 tcpRtoMax 1.3.6.1.2.1.6.3 tcpMaxConn 1.3.6.1.2.1.6.4 tcpActiveOpens 1.3.6.1.2.1.6.5 tcpPassiveOpens 1.3.6.1.2.1.6.6 tcpAttemptFails 1.3.6.1.2.1.6.7 tcpEstabResets 1.3.6.1.2.1.6.8 tcpCurrEstab 1.3.6.1.2.1.6.9 tcpInSegs 1.3.6.1.2.1.6.10 tcpOutSegs 1.3.6.1.2.1.6.11 tcpRetransSegs 1.3.6.1.2.1.6.12 tcpConnTable 1.3.6.1.2.1.6.13 tcpConnEntry 1.3.6.1.2.1.6.13.1 tcpConnState 1.3.6.1.2.1.6.13.1.1 tcpConnLocalAddress 1.3.6.1.2.1.6.13.1.2 tcpConnLocalPort 1.3.6.1.2.1.6.13.1.3 tcpConnRemAddress 1.3.6.1.2.1.6.13.1.4 tcpConnRemPort 1.3.6.1.2.1.6.13.1.5 tcpInErrs 1.3.6.1.2.1.6.14 tcpOutRsts 1.3.6.1.2.1.6.15 SNMP UDP Group udpInDatagrams 1.3.6.1.2.1.7.1 udpNoPorts 1.3.6.1.2.1.7.2 udpInErrors 1.3.6.1.2.1.7.3 udpOutDatagrams 1.3.6.1.2.1.7.4 udpTable 1.3.6.1.2.1.7.5 udpEntry 1.3.6.1.2.1.7.5.1 udpLocalAddress 1.3.6.1.2.1.7.5.1.1 udpLocalPort 1.3.6.1.2.1.7.5.1.2 SNMP Group： snmpInPkts 1.3.6.1.2.1.11.1 snmpOutPkts 1.3.6.1.2.1.11.2 snmpInBadVersions 1.3.6.1.2.1.11.3 snmpInBadCommunityNames 1.3.6.1.2.1.11.4 snmpInBadCommunityUses 1.3.6.1.2.1.11.5 snmpInASNParseErrs 1.3.6.1.2.1.11.6 NOT USED 1.3.6.1.2.1.11.7 snmpInTooBigs 1.3.6.1.2.1.11.8 snmpInNoSuchNames 1.3.6.1.2.1.11.9 snmpInBadValues 1.3.6.1.2.1.11.10 snmpInReadOnlys 1.3.6.1.2.1.11.11 snmpInGenErrs 1.3.6.1.2.1.11.12 snmpInTotalReqVars 1.3.6.1.2.1.11.13 snmpInTotalSetVars 1.3.6.1.2.1.11.14 snmpInGetRequests 1.3.6.1.2.1.11.15 snmpInGetNexts 1.3.6.1.2.1.11.16 snmpInSetRequests 1.3.6.1.2.1.11.17 snmpInGetResponses 1.3.6.1.2.1.11.18 snmpInTraps 1.3.6.1.2.1.11.19 snmpOutTooBigs 1.3.6.1.2.1.11.20 snmpOutNoSuchNames 1.3.6.1.2.1.11.21 snmpOutBadValues 1.3.6.1.2.1.11.22 NOT USED 1.3.6.1.2.1.11.23 snmpOutGenErrs 1.3.6.1.2.1.11.24 snmpOutGetRequests 1.3.6.1.2.1.11.25 snmpOutGetNexts 1.3.6.1.2.1.11.26 snmpOutSetRequests 1.3.6.1.2.1.11.27 snmpOutGetResponses 1.3.6.1.2.1.11.28 snmpOutTraps 1.3.6.1.2.1.11.29 snmpEnableAuthenTraps 1.3.6.1.2.1.11.30 应用示例： 查看服务器1分钟平均负载： snmpwalk -v1 -c public 127.0.0.1 .1.3.6.1.4.1.2021.10.1.3.1 UCD-SNMP-MIB::laLoad.1 = STRING: 0.25 查看服务器当前连接： snmpwalk -v1 -c public 127.0.0.1 1.3.6.1.2.1.6.13.1.1 TCP-MIB::tcpConnState.0.0.0.0.22.0.0.0.0.0 = INTEGER: listen(2) TCP-MIB::tcpConnState.0.0.0.0.80.0.0.0.0.0 = INTEGER: listen(2) TCP-MIB::tcpConnState.0.0.0.0.111.0.0.0.0.0 = INTEGER: listen(2) TCP-MIB::tcpConnState.0.0.0.0.443.0.0.0.0.0 = INTEGER: listen(2) TCP-MIB::tcpConnState.0.0.0.0.3306.0.0.0.0.0 = INTEGER: listen(2) TCP-MIB::tcpConnState.127.0.0.1.25.0.0.0.0.0 = INTEGER: listen(2) TCP-MIB::tcpConnState.127.0.0.1.199.0.0.0.0.0 = INTEGER: listen(2) TCP-MIB::tcpConnState.192.168.1.2.22.192.168.1.16.5035 = INTEGER: established(5) TCP-MIB::tcpConnState.192.168.1.2.22.192.168.1.16.10518 = INTEGER: established(5) TCP-MIB::tcpConnState.192.168.1.2.22.192.168.1.16.24713 = INTEGER: established(5) "},"docs/snmp/网络端口流量计算.html":{"url":"docs/snmp/网络端口流量计算.html","title":"网络端口流量计算","keywords":"","body":" "},"docs/springboot/Http请求几种方式.html":{"url":"docs/springboot/Http请求几种方式.html","title":"Http请求几种方式","keywords":"","body":"https://blog.csdn.net/riemann_/article/details/90539829 okhttp：常用 通过SpringBoot-RestTemplate：常用 通过apache common封装好的HttpClient 通过JDK网络类Java.net.HttpURLConnection RestTemplate + okhttp合用 https://www.imooc.com/article/301043 "},"docs/springboot/logback日志.html":{"url":"docs/springboot/logback日志.html","title":"Logback日志","keywords":"","body":"包引入 springboot的pom文件都会引一个parent org.springframework.boot spring-boot-starter-parent 2.0.0.RELEASE 点进去这个parent，会有一个这个dependency org.springframework.boot spring-boot-dependencies 2.0.0.RELEASE ../../spring-boot-dependencies 再点进去就是2.0版本，所谓的它给你集成的各种包依赖，而且规定了版本号，其中有一个包如下 org.springframework.boot spring-boot-starter 2.0.0.RELEASE 再点进去 org.springframework.boot spring-boot-starter-logging 2.0.0.RELEASE compile 再点，这些都是原有的日志包，所以，不必再引依赖了，直接用就ok了，用法如下： ch.qos.logback logback-classic 1.2.3 compile org.apache.logging.log4j log4j-to-slf4j 2.10.0 compile org.slf4j jul-to-slf4j 1.7.25 compile 官方推荐使用的xml名字的格式为：logback-spring.xml而不是logback.xml --> logback info ${CONSOLE_LOG_PATTERN} UTF-8 ${log.path}/log_debug.log %d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n UTF-8 ${log.path}/debug/log-debug-%d{yyyy-MM-dd}.%i.log 100MB 15 debug ACCEPT DENY ${log.path}/log_info.log %d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n UTF-8 ${log.path}/info/log-info-%d{yyyy-MM-dd}.%i.log 100MB 15 info ACCEPT DENY ${log.path}/log_warn.log %d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n UTF-8 ${log.path}/warn/log-warn-%d{yyyy-MM-dd}.%i.log 100MB 15 warn ACCEPT DENY ${log.path}/log_error.log %d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n UTF-8 ${log.path}/error/log-error-%d{yyyy-MM-dd}.%i.log 100MB 15 ERROR ACCEPT DENY 用来设置某一个包或者具体的某一个类的日志打印级别、 以及指定。仅有一个name属性， 一个可选的level和一个可选的addtivity属性。 name:用来指定受此logger约束的某一个包或者具体的某一个类。 level:用来设置打印级别，大小写无关：TRACE, DEBUG, INFO, WARN, ERROR, ALL 和 OFF， 还有一个特俗值INHERITED或者同义词NULL，代表强制执行上级的级别。 如果未设置此属性，那么当前logger将会继承上级的级别。 addtivity:是否向上级logger传递打印信息。默认是true。 --> --> --> 改成这样就会打印sql，不过这样日志那边会出现很多其他消息 第二种就是单独给dao下目录配置debug模式，代码如下，这样配置sql语句会打印，其他还是正常info级别： --> --> --> --> --> --> --> --> --> --> "},"docs/springboot/springmvc注释.html":{"url":"docs/springboot/springmvc注释.html","title":"Springmvc注释","keywords":"","body":"参考： https://blog.csdn.net/weixin_38004638/article/details/99655322 @GetMapping，处理get请求 @PostMapping，处理post请求 @PutMapping，处理put请求 @DeleteMapping，处理delete请求 @PostMapping(value = \"/user/login\") 等于@RequestMapping(value = \"/user/login\",method = RequestMethod.POST) @RequestParam(\"username\" ) String username, @RequestParam Map params params.get(\"instance\") @RequestParam有三个配置参数： required 表示是否必须，默认为 true，必须。 defaultValue 可设置请求参数的默认值。 value 为接收url的参数名（相当于key值）。 @RequestParam用来处理 Content-Type 为 application/x-www-form-urlencoded 编码的内容，Content-Type默认为该属性。@RequestParam也可用于其它类型的请求，例如：POST、DELETE等请求。不能批量操作 不推荐使用@RequestParam接收application/json，这时候就需要使用到@RequestBody。 向表中批量插入数据 举个批量插入数据的例子，Controller层的写法如下图所示 @GetMapping(\"/winDetail/{instance}\") @PathVariable(\"instance\")String instance "},"docs/springboot/插件/pagehelper.html":{"url":"docs/springboot/插件/pagehelper.html","title":"Pagehelper","keywords":"","body":"pagehelper配置 导入依赖包 com.github.pagehelper pagehelper-spring-boot-starter 1.2.13 配置 在application.properties配置文件中添加以下配置： #pagehelper分页插件配置 pagehelper.helperDialect=mysql pagehelper.reasonable=true pagehelper.supportMethodsArguments=true pagehelper.params=count=countSql 使用 在controller中加入 语法 //PageHelper.startPage(pageNo,pageSize); @GetMapping(\"/users\") public List lists(@RequestParam(defaultValue = \"1\") int pageNo, @RequestParam(defaultValue = \"10\") int pageSize) { PageHelper.startPage(pageNo,pageSize); return userService.getUsers(); } 说明： pagehelper 只对startpage下的第一个语句有用 pageNo和pageSize两个参数是为了接收前台传过来的值，并且通过defaultValue为这两个参数提供了默认值。 分页主要代码：PageHelper.startPage(pageNo,pageSize); 实例 第一个返回分页数据 第二个返回分页信息，及包含总页数、当前页数、每页条数等分页相关的信息 创建mapper package com.jeff.mapper; import java.util.List; import org.apache.ibatis.annotations.Mapper; import org.apache.ibatis.annotations.Param; import org.apache.ibatis.annotations.Select; import com.github.pagehelper.Page; import com.jeff.entity.User; @Mapper public interface UserMapper { @Select(\"select * from sys_user where id=#{id}\") User getUserById(@Param(\"id\") Long id); @Select(\"select * from sys_user\") List getUserList(); @Select(\"select * from sys_user\") Page getUserList2(); } 创建service package com.jeff.service; import java.util.List; import com.github.pagehelper.Page; import com.jeff.entity.User; public interface UserService { User getUserById(Long id); List getUserList1(); Page getUserList2(); } 创建serviceImpl package com.jeff.service.impl; import java.util.List; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Service; import com.github.pagehelper.Page; import com.jeff.entity.User; import com.jeff.mapper.UserMapper; import com.jeff.service.UserService; @Service public class UserServiceImpl implements UserService { @Autowired private UserMapper mapper; @Override public User getUserById(Long id) { return mapper.getUserById(id); } @Override public List getUserList1() { return mapper.getUserList(); } @Override public Page getUserList2() { return mapper.getUserList2(); } } 创建controller 方法二也可以这样 用com.github.pagehelper.PageInfo类封装Page数据 PageInfo pageInfo = new PageInfo<>(getUserList2()); package com.jeff.controller; import java.util.List; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; import com.github.pagehelper.Page; import com.github.pagehelper.PageHelper; import com.github.pagehelper.PageInfo; import com.jeff.entity.User; import com.jeff.entity.request.PageEntity; import com.jeff.service.UserService; @RestController @RequestMapping(\"user\") public class UserController { @Autowired private UserService service; @RequestMapping(\"getUserById\") public User getUserById(Long id) { return service.getUserById(id); } /** * * @description: 分页查询方法一 * @author: Jeff * @date: 2020年3月14日 * @param page * @return */ @RequestMapping(\"getUserList1\") public Object getUserList1(PageEntity page) { PageHelper.startPage(page.getPage(), page.getRows()); List list = service.getUserList1(); PageInfo pageInfo = new PageInfo<>(list); return pageInfo; } /** * * @description: 分页查询方法二 * @author: Jeff * @date: 2020年3月14日 * @param page * @return */ @RequestMapping(\"getUserList2\") public Object getUserList2(PageEntity page) { PageHelper.startPage(page.getPage(), page.getRows()); Page list = service.getUserList2(); return list; } } "},"docs/springboot完整项目/大幅度发.html":{"url":"docs/springboot完整项目/大幅度发.html","title":"大幅度发","keywords":"","body":"步骤： idea环境搭建： 插件准备： maven helper ，restfultool，mybatis log 一、整合springboot-mybatisplus 二、整合 shiro 用户登录 "},"docs/springboot完整项目/开源流程.html":{"url":"docs/springboot完整项目/开源流程.html","title":"开源流程","keywords":"","body":"步骤： idea环境搭建： 插件准备： maven helper ，restfultool，mybatis log 一、整合springboot-mybatisplus 二、整合 shiro 用户登录 https://www.jianshu.com/p/7f724bec3dc3 "},"docs/tomcat/tomcat启动配置.html":{"url":"docs/tomcat/tomcat启动配置.html","title":"Tomcat启动配置","keywords":"","body":"第一步： vim catalina.sh 在 CLASSPATH 上添加 CATALINA_PID=\"CATALINA_BASE/tomcat.pid\" 一、添加配置文件 /etc/systemd/system/tomcat.service [Unit] Description=Tomcat After=syslog.target network.target remote-fs.target nss-lookup.target [Service] Type=forking Environment=\"JAVA_HOME=/usr/java/jdk1.8.0_191\" PIDFile=/usr/local/tomcat8/tomcat.pid ExecStart=/usr/local/tomcat8/bin/startup.sh ExecReload=/bin/kill -s HUP $MAINPID ExecStop=/bin/kill -s QUIT $MAINPID PrivateTmp=true [Install] WantedBy=multi-user.target "},"docs/vmware/vmware扩容.html":{"url":"docs/vmware/vmware扩容.html","title":"Vmware扩容","keywords":"","body":"vmware虚拟机扩容 扩展vmware-centos7硬盘空间 关闭Vmware的centos7系统，才能在VMWare菜单中设置需要增加到的磁盘大小 如果这个选项是灰色的，说明此虚拟机建有快照，把快照全部删除再试试! 或者web界面： 选中虚拟机->虚拟机设置->硬盘->实用工具->扩展->设置最大磁盘大小->点击扩展 对新增加的硬盘进行分区、格式化 我们增加了空间的硬盘是 /dev/sda 分区： [root@localhost]# fdisk /dev/sda　　　　 p　　　　　　　查看已分区数量（我看到有两个 /dev/sda1 /dev/sda2） n　　　　　　　新增加一个分区 p　　　　　　　分区类型我们选择为主分区 　　　　　　 分区号输入3（因为1,2已经用过了,sda1是分区1,sda2是分区2,sda3分区3） 回车　　　　　 默认（起始扇区） 回车　　　　　 默认（结束扇区） t　　　　　　　 修改分区类型 　　　　　　 选分区3 8e　　　　　 　修改为LVM（8e就是LVM） w　　　　　 　写分区表 q　　　　　 　完成，退出fdisk命令 使用partprobe 命令 或者重启机器 格式化分区3命令: mkfs.ext3 /dev/sda3 添加新lvm到已有的lvm组，实现扩容 lvm　　　　　　　　　　　　 进入lvm管理 lvm>pvcreate /dev/sda3　　 这是初始化刚才的分区3 lvm>vgextend centos /dev/sda3 将初始化过的分区加入到虚拟卷组centos (卷和卷组的命令可以通过 vgdisplay ) lvm>vgdisplay -v或者vgdisplay查看free PE /Site lvm>lvextend -l+6143 /dev/mapper/centos-root　　扩展已有卷的容量（6143 是通过vgdisplay查看free PE /Site的大小） lvm>pvdisplay 查看卷容量，这时你会看到一个很大的卷了 lvm>quit 　退出 上面只是卷扩容了，下面是文件系统的真正扩容，输入以下命令： CentOS7下面由于使用的是XFS命令: /dev/mapper/centos-root是df -h查看到根目录的挂载点 xfs_growfs /dev/mapper/centos-root 参考文章： https://blog.csdn.net/Wang_Xin_SH/article/details/77872885?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.control&dist_request_id=192a8808-ed95-4e2d-9a6e-d54b687bcbc5&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.control https://blog.csdn.net/zzchances/article/details/89918277 "},"docs/vmware/虚拟机扩容-home转root.html":{"url":"docs/vmware/虚拟机扩容-home转root.html","title":"虚拟机扩容 Home转Root","keywords":"","body":"mkdir /backup mv /home/* /backup/ umount /home lvremove /dev/centos/home lvcreate -L 50G -n home cents mkfs -t xfs /dev/centos/home mv /backup/* /home/ lvextend -L +xxxG /dev/centos/root xfs_growfs root rm -rf /backup mkdir /backup && mv /home/* /backup umount /home lvremove /dev/centos/home //删除逻辑卷home lvcreate -L 50G -n home cents vgchange -ay centos mkfs -t xfs /dev/centos/home mount /dev/centos/home /home/ mv /backup/* /home lvextend -L +xxxG /dev/centos/root vgchange -ay centos xfs_growfs /dev/centos/root mkdir /backup && mv /home/* /backup umount /home lvremove /dev/centos/home //删除逻辑卷home vgdisplay //查看卷组可用空间 Free PE / Size 中显示的空间为卷组的空闲空间 home释放的 lvcreate -L 50G -n home centos //L表示大小，默认单位为M；n表示卷名；这里的centos是CentOS7安装系统的时候就默认建立好的卷组名 lvdisplay //查看逻辑卷home vgdisplay //再次查看卷组空间大小 vgchange -ay centos //可选步骤：激活卷组centos，使得这个新建的home逻辑卷生效 mkfs -t xfs /dev/centos/home //在新建的逻辑卷home上建立xfs文件系统 mount /dev/centos/home /home/ //把这个新逻辑卷home挂到之前的文件夹/home中去，直接重启用fstab来挂载也行 df -h //现在来查看磁盘使用情况 mv /backup/* /home //再把之前拷出来的东西拷回新建的/home中 lvextend -L +xxxG /dev/centos/root //把剩下的823G现在分配给root卷，剩下那点渣渣空间让它闲着；+号表示在原来的基础上额外增加，不要加好则设定为具体额度 vgchange -ay centos xfs_growfs /dev/centos/root 查看磁盘使用情况 df -h vgdisplay //查看逻辑卷组情况 lvdisplay //查看逻辑卷情况，默认三个，root、home和交换空间swap fdisk -l "},"docs/vmware/虚拟机扩容.html":{"url":"docs/vmware/虚拟机扩容.html","title":"虚拟机扩容","keywords":"","body":"VMware分配空间 选中虚拟机->虚拟机设置->硬盘->实用工具->扩展->设置最大磁盘大小->点击扩展 二、查看当前磁盘空间，/dev/mapper/cl-root硬盘空间只有8GB，打算扩容： df -h Filesystem Size Used Avail Use% Mounted on /dev/mapper/cl-root 8.0G 3.8G 4.3G 47% / devtmpfs 482M 0 482M 0% /dev tmpfs 493M 0 493M 0% /dev/shm tmpfs 493M 6.7M 486M 2% /run tmpfs 493M 0 493M 0% /sys/fs/cgroup /dev/sda1 1014M 184M 831M 19% /boot tmpfs 99M 0 99M 0% /run/user/0 对新增的硬盘空间做新增分区（硬盘数没有增加，增加的是空间） fdisk /dev/sda Welcome to fdisk (util-linux 2.23.2). Changes will remain in memory only, until you decide to write them. Be careful before using the write command. Command (m for help): n Partition type: p primary (2 primary, 0 extended, 2 free) e extended Select (default p): p Partition number (3,4, default 3): 3 First sector (20971520-41943039, default 20971520): Using default value 20971520 Last sector, +sectors or +size{K,M,G} (20971520-41943039, default 41943039): Using default value 41943039 Partition 3 of type Linux and of size 10 GiB is set Command (m for help): t Partition number (1-3, default 3): 3 Hex code (type L to list all codes): 8e Changed type of partition 'Linux' to 'Linux LVM' Command (m for help): p Disk /dev/sda: 21.5 GB, 21474836480 bytes, 41943040 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk label type: dos Disk identifier: 0x000bc924 Device Boot Start End Blocks Id System /dev/sda1 * 2048 2099199 1048576 83 Linux /dev/sda2 2099200 20971519 9436160 8e Linux LVM /dev/sda3 20971520 41943039 10485760 8e Linux LVM Command (m for help): w The partition table has been altered! Calling ioctl() to re-read partition table. WARNING: Re-reading the partition table failed with error 16: Device or resource busy. The kernel still uses the old table. The new table will be used at the next reboot or after you run partprobe(8) or kpartx(8) Syncing disks. 重启系统 reboot 查看当前分区类型，本例类型为xfs df -T /dev/sda1 Filesystem Type 1K-blocks Used Available Use% Mounted on /dev/sda1 xfs 1038336 188240 850096 19% /boot 在新磁盘上创建xfs文件系统 mkfs.xfs /dev/sda3 meta-data=/dev/sda3 isize=512 agcount=4, agsize=655360 blks = sectsz=512 attr=2, projid32bit=1 = crc=1 finobt=0, sparse=0 data = bsize=4096 blocks=2621440, imaxpct=25 = sunit=0 swidth=0 blks naming =version 2 bsize=4096 ascii-ci=0 ftype=1 log =internal log bsize=4096 blocks=2560, version=2 = sectsz=512 sunit=0 blks, lazy-count=1 realtime =none extsz=4096 blocks=0, rtextents=0 创建PV pvcreate /dev/sda3 WARNING: xfs signature detected on /dev/sda3 at offset 0. Wipe it? [y/n]: y Wiping xfs signature on /dev/sda3. Physical volume \"/dev/sda3\" successfully created. pvdisplay --- Physical volume --- PV Name /dev/sda2 VG Name cl PV Size 9.00 GiB / not usable 3.00 MiB Allocatable yes (but full) PE Size 4.00 MiB Total PE 2303 Free PE 0 Allocated PE 2303 PV UUID MlRwjY-TmVF-H8PV-heSz-ALGL-Q7sp-jFU6Al \"/dev/sda3\" is a new physical volume of \"10.00 GiB\" --- NEW Physical volume --- PV Name /dev/sda3 VG Name PV Size 10.00 GiB Allocatable NO PE Size 0 Total PE 0 Free PE 0 Allocated PE 0 PV UUID 0hmgH0-0wVg-jWUW-65WX-1TYb-sUGH-6jF1qm PV加入VG，vgextend后接VG Name，本例中为cl vgdisplay --- Volume group --- VG Name cl System ID Format lvm2 Metadata Areas 1 Metadata Sequence No 3 VG Access read/write VG Status resizable MAX LV 0 Cur LV 2 Open LV 2 Max PV 0 Cur PV 1 Act PV 1 VG Size 9.00 GiB PE Size 4.00 MiB Total PE 2303 Alloc PE / Size 2303 / 9.00 GiB Free PE / Size 0 / 0 VG UUID dYdb4l-wMUh-e2xv-WiaJ-Oa52-NvdF-s5ICJC vgextend cl /dev/sda3 VG加入LV lvextend -l +2559 /dev/cl/root Size of logical volume cl/root changed from 8.00 GiB (2047 extents) to 17.99 GiB (4606 extents). Logical volume cl/root successfully resized. 后两个参数“+2559”和“/dev/cl/root”来源详解： “+2559”来自于vgdisplay命令的Free PE/Size字段 vgdisplay --- Volume group --- VG Name cl ... VG Size 18.99 GiB PE Size 4.00 MiB Total PE 4862 Alloc PE / Size 2303 / 9.00 GiB Free PE / Size 2559 / 10.00 GiB VG UUID dYdb4l-wMUh-e2xv-WiaJ-Oa52-NvdF-s5ICJC “/dev/cl/root”来自于lvdisplay命令的LV Path字段。 lvdisplay ... --- Logical volume --- LV Path /dev/cl/root ... 调整文件系统大小，本例中是xfs文件系统使用xfs_growfs命令调整，若其他文件系统，如ext4使用resize2fs命令，注意区分。 xfs_growfs /dev/cl/root meta-data=/dev/mapper/cl-root isize=512 agcount=4, agsize=524032 blks = sectsz=512 attr=2, projid32bit=1 = crc=1 finobt=0 spinodes=0 data = bsize=4096 blocks=2096128, imaxpct=25 = sunit=0 swidth=0 blks naming =version 2 bsize=4096 ascii-ci=0 ftype=1 log =internal bsize=4096 blocks=2560, version=2 = sectsz=512 sunit=0 blks, lazy-count=1 realtime =none extsz=4096 blocks=0, rtextents=0 data blocks changed from 2096128 to 4716544 结果 /dev/mapper/cl-root从8G增加到了18G df -h Filesystem Size Used Avail Use% Mounted on /dev/mapper/cl-root 18G 3.8G 15G 21% / devtmpfs 482M 0 482M 0% /dev tmpfs 493M 0 493M 0% /dev/shm tmpfs 493M 6.7M 486M 2% /run tmpfs 493M 0 493M 0% /sys/fs/cgroup /dev/sda1 1014M 184M 831M 19% /boot tmpfs 99M 0 99M 0% /run/user/0 "},"docs/vpn/Goflyway配置.html":{"url":"docs/vpn/Goflyway配置.html","title":"Goflyway配置","keywords":"","body":"服务器：209.246.143.78 9999 Aa123456 CDN 文件位置 goflyway_x64.exe 右键：代理模式--全局模式 "},"docs/vpn/vps申请.html":{"url":"docs/vpn/vps申请.html","title":"Vps申请","keywords":"","body":"https://github.com/Alvin9999/new-pac/wiki/%E8%87%AA%E5%BB%BAss%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%95%99%E7%A8%8B vps申请 一、申请虚机 www.vultr.com 315824016@qq.com WJWwjw59510.... 1、点左侧server 进行购买 2、测试ip是否是东京的 https://ip.cn/ 3、xshell连接 二、执行命令 wget --no-check-certificate https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocks.sh chmod +x shadowsocks.sh ./shadowsocks.sh 2>&1 | tee shadowsocks.log 设置连接密码和端口 设置的结果： Your Server IP : 66.42.45.247 Your Server Port : 8888 Your Password : 106511 Your Encryption Method: aes-256-cfb #一定要选这个7，iphone支持这个 三、加速 锐速不支持Openvz！！！锐速不支持Openvz！！！锐速不支持Openvz！ 检测： 执行一键安装锐速命令 wget -N --no-check-certificate https://raw.githubusercontent.com/91yun/serverspeeder/master/serverspeeder-all.sh && bash serverspeeder-all.sh 要是有提示：锐速不支持该内核 rpm -ivh http://soft.91yun.org/ISO/Linux/CentOS/kernel/kernel-3.10.0-229.1.2.el7.x86_64.rpm --force 然后：重启 reboot 再次执行安装命令 wget -N --no-check-certificate https://raw.githubusercontent.com/91yun/serverspeeder/master/serverspeeder-all.sh && bash serverspeeder-all.sh 选 1 其他： 卸载 chattr -i /serverspeeder/etc/apx* && /serverspeeder/bin/serverSpeeder.sh uninstall -f 锐速相关命令 service serverSpeeder status 查看serverSpeeder的状态 service serverSpeeder start | stop | restart 停止暂停重启锐速 四、配置多客户端 配置文件路径及代码： vi /etcconfig.json 按i编辑，esc退出编辑，然后按Shift+Q编辑状态输入wq保存 { \"port_password\":{ \"8989\":\"password0\", \"9001\":\"password1\", \"9002\":\"password2\", \"9003\":\"password3\", \"9004\":\"password4\" }, \"method\":\"aes-256-cfb\", \"timeout\":600 } 五、客户端安装 iphone： 1、iphone下载wingy（免费的），app store里搜wingy（中国app store已经下架，可以换到美国账户下载） https://itunes.apple.com/us/app/wingy-proxy-for-http-s-socks5/id1178584911?mt=8 点击选择线路--新增线路--shadowsocks--依次填入刚才记录的信息就好--保存--点击连接就可以了 这样就翻墙成功了 2、windows https://github.com/shadowsocks/shadowsocks-windows/releases 下载Shadowsocks-4.0.6.zip 解压：填入之前记录的自己的服务器信息，点击确定 在电脑右下角任务栏找到ss图标，右键点击，点击启用系统代理就可以了，试试上google吧 3、android https://github.com/shadowsocks/shadowsocks-android/releases 添加配置就可以了 [https://www.amz520.com/articles/25048.html "},"docs/vscode/vscode使用.html":{"url":"docs/vscode/vscode使用.html","title":"Vscode使用","keywords":"","body":"vscode使用教程 命令面板 命令面板：ctrl+shift+p 命令快捷键 调试： ctrl+shift+y 命令面板中可以搜索命令，然后执行 界面介绍 右侧设置 多个标签页 https://www.pianshen.com/article/8212968259/ 工作区放大缩小 https://www.jianshu.com/p/530df9a13fca 添加注释 可以看到如果想给已有的代码直接添加行注释 ctrl+k ctrl+c，取消是ctrl+k ctrl+/ 如果是想在新的一行中开始一段新的行注释（toggle line comment）是ctrl+/ 添加块注释shif+alt+a vscode vue 格式化 1.安装 vetur 2.在User Setting中增加设置: \"vetur.format.defaultFormatter.html\": \"js-beautify-html\" 3.搞定 格式化快捷键：Alt+Shift+F 鼠标滚动改变字体大小 设置中setting中 ctrl+鼠标滚轮 关闭缩略图 设置里面搜索 \"editor.minimap.enabled\"，设置为false即可。 "},"docs/vscode/vscode快捷键.html":{"url":"docs/vscode/vscode快捷键.html","title":"Vscode快捷键","keywords":"","body":"快捷键面板： 文件-->首选项-->键盘快捷方式 或底部设置 搜索文本/全局替换 ctrl+shift+f 左侧小箭头可以全局替换 格式化 Shift + Alt + F 显示命令面板 ctrl+shift+p 隐藏侧边栏和底部 ctrl+b： 鼠标放在侧边栏 ctrl+j:隐藏底部面板 ：查看->外观 注释 ctrl+/： ctrl+shift+/注释 复制当前行 ctrl+D 快速查找文件 ctrl+p "},"docs/vscode/vscode插件.html":{"url":"docs/vscode/vscode插件.html","title":"Vscode插件","keywords":"","body":"VSCode 开发Vue必备插件 　　对于很多使用vscode编写vue项目的新手同学来说，可能不知道使用什么插件，这里简单说一下我常用的几款插件。 vetur vetur能够实现在 .vue 文件中： 语法错误检查，包括 CSS/SCSS/LESS/Javascript/TypeScript 语法高亮，包括 html/jade/pug css/sass/scss/less/stylus js/ts emmet 支持 代码自动补全（目前还是初级阶段），包括 HTML/CSS/SCSS/LESS/JavaScript/TypeScript 配合 ESLint 插件使用效果更佳 设置标签不自动换行 设置--扩展--vetur 或右上角 打开设置json， \"vetur.format.defaultFormatter.html\": \"js-beautify-html\",//html不换行 \"vetur.format.defaultFormatterOptions\": { \"js-beautify-html\": { //html 标签属性 换行设置[auto|force|force-aligned|force-expand-multiline] [\"auto\"] \"wrap_attributes\": \"auto\" , // 设置多个字符后换行 0 表示忽略 \"wrap_line_length\": 120, // 在文件结尾添加新行 \"end_with_newline\": false }, \"prettier\": { \"singleQuote\": true, \"semi\": false, //不加分号 \"tabWidth\": 4 }, \"prettyhtml\": { \"printWidth\": 100, \"singleQuote\": false, \"wrapAttributes\": false, \"sortAttributes\": false } }, // js代码不自动换行 \"vetur.format.defaultFormatter.js\": \"vscode-typescript\", 注意：会与prettier冲突，右键格式化的文件，选择格式文档的方式 --选择vetur为默认的 eslint eslint插件能够检测代码语法问题，与格式问题，对项目代码风格统一至关重要。 三.EditorConfig for Visual Studio Code EditorConfig 是一种被各种编辑器广泛支持的配置，使用此配置有助于项目在整个团队中保持一致的代码风格。 四.Path Intellisense 在编辑器中输入路径时，自动补全。 View In Browser 在浏览器中查看静态文件。 六.Live Server 　　这个插件很有用，安装之后可以打开一个简单的服务器。而且还会自动更新。安装之后，打开项目文件夹，再在文件上点击右键就会出现一个Open with Live Server的选项， 就会自动打开浏览器了。默认端口号是5500 七.GitLens----- Git Supercharged(必备) 查看git文件提交历史。 八.Document This 注释文档生成 九.Debugger for Chrome 直接在vscode里面进行调试js文件，跟谷歌的控制台是一样的功能，下载了它就不用打开浏览器的控制台就能进行打断点。 需要配置vscode的lauch.json的谷歌调试相关配置 十.HTML CSS Support 在编写样式表的时候，自动补全功能大大缩减了编写时间，推荐！ 十一.JavaScript Snippet Pack 针对js的插件，包含了js的常用语法关键字，很实用。 十二.HTML Snippets 这款插件包含html标签，非常全，很实用。 十三.One Monokai Theme 能够选择自己喜欢的颜色主题，来编写代码，比较喜欢用的是monokai。 十四.vscode-icons(很好用) 能够选择自己喜欢的图标主题，比较推荐vscode icons Vue VSCode Snippets 快捷生成代码： vbase-less Path Intellisense vue import路径提示 vue-helper 自定义组件跳转 ctrl VS Color Picker 取色 CSS Peek ：css跳转 SVG Viewer：右键可以看SVG Icon Fonts：图库支持 element-ui 快捷提示 vue-helper（shenjiaolong） 或Element UI Snippets vscode-element-helper "},"docs/vscode/vue开发配置.html":{"url":"docs/vscode/vue开发配置.html","title":"Vue开发配置","keywords":"","body":"https://blog.csdn.net/gods_boy/article/details/84404033 新版 eslint 配置 https://www.cnblogs.com/aurora-ql/p/13423563.html "},"docs/vue/echart相关.html":{"url":"docs/vue/echart相关.html","title":"Echart相关","keywords":"","body":""},"docs/vue/v-bind和v-model区别.html":{"url":"docs/vue/v-bind和v-model区别.html","title":"V Bind和V Model区别","keywords":"","body":"vue中v-model和v-bind区别 Vue中的数据绑定 绑定数据有三种方式： 插值，也就是的形式，以文本的形式和实例data中对应的属性进行绑定 v-bind： v-model： v-bind eg：v-bind:class 可简写为 :class 当加上v-bind:之后，它的值classe不是字符串，而是vue实例对应的data.classed的这个变量。也就是说data.classed是什么值，它就会给class属性传递什么值，当data.classed发生变化的时候，class属性也发生变化，这非常适合用在通过css来实现动画效果的场合。他只是单向变动 v-bind支持的类型 html中的属性、css的样式、对象、数组、number 类型、bool类型 v-bind使用： // 绑定文本 // 绑定文本 // 绑定属性 // 绑定表达式 :class{className:true} v-model 主要是用在表单元素中，它实现了双向绑定。在同事使用v-bind和v-model中，v-model建立的双向绑定对输入型元素input, textarea, select等具有优先权，会强制实行双向绑定。很多时候v-model使用在表单的中实现双向绑定。 "},"docs/vue/vue-admin-template教程.html":{"url":"docs/vue/vue-admin-template教程.html","title":"Vue Admin Template教程","keywords":"","body":"教程 克隆项目 git clone https://github.com/PanJiaChen/vue-admin-template 进入项目目录 cd vue-admin-template 安装依赖 npm install 建议不要用 cnpm 安装 会有各种诡异的bug 可以通过如下操作解决 npm 下载速度慢的问题 npm install --registry=https://registry.npm.taobao.org 本地开发 启动项目 npm run dev 运行界面 相关文档： https://blog.csdn.net/qq_42829628/article/details/106963947 https://www.cnblogs.com/codeluojay/p/13123494.html "},"docs/vue/vue-ui创建.html":{"url":"docs/vue/vue-ui创建.html","title":"Vue Ui创建","keywords":"","body":"vue 升级： vue 3.0以上 npm i -g @vue/cli "},"docs/vue/vue命令行安装脚手架.html":{"url":"docs/vue/vue命令行安装脚手架.html","title":"Vue命令行安装脚手架","keywords":"","body":"命令行安装 概念 npm: Nodejs下的包管理器。 webpack: 它主要的用途是通过CommonJS的语法，把所有浏览器端需要发布的静态资源，做相应的准备，比如资源的合并和打包。 vue-cli: 用户生成Vue工程模板。（帮你快速开始一个vue的项目，也就是给你一套vue的结构，包含基础的依赖库，只需要 npm install就可以安装） npm安装 nodejs官网 npm常用命令 echo %PATH% node -v npm -v #修改npm本地仓库地址 npm config set prefix \"D:\\Program Files\\nodejs\\node_global\" npm config set cache \"D:\\Program Files\\nodejs\\node_cache\" npm list --global npm安装插件 配置淘宝镜像 npm config set registry=https://registry.npm.taobao.org npm config list #安装更新 npm install [插件名称] -g #-g:是全局 配置vue 配置node和node_path 修改path: D:\\Program Files\\nodejs\\node_global; b、新增NODE_PATH：D:\\Program Files\\nodejs\\node_global\\node_modules 配置vue和vue-router npm install vue -g npm install vue-router -g 安装vue脚手架vue-cli npm install vue-cli –g #验证 vue -V 创建vue项目 找到存放项目的空目录 #初始化项目 vue init webpack vueproject #进入项目 cd vueproject #安装项目依赖 npm install #运行项目 npm run dev #生成静态文件 npm run build #(生成静态文件，打开dist文件夹下新生成的index.html文件) 项目目录描述 "},"docs/vue/vue学习笔记.html":{"url":"docs/vue/vue学习笔记.html","title":"Vue学习笔记","keywords":"","body":"学习笔记 环境搭建 vue环境搭建 vue环境搭建-命令行模式 vue项目的目录结构 src/main.js :是整个项目的入口文件 new Vue({ router, render: h => h(App) }).$mount('#app') //new 一个vue实例，通过render函数把app跟组件渲染到页面，同时把路由router挂载在实例中 App.vue :跟组件 template：UI结构 script：行为 style：样式 路由：router/index.js routes:设置路由规则：import 导入组件 import路径提示插件：Path Intellisense Vue VSCode Snippets：快捷命令 如 ：vbase-less element.js： 可以按需导入 import { Button, Message } from 'element-ui' //vue Vue.use(Button) //原型挂载 js中直接 this.$message 使用 Vue.prototype.$message = Message 里面用到了阿里的第三方图标库： https://www.iconfont.cn/ 登录和退出 技术点 http是无状态的（同一个会话的连续两个请求互相不了解 ）http应用层面向对象协议：超文本传输协议 解决http无状态的方法 cookie在客户端记录状态 session在服务端记录状态 token 方式维持状态（存在跨域问题用） 登录页面布局 用到的组件 el-form：表单 el-form-item：表单项 el-imput：输入框 el-button 组件 字体图标 创建模板 Login.vue: 可以用vbase 在 /route/index.js 中配置路由规则，渲染在app.vue根组件中 表单处理 表单属性 model :数据绑定 rules：表单验证 表单方法： resetFields：重置 this.$refs.loginFormRef.resetFields() validate：this.$refs.loginFormRef.validate(async valid => {} this.$router.push('/home') 页面跳转 ref：通过ref获取到表单的实例对象 权限管理 权限列表 用到的组件 面包屑导航：el-breadcrumb 卡片容器：el-card table:el-table 边框：border ，隔行变色：stripe 获取每一行的数据： 用作用域插槽 #scope.row 获得行数据对象 slot-scope=\"scope\" scope.row：行数据 标签一 标签二 标签三 v-if ,v-else-if,v-else标签使用 用到 el-tab 异步请求： 返回是promise的可以进行同步优化：async和await 权限管理业务分析 用户绑定不同的角色，角色绑定不同的权限，用户和权限不关联 角色列表 效果 用到到组件 面包屑导航：el-breadcrumb 卡片容器：el-card able:el-table ：列扩展 属性 v-for 循环 ：格栅系统布局加for循环 .bgbottom { border-bottom: 1px solid #eee; } .bgtop { border-top: 1px solid #eee; } 三目运算符 嵌套循环 tag:标签删除 closable 关闭函数 close 关闭确认窗口MessageBox 商品分类 属性结构插件 ：vue-table-with-tree-grid https://github.com/MisterTaki/vue-table-with-tree-grid "},"docs/vue/vue开发笔记.html":{"url":"docs/vue/vue开发笔记.html","title":"Vue开发笔记","keywords":"","body":"table-的expend 手风琴效果 https://blog.csdn.net/sinat_33312523/article/details/78928236 父子组件传值 #父组件 export default { name: 'index', components: { 'children-components': childrenComponents }, data(){ dcamera_option: { input_value: 6 } } } #子组件 export default { name: 'ChildrenComponents', props: { options: { type: Object, required: true }, } } vue中created、mounted、activated的区别 created：在模板渲染成html之前调用，即通常初始化某些属性值，然后再渲染成视图；但是注意，只会触发一次 mounted：在渲染成html之后调用，通常是初始化页面完成后，再对html的dom节点进行一些需要的操作。是挂载vue实例后的钩子函数，钩子在主页挂载时执行一次，如果没有缓存的话，再次回到主页时，此函数还会执行。 activated：是组件被激活后的钩子函数，每次回到页面都会执行 执行顺序：created => mounted => activated this.$message.error(data.msg) echart和v-chart相关 官方文档：https://v-charts.js.org/#/ 百度：https://echarts.apache.org/zh/option.html#title npm i v-charts echarts -S 报错： --save echarts/lib/visual/dataColor 解决： npm i v-charts echarts@4.9.0 -S 如不行用下面 npm install v-echarts echarts --save Vue项目中，Cannot find module 'node-sass' 报错找不到解决 cnpm install node-sass@latest -S 问题： vue2引入v-charts为什么需要f12才会显示 解决：组件加入宽度和高度 父子加载顺序 https://blog.csdn.net/weixin_43878906/article/details/108274025 折线图例子： https://www.oschina.net/p/v-charts https://www.cnblogs.com/cina33blogs/p/10750169.html 参考例子 vchart ：https://blog.csdn.net/weixin_44824839/article/details/103140933 拓展参考： https://echarts.apache.org/zh/option.html#title y轴固定内容滚动 https://blog.csdn.net/qq_42714690/article/details/103655087 时区转换 https://blog.csdn.net/sinat_32849897/article/details/110848673 vue中的数据格式化filters、formatter https://blog.csdn.net/messicr7/article/details/105435314/?utm_medium=distribute.pc_relevant.none-task-blog-baidujs_baidulandingword-1&spm=1001.2101.3001.4242 {{ message | filterA | filterB }} 这个 写法的功能是，把message 传递给filterA 返回值传递给filterB最后返回显示结果到页面上，可以看出是按函数的先后顺序调用下去最后返回结果显示。 {{ mobile | formatmobile}} 跨域解决： https://blog.csdn.net/lindali1115/article/details/108096631 json 格式的问题 js保留两位小数 https://www.jb51.net/article/134067.htm 页面不跳转：，vue-springboot整包部署 在controller层应该用@Controller注解，不能用@ResController注解，如果使用@ResController注解，此注解是将json转换成字符串,那么就无法转到html页面，只会返回字符串 或者用 @RestController @RequestMapping(\"rmsLogin\") 多加个RequestMapping 整包部署： dist包放在了 /static/static/目录下 shiro配置中加入 filterMap.put(\"/static/**\", \"anon\"); 访问地址 http://localhost:8080/idc-services/static/index.html application.properties 中加入 spring.web.resource.static-locations=classpath:/ spring.mvc.view.suffix=.html SysLoginController添加 @RequestMapping(\"\") 启动命令 $nohup java -jar idc-services-1.0.0.jar > log.file 2>&1 & vue自定义全局方法 https://www.cnblogs.com/conglvse/p/10062449.html 全局过滤器 https://blog.csdn.net/weixin_33749131/article/details/93396673 js保留两位小数 https://www.jb51.net/article/134067.htm docker启动错误 ERROR: for prometheus Cannot restart container 950af762c9501a7ee07db430d92da45a8a515980bace5a04192496f6173b1369: driver failed programming external connectivity on endpoint prometheus (ffec7c8009254b20c7605546ed2b03be313596b2f9fd81108bf1b3e3d40951e0): (iptables failed: iptables --wait -t nat -A DOCKER -p tcp -d 0/0 --dport 9090 -j DNAT --to-destination 172.17.0.8:9090 ! -i br-e69a795d182b: iptables: No chain/target/match by that name. 解决：https://blog.csdn.net/u013948858/article/details/83115388 https://blog.51cto.com/17099933344/1929664 极端解决： systemctl stop firewalld systemctl stop iptables 泛型接口实例化 https://blog.csdn.net/weixin_34075551/article/details/86132595 https://blog.csdn.net/aiyaya_/article/details/79212852 "},"docs/vue/vue环境搭建.html":{"url":"docs/vue/vue环境搭建.html","title":"Vue环境搭建","keywords":"","body":"安装vue脚手架 安装cnpm npm install -g cnpm --registry=https://registry.npm.taobao.org #查看版本 cnpm -v 如不是内部命令 配置下 D:\\program\\nodejs\\npm_global path vue安装 #淘宝仓库 $npm config set registry=https://registry.npm.taobao.org #显示配置 $npm config list #检查镜像站命令 npm config get registry $cnpm install vue #安装vue $ cnpm install -g vue-cli #vue-cli 提供一个官方命令行工具 在cmd中 VUE UI的安装 需要3.0以上版本 $npm i -g @vue/cli 或 $cnpm install -g @vue/cli $vue ui http://localhost:8000/ 项目创建 选择功能： babel，router（路由），linter（格式校验）,使用配置文件 关闭历史模式，使用hash模式 安装element-ui组件库 在vue-ui 仪表盘 插件中安装 element 依赖中安装axios ：运行依赖 用vscode打开： 打开终端，查看项目状态：git status git checkout -b login --创建分支 git branch --查看分支 开发依赖：less-loader 而这个less是需要安装的，在相应项目目录下 npm install --save-dev less-loader less 要和相应的vue 版本相同 npm install less-loader@4.1.0 --save-dev 使用element-ui 如果是按需导入 ，需要在element.js 中导入 相应的标签，并注册 图标 element ui也有，也可以采用阿里图标图 阿里图库使用：https://blog.csdn.net/qq_32113629/article/details/79740949 登录 https://www.iconfont.cn/ 搜索添加购物车 创建项目 下载项目 复制项目中如下内容到 assert icon中 导入： main.js 中import './assets/icon/iconfont.css' 使用 iconfont iconmima --前缀加 图标名称 https://blog.csdn.net/qq_40741855/article/details/89455055 使用阿里图标库有三种方式 1）1.unicode引用 2）font-class引用---这是一种最常用的方式，网上的方案也是这种最多，但是这种方案，图标不能缩放，只能小图标 3）symbol引用--最新的方式，也是阿里最支持的，图标可以进行样式调整，并且你修改你的图标的时候只要更新一下地址就可以了，我最终也是采用的这种 我只说一下第三种方式，以及第二种方式踩过的坑 npm 命令 安装VCBuild.exe $npm install --global --production windows-build-tools node-sass安装 因为版本问题 #查看某个项目的pkg信息 $npm ls pkg #查看全部版本 $npm view node-sass versions #卸载相应版本 $npm uninstall sass-loader #安装相应版本 $npm install sass-loader@7.3.1 --save-dev 查看版本信息 #查看全部版本 npm view node-sass versions npm view node-sass version #查看最新版本信息 npm info node-sass #查看某个项目的pkg信息 npm ls pkg #查看本地全局安装的pkg版本 npm ls webpack -g $cnpm install mockjs --save-dev #查看global npm list --global "},"docs/vue/vue项目升级element.html":{"url":"docs/vue/vue项目升级element.html","title":"Vue项目升级Element","keywords":"","body":"先卸载 npm uninstall element-ui 重新安装 npm install element-ui –S （安装最新版本） npm install element-ui@2.4.11 --save（安装到指定版本，此处是2.4.11版本） 同时要升级 同理更新项目中的node-sass npm uninstall --save node-sass cnpm install --save node-sass "},"docs/vue/表单设计.html":{"url":"docs/vue/表单设计.html","title":"表单设计","keywords":"","body":"Form Generator Plugin vscode 插件：jakHuang 或 Form Generator Plugin https://gitee.com/mrhj/form-generator https://mrhj.gitee.io/form-generator/#/ "},"docs/windows/C盘瘦身.html":{"url":"docs/windows/C盘瘦身.html","title":"C盘瘦身","keywords":"","body":"c盘瘦身 瘦windwos更新 删除：C:\\Windows\\SoftwareDistribution\\Download 目录下文件 关闭休眠文件 powercfg /h off #开启 powercfg /h on #关闭 方法一：在设置中开启【存储感知】 　　1、从Win10开始菜单打开【设置】-【系统】-【储存】，把储存感知功能的开关打开，系统会自动清理临时文件、更新缓存； 　　2、下面还有一个【立即释放空间】的按钮，点击后会自动进入手动删除，删除【以前的Windows安装】勾选后点击删除即可； 　　方法二：删除安装缓存文件 　　1、首先按下WIN+R，然后在运行中输入services.msc 回车； 　　2、在服务中找到【Windows update服务】，右键点击停止； 　　3、然后打开文件夹C:\\Windows\\SoftwareDistribution\\Download，这个文件夹中的就是更新后留下的更新文件，将其全选删除； 　　4、删除后重新在服务中开启【Windows update服务】。 "},"docs/windows/windows10开机锁屏.html":{"url":"docs/windows/windows10开机锁屏.html","title":"Windows10开机锁屏","keywords":"","body":"C:\\Users\\Administrator\\AppData\\Local\\Packages\\Microsoft.Windows.ContentDeliveryManager_cw5n1h2txyewy\\LocalState\\Assets cmd ren . *.jpg "},"docs/windows/windows背景图.html":{"url":"docs/windows/windows背景图.html","title":"Windows背景图","keywords":"","body":"C:\\Windows\\Web C:\\Users\\Administrator\\AppData\\Local\\Packages\\Microsoft.Windows.ContentDeliveryManager_cw5n1h2txyewy\\LocalState\\Assets C:\\Users\\Administrator\\AppData\\Local\\Microsoft\\Windows\\Themes "},"docs/windows/win定时任务.html":{"url":"docs/windows/win定时任务.html","title":"Win定时任务","keywords":"","body":"https://jingyan.baidu.com/article/9080802200cc15fd91c80fcf.html "},"docs/windows/首页被劫持去除小图标.html":{"url":"docs/windows/首页被劫持去除小图标.html","title":"首页被劫持去除小图标","keywords":"","body":"https://blog.csdn.net/wgllovemother/article/details/102989819 磁盘清理 https://jingyan.baidu.com/article/d5a880eb432da953f147ccce.html 去除桌面图标 1.点击电脑开始，选择运行打开 2.在运行窗口中输入regedit并点击确定 3.在打开的注册表编辑器中点击HKEY_CLASSES_ROOT前面的小三角 4.HKEY_CLASSES_ROOT下拉单中找到lnkfile点击打开 5.在右侧列表中找到isshortcut， 6 设置为空，不然无法固定任务栏。 Windows Registry Editor Version 5.00 　　[HKEY_CLASSES_ROOT\\lnkfile] \"IsShortcut\"=\"\" "},"docs/zabbix/zabbix常用知识.html":{"url":"docs/zabbix/zabbix常用知识.html","title":"Zabbix常用知识","keywords":"","body":""},"docs/zabbix/zabbix的docker安装.html":{"url":"docs/zabbix/zabbix的docker安装.html","title":"Zabbix的Docker安装","keywords":"","body":"docker pull zabbix/zabbix-server-mysql "},"docs/云原生/云原生概念.html":{"url":"docs/云原生/云原生概念.html","title":"云原生概念","keywords":"","body":"云原生 概念 云原生从字面意思上来看可以分成云和原生两个部分。 云是和本地相对的，传统的应用必须跑在本地服务器上，现在流行的应用都跑在云端，云包含了IaaS,、PaaS和SaaS。 原生就是土生土长的意思，我们在开始设计应用的时候就考虑到应用将来是运行云环境里面的，要充分利用云资源的优点，比如️云服务的弹性和分布式优势。 那具体要怎么利用呢，请参考下图： 微服务 微服务解决的是我们软件开发中一直追求的低耦合+高内聚，记得有一次我们系统的接口出了问题，结果影响了用户的前台操作，于是黎叔拍案而起，灵魂发问：“为啥这两个会互相影响？！” 微服务可以解决这个问题，微服务的本质是把一块大饼分成若干块低耦合的小饼，比如一块小饼专门负责接收外部的数据，一块小饼专门负责响应前台的操作，小饼可以进一步拆分，比如负责接收外部数据的小饼可以继续分成多块负责接收不同类型数据的小饼，这样每个小饼出问题了，其它小饼还能正常对外提供服务。 DevOps DevOps的意思就是开发和运维不再是分开的两个团队，而是你中有我，我中有你的一个团队。我们现在开发和运维已经是一个团队了，但是运维方面的知识和经验还需要持续提高。 持续交付 持续交付的意思就是在不影响用户使用服务的前提下频繁把新功能发布给用户使用，要做到这点非常非常难。我们现在两周一个版本，每次上线之后都会给不同的用户造成不同程度的影响。 容器化 容器化的好处在于运维的时候不需要再关心每个服务所使用的技术栈了，每个服务都被无差别地封装在容器里，可以被无差别地管理和维护，现在比较流行的工具是docker和k8s。 所以你也可以简单地把云原生理解为：云原生 = 微服务 + DevOps + 持续交付 + 容器化 "},"docs/交换机/华为交换机/交换机配置.html":{"url":"docs/交换机/华为交换机/交换机配置.html","title":"交换机配置","keywords":"","body":"snmp配置 配置模式： system-view 查看序列号：display esn display version snmp 配置 system-view [HUAWEI] snmp-agent sys-info version v2c [HUAWEI] snmp-agent community write community001 mib-view alliso acl 2001 LLDP 配置 使能SwitchA的全局LLDP功能。 system-view sysname SwitchA commit lldp enable commit 在SwitchA上执行display lldp neighbor brief命令，检查SwitchA的邻居简要信息。 [~SwitchA] display lldp neighbor brief Local Intf Neighbor Dev Neighbor Intf Exptime(s)GE3/0/24 switch1 Gi1/0/23 94GE3/0/43 Switch-4 GE1/0/24 98GE3/0/44 Switch-5 GE1/0/24 101 在SwitchA上执行display lldp neighbor interface 10ge 1/0/1命令，检查SwitchA的邻居详细信息 display lldp neighbor interface GigabitEthernet 3/0/24 [~SwitchA] display lldp neighbor interface 10ge 1/0/1 10GE1/0/1 has 1 neighbor(s): Neighbor index :1 Chassis type :macAddress Chassis ID :0025-9e95-7c20 Port ID type :interfaceName Port ID :10GE1/0/2 //邻居设备接口ID。 Port description :HUAWEI, CloudEngine Series, 10GE1/0/2 Interface //邻居设备接口信息描述。 System name :SwitchB //邻居设备系统名称。 System description :Huawei Versatile Routing Platform Software VRP (R) software, Version 8.50 (CE6850 V100R001C00) //邻居设备系统信息描述。 Copyright (C) 2011-2012 Huawei Technologies Co., Ltd. HUAWEI CE6850 System capabilities supported :bridge router System capabilities enabled :bridge router Management address type :ipv4 Management address :10.10.10.2 Expired time :111s Port VLAN ID(PVID) :100 //邻居设备接口的VLAN ID。 dis interface brief #显示端口详细信息 display mac-address #来查看端口下的MAC display arp #找IP对应的MAC，通过IP后面的端口号就可以知道二层某个端口下所连接的设备信息。 "},"docs/交换机/物理口区别.html":{"url":"docs/交换机/物理口区别.html","title":"物理口区别","keywords":"","body":"ethernet接口与gigabitethernet接口的区别 设备里面的ethernet是100M接口 gigabitethernet是1000M接口 ethernet不能配置IP，是因为这个接口是二层口，所以不能设置IP "},"docs/交换机/网络拓扑工具.html":{"url":"docs/交换机/网络拓扑工具.html","title":"网络拓扑工具","keywords":"","body":"https://mikrotik.com/download 配置文档 https://blog.csdn.net/abcdu1/article/details/90297758 "},"docs/分布式/CAP和BASE.html":{"url":"docs/分布式/CAP和BASE.html","title":"CAP和BASE","keywords":"","body":"https://www.jianshu.com/p/bf3c47842f29 一致性（Consistency） - 对某个指定的客户端来说，读操作保证能够返回最新的写操作结果。 A read is guaranteed to return the most recent write for a given client. 可用性（Availability） - 非故障的节点在合理的时间内返回合理的响应（不是错误和超时的响应）。 A non-failing node will return a reasonable response within a reasonable amount of time (no error or timeout). 分区容错性（Partition Tolerance） - 当出现网络分区后，系统能够继续履行职责。 The system will continue to function when network partitions occur. CAP应用 虽然CAP理论定义是三个要素中只能取两个，但放到分布式环境下来思考的话，我们会发出必须选择P(分区容错)要素，因为网络本身无法做到100%可靠，有可能出故障，所以分区是一个必然的现象。 如果我们选择了CA而放弃了P，那么当发生分区现象时，为了保证C，系统需要禁止写入，当有写入请求时，系统返回error，这双和A冲突了，因为A要求返回no error 和no timeout。因此，分布式系统理论上不可能选择CA架构，只能选择CP或者AP架构。 CP - Consistency/Partition Tolerance 如图1-1所示，为了保证一致性，当发生分区现象后，N1节点上的数据已经更新到y，但由于N1和N2之间的复制通道中断，数据y无法同步到N2，N2节点上的数据还是x。 这时客户端C访问N2时，N2需要返回Error，提示客户端面C：“系统现在发生错误”，这种处理方式违背了可用性（Availability）的要求，因此CAP三者只能满足CP。 图1-1：CP模式 AP - Availability/Partition Tolerance 如图1-2所示，为了保证可用性，当发生分区现象后，N1节点上的数据已经更新到y，但由于N1和N2之间的复制通道中断，数据y无法同步到N2，N2节点上的数据还是x。 这时客户C访问N2时，N2将当前自己拥有的数据x返回给客户端C了，而实际上当前最新的数据已经是y了，这就不满足一致性（Consistency）的要求了，因此CAP三者只能满足AP。 注意：这里N2节点返回的x，虽然不是一个“正确”的结果，但是一个“合理”的结果，因为x是旧的数据，并不是一个错乱的值，只是不是最新的数据而已。 图1-2：AP模式 CAP扩展 理论的优点在于清晰简洁、易于理解，但是缺点就是高度抽象化、省略了很多的细节，导致在将理论应用到实践时，由于各种复杂情况，可能出现误解和偏差，CAP理论也不例外。 如果我们没有意识到这些关键的细节点，那么在实践中应用CAP理论时，就可能发出方案很难落地。 而在我们谈到数据一致性时，CAP、ACID、BASE这些就是我们拿来讨论的对象，原因是这三者都是和数据一致性相关的理论，如果不仔细理解三者之间的差别，则可能会陷入一头雾水的状态，不知道该用哪个才好。 这里，我们来说说CAP的具体细节，简单对比一下ACID、BASE几个概念的关键区别点。 CAP关键细节点 CAP关注的粒度是数据，而不是整个系统。 C与A之间的取舍可以在同一系统内以非常细小的粒度反复发生，而每一次的决策可能因为具体的操作，乃至因为牵涉到特定的数据或用户有所不同。 以一个用户管理系统为例，用户管理系统包含用户账号数据（用户ID、密码）、用户信息数据（昵称、兴趣、性别等）。通常情况下，用户账号数据会选择CP，而用户信息数据会选择AP，如果限定整个系统为CP，则不符合用户信息的应用场景；如果限定整个系统为AP，则又不符合用户账号数据的应用场景。 所以在CAP理论落地实践时，我们需要将系统内的数据按照不同的应用场景和要求进行分类，每类数据选择不同的策略（CP或AP），而不是直接限定整个系统所有数据都是同一策略。 CAP是忽略网络延迟的。 这是一个非常隐含的假设，布鲁尔在定义一致性时，并没有将延迟考虑进去。即当事务提交时，数据能够瞬间复制到所有节点。但实际情况下，从节点A复制数据到节点B，总是需要花费一定时间的。如果在相同机房可能是几毫秒，如果跨机房，可能是几十毫秒。这也就是说，CAP理论中的C在实践中是不可能完美实现的，在数据复制的过程中，节点A和节点B的数据并不一致。 正常运行情况下，不存在CP和AP的选择，可以同时满足CA。 CAP理论告诉我们分布式系统只能选择CP或者AP，但其实这里的前提是系统发生了“分区”现象。如果系统没有发生分区现象，也就是说P不存在的时候（节点的网络连接一切正常），我们就没有必要放弃C或者A，应该C和A都可以保证，这就要求架构设计的时候即要考虑分区发生时选择CP还是AP，也要考虑分区没有发生时如何保证CA。 这里我们还以用户管理系统为例，即使是实现CA，不同的数据实现方式也可能不一样：用户账号数据可以采用“消息队列”的方式来实现CA，因为消息队列可以比较好地控制实时性，但实现起来就复杂一些；而用户信息数据可以采用“数据库同步”的方式来实现CA，因为数据库的方式虽然在某些场景下可能延迟较高，但使用起来简单。 放弃并不等于什么都不做，需要为分区恢复后做准备。 CAP理论告诉我们三者只能取两个，需要“牺牲”（sacrificed）另外一个，这里的“牺牲”是有一定误导作用的，因为“牺牲”让很多人理解成什么也不做。实际上，CAP理论的“牺牲”只是说在分区过程中我们无法保证C或者A，但并不意味着什么都不做。分区期间放弃C或者A，并不意味着永远放弃C和A，我们可以在分区期间进行一些操作，从而让分区故障解决后，系统能够重新达到CA的状态。 最典型的就是在分区期间记录一些日志，当分区故障解决后，系统根据日志进行数据恢复，使得重新达到CA状态。 ACID ACID 是数据库管理系统为了保证事务的正确性而提出来的一个理论，ACID 包含四个约束： Atomicity（原子性） 一个事务中的所有操作，要么全部完成，要么全部不完成，不会在中间某个环节结束。事务在执行过程中发生错误，会被回滚到事务开始前的状态，就像这个事务从来没有执行过一样。 Consistency（一致性） 在事务开始之前和事务结束以后，数据库的完整性没有被破坏。 Isolation（隔离性） 数据库允许多个并发事务同时对数据进行读写和修改的能力。隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。事务隔离分为不同级别，包括读未提交（Read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（Serializable）。 Durability（持久性） 事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。 划重点： 我们可以看到，ACID中的A（Atomicity）和CAP中的A（Availability）意义完全不同，而ACID中的C和CAP中的C名称虽然都是一致性，但含义也完全不一样。ACID 中的 C 是指数据库的数据完整性，而 CAP 中的 C 是指分布式节点中的数据一致性。再结合 ACID 的应用场景是数据库事务，CAP 关注的是分布式系统数据读写这个差异点来看，其实 CAP 和 ACID 的对比就类似关公战秦琼，虽然关公和秦琼都是武将，但其实没有太多可比性。 BASE BASE 是指基本可用（Basically Available）、软状态（ Soft State）、最终一致性（ Eventual Consistency），核心思想是即使无法做到强一致性（CAP 的一致性就是强一致性），但应用可以采用适合的方式达到最终一致性。 基本可用（Basically Available） 分布式系统在出现故障时，允许损失部分可用性，即保证核心可用。 这里的关键词部分和核心，具体选择哪些作为可以损失的业务，哪些是必须保证的业务，是一项有挑战的工作。例如，对于一个用户管理系统来说，“登录”是核心功能，而“注册”可以算作非核心功能。因为未注册的用户本来就还没有使用系统的业务，注册不了最多就是流失一部分用户，而且这部分用户数量较少。如果用户已经注册但无法登录，那就意味用户无法使用系统。例如，充了钱的游戏不能玩了、云存储不能用了……这些会对用户造成较大损失，而且登录用户数量远远大于新注册用户，影响范围更大。 软状态（ Soft State） 允许系统存在中间状态，而该中间状态不会影响系统整体可用性。这里的中间状态就是 CAP 理论中的数据不一致。 最终一致性（ Eventual Consistency） 系统中的所有数据副本经过一定时间后，最终能够达到一致的状态。 这里的关键词是一定时间 和 最终，一定时间和数据的特性是强关联的，不同的数据能够容忍的不一致时间是不同的。举一个微博系统的例子，用户账号数据最好能在 1 分钟内就达到一致状态，因为用户在 A 节点注册或者登录后，1 分钟内不太可能立刻切换到另外一个节点，但 10 分钟后可能就重新登录到另外一个节点了；而用户发布的最新微博，可以容忍 30 分钟内达到一致状态，因为对于用户来说，看不到某个明星发布的最新微博，用户是无感知的，会认为明星没有发布微博。“最终”的含义就是不管多长时间，最终还是要达到一致性的状态。 划重点： BASE 理论本质上是对 CAP 的延伸和补充，更具体地说，是对 CAP 中 AP 方案的一个补充。前面在剖析 CAP 理论时，提到了其实和 BASE 相关的两点： CAP 理论是忽略延时的，而实际应用中延时是无法避免的。 AP 方案中牺牲一致性只是指分区期间，而不是永远放弃一致性。 总结 综合上面的分析，ACID 是数据库事务完整性的理论，CAP 是分布式系统设计理论，BASE 是 CAP 理论中 AP 方案的延伸。 "},"docs/分布式/centos7安装redis 6.05.html":{"url":"docs/分布式/centos7安装redis 6.05.html","title":"Centos7安装Redis 6.05","keywords":"","body":"yum -y install gcc 下载安装包 tar -zxvf xxx.tar.gz 解压目录下： 编译安装 make PREFIX=/usr/local/redis install 修改配置 拷贝 redis.conf 到 bin目录 将 bind 127.0.0.1 ::1 这一行注释掉。 daemonize yes #后台运行 修改办法：protected-mode no 启动 [root@mmjredis bin]# ./redis-server redis.conf ./redis-cli -h 127.0.0.1 -p 6379 远程访问 开机启动： vi /etc/systemd/system/multi-user.target.wants/redis.service [Unit] Description=redis-server After=network.target [Service] Type=forking ExecStart=/usr/local/redis/bin/redis-server /usr/local/redis/bin/redis.conf PrivateTmp=true [Install] WantedBy=multi-user.target 各项参数说明： 　　Description:描述服务 　　After:描述服务在哪些基础服务启动后再启动 　　[Service]服务运行参数的设置 　　Type=forking是最简单和速度最快的选择 　　ExecStart为启动服务的具体运行命令 　　ExecReload为重启命令 　　ExecStop为停止命令 　　PrivateTmp=True表示给服务分配独立的临时空间 　　注意：[Service]的启动、重启、停止命令全部要求使用绝对路径 　　[Install]运行级别下服务安装的相关设置，可设置为多用户，即系统运行级别为3 详细说明请参考systemd.service 中文手册网址：http://www.jinbuguo.com/systemd/systemd.service.html 常见报错： serverLog(LL_NOTICE,\"The server is now ready to accept connections at %s\", server.unixsocket); ^ server.c:5103:19: error: ‘struct redisServer’ has no member named ‘supervised_mode’ if (server.supervised_mode == SUPERVISED_SYSTEMD) { ^ server.c:5104:24: error: ‘struct redisServer’ has no member named ‘masterhost’ if (!server.masterhost) { ^ server.c:5117:15: error: ‘struct redisServer’ has no member named ‘maxmemory’ if (server.maxmemory > 0 && server.maxmemory 0 && server.maxmemory # 查看gcc版本是否在5.3以上，centos7.6默认安装4.8.5 gcc -v # 升级gcc到5.3及以上,如下： 升级到gcc 9.3： yum -y install centos-release-scl yum -y install devtoolset-9-gcc devtoolset-9-gcc-c++ devtoolset-9-binutils scl enable devtoolset-9 bash 需要注意的是scl命令启用只是临时的，退出shell或重启就会恢复原系统gcc版本。 如果要长期使用gcc 9.3的话： echo \"source /opt/rh/devtoolset-9/enable\" >>/etc/profile 这样退出shell重新打开就是新版的gcc了 以下其他版本同理，修改devtoolset版本号即可。 https://blog.csdn.net/weidu01/article/details/105946606/ "},"docs/分布式/springboot2+dubbo安装+zookeeper.html":{"url":"docs/分布式/springboot2+dubbo安装+zookeeper.html","title":"Springboot2+Dubbo安装+Zookeeper","keywords":"","body":"一、dubbo-admin安装 https://dubbo.apache.org/zh-cn/ 下载 https://github.com/apache/incubator-dubbo-admin 主分支 https://github.com/apache/dubbo-admin/tree/master springboot项目 编译成jar运行 二、zookeeper安装 三、工程结构 API接口：提供接口定义，数据结构定义 服务端：提供接口实现 客户端：去使用接口 @Service 分spring注解和dubbo注解 方法一、 启动类加 @EnableDubbo @Service import com.alibaba.dubbo.config.annotation.Service; @Service(version = \"${provider.service.version}\") 可以加版本号 加配置文件 #当前服务/应用名称 dubbo.application.name=provider #注册中心的协议和地址 #dubbo.server=true dubbo.registry.address=zookeeper://192.168.210.72:2181 #通信规则(通信协议和接口) dubbo.protocol.name=dubbo dubbo.protocol.port=20880 dubbo.scan.base-packages=com.geekq.provider.service.impl ## Service version provider.service.version=1.0.0 方法二、 用 import org.springframework.stereotype.Service; @Service(\"goodGroupService\") 启动类加 @ImportResource(value={\"classpath:provider.xml\"}) "},"docs/分布式/tomcat并发.html":{"url":"docs/分布式/tomcat并发.html","title":"Tomcat并发","keywords":"","body":"Tomcat的最大并发数是可以配置的，实际运用中，最大并du发数与硬件性能和CPU数量都有zhi很大关系dao的。更好的硬件，更多的处理器都会使Tomcat支持更多的并发。 　　Tomcat默认的HTTP实现是采用阻塞式的Socket通信，每个请求都需要创建一个线程处理，当一个进程有500个线程在跑的话，那性能已经是很低很低了。Tomcat 默认配置的最大请求数是150，也就是说同时支持150个并发。具体能承载多少并发，需要看硬件的配置，CPU 越多性能越高，分配给JVM的内存越多性能也就越高，但也会加重GC的负担。当某个应用拥有 250 个以上并发的时候，应考虑应用服务器的集群。 　　操作系统对于进程中的线程数有一定的限制： 　　Windows 每个进程中的线程数不允许超过 2000 　　Linux 每个进程中的线程数不允许超过 1000 　　在Java中每开启一个线程需要耗用1MB的JVM内存空间用于作为线程栈之用，此处也应考虑。 "},"docs/分布式/zookeeper安装.html":{"url":"docs/分布式/zookeeper安装.html","title":"Zookeeper安装","keywords":"","body":"centos安装 centos7安装 安装前要安装jdk 一、下载 http://mirror.bit.edu.cn/apache/zookeeper/ 下载稳定版 二、解压安装 tar -zxvf apache-zookeeper-3.5.8-bin.tar.gz -C /usr/local 修改配置文件 cp xxx/zookeeper/conf/zoo_sample.cfg xxx/zookeeper/conf/zoo.cfg 启动zookeeper /usr/local/zookeeper/bin/zkServer.sh 设置开机启动 创建 /etc/systemd/system/zookeeper.service 文件，内容下 [Unit] Description=ZooKeeper Service After=network.target After=syslog.target [Service] Environment=ZOO_LOG_DIR=/var/log/zookeeper SyslogIdentifier=zookeeper Type=forking User=root Group=root ExecStart=/usr/local/zookeeper/bin/zkServer.sh start /usr/local/zookeeper/conf/zoo.cfg ExecStop=/usr/local/zookeeper/bin/zkServer.sh stop /usr/local/zookeeper/conf/zoo.cfg ExecReload=/usr/local/zookeeper/bin/zkServer.sh restart /usr/local/zookeeper/conf/zoo.cfg [Install] WantedBy=default.target 启动命令： systemctl daemon-reload systemctl enable zookeeper systemctl start zookeeper systemctl stop zookeeper 参考：https://www.pocketdigi.com/20180131/1593.html 常见错误 1、Zookeeper JAVA_HOME is not set and java could not be found in PATH 修改zkEnv.sh文件 增加JAVA_HOME 解决：进入Zookeeper的bin目录下，修改zkEnv.sh文件 添加java路径： JAVA_HOME=\"/usr/java/jdk1.8.0_191\" "},"docs/分布式/分布式-从有状态到无状态-长连接短连接.html":{"url":"docs/分布式/分布式-从有状态到无状态-长连接短连接.html","title":"分布式 从有状态到无状态 长连接短连接","keywords":"","body":"服务的有状态无状态 服务的“状态” 无状态的服务 客户端的每次请求必须具备自描述信息，通过这些信息识别客户端身份。服务端不保存任何客户端请求者信息。 无状态的好处？ 客户端请求不依赖服务端的信息，任何多次请求不需要必须访问到同一台服务 服务端的集群和状态对客户端透明 =-服务端可以任意的迁移和伸缩 =-减小服务端存储压力 什么是有状态？ 有状态服务，即服务端需要记录每次会话的客户端信息，从而识别客户端身份，根据用户身份进行请求的处理，典型的设计如 tomcat 中的 session。 例如登录：用户登录后，我们把登录者的信息保存在服务端 session 中，并且给用户一个 cookie 值，记录对应的 session。然后下次请求，用户携带 cookie 值来，我们就能识别到对应 session，从而找到用户的信息。 有状态的缺点是什么？ • 服务端保存大量数据，增加服务端压力 • 服务端保存用户状态，无法进行水平扩展 • 客户端请求依赖服务端，多次请求必须访问同一台服务器 参考： https://www.jianshu.com/p/65c95c097d20 BLL和DAL：DAL 数据访问层，BLL（business logic layer）：业务逻辑层 长连接短连接 在HTTP/1.0中默认使用短连接。也就是说，客户端和服务器每进行一次HTTP操作，就建立一次连接，任务结束就中断连接。当客户端浏览器访问的某个HTML或其他类型的Web页中包含有其他的Web资源（如JavaScript文件、图像文件、CSS文件等），每遇到这样一个Web资源，浏览器就会重新建立一个HTTP会话。 而从HTTP/1.1起，默认使用长连接，用以保持连接特性。使用长连接的HTTP协议，会在响应头加入这行代码： Connection:keep-alive HTTP1.1规定了默认保持长连接（HTTP persistent connection ，也有翻译为持久连接），数据传输完成了保持TCP连接不断开（不发RST包、不四次握手），等待在同域名下继续用这个通道传输数据；相反的就是短连接 ## NIO异步通信 "},"docs/分布式/分布式-集群.html":{"url":"docs/分布式/分布式-集群.html","title":"分布式 集群","keywords":"","body":"分布式和集群的区别与联系 分布式：各系统之间通过交换信息的方式进行协作 集群：相同组件部署在不同的容器中或服务器上（eg:一套系统部署在多个服务器上，通过负载均衡进行调度） 分布式是指通过网络连接的多个组件，通过交换信息协作而形成的系统。而集群，是指同一种组件的多个实例，形成的逻辑上的整体。 可以看出这两个概念并不完全冲突，分布式系统也可以是一个集群，例子就是前面说的zookeeper等，它的特征是服务之间会互相通信协作。 是分布式系统不是集群的情况，就是多个不同组件构成的系统； 是集群不是分布式系统的情况，比如多个经过负载均衡的HTTP服务器，它们之间不会互相通信，如果不带上负载均衡的部分的话，一般不叫做分布式系统。 主备，主从 无状态主备集群 仅有一台主机完成任务，且没有本地状态，其余从机机器待命，一旦主机宕机，从机选主成为主机。 有状态主备集群 仅有一台主机完成任务，有本地状态，其余从机机器待命，一旦主机宕机，从机选主成为主机。 无状态的主从集群 所有机器没有本地状态，理论上机器可以无限叠加，共同向外界提供同一服务。解决方案就是dubbo+zookeeper。 4.有状态的主从集群 所有机器都有本地状态，共同向外界提供同一服务。一旦某台机器宕机，需要主机协调其他从机代理其本地状态的任务。Paxos、raft和ZAB等一众分布式一致性算法的终极目标就是解决该问题。 分布式是指通过网络连接的多个组件，通过交换信息协作而形成的系统。而集群，是指同一种组件的多个实例，形成的逻辑上的整体 "},"docs/分布式/分布式事务二阶段三阶段.html":{"url":"docs/分布式/分布式事务二阶段三阶段.html","title":"分布式事务二阶段三阶段","keywords":"","body":"分布式系统和分布式一致性问题 　　分布式系统，即运行在多台不同的网络计算机上的软硬件系统，并且仅通过消息传递来进行通信和协调。 　　分布式一致性问题，即相互独立的节点之间如何就一项决议达成一致的问题。 2PC(Two-Phase Commit 二阶段提交） 二阶段提交，是指将事务提交分成两个部分：准备阶段和提交阶段。事务的发起者称之为协调者，事务的执行者称为参与者。 阶段一：准备阶段 由协调者发起并传递带有事务信息的请求给各个参与者，询问是否可以提交事务，并等待返回结果。 个 参与者执行事务操作，将Undo和Redo放入事务日志中（但是不提交） 如果参与者执行成功就返回YES（可以提交事务），失败NO(不能提交事务) 阶段二：提交阶段 此阶段分两种情况：所有参与者均返回YES，有任何一个参与者返回NO 所有参与者均反馈YES时，即提交事务。 任何一个参与者反馈NO时，即中断事务。 提交事务：（所有参与者均反馈YES） 　　1、协调者向所有参与者发出正式提交事务的请求（即Commit请求）。 　　2、参与者执行Commit请求，并释放整个事务期间占用的资源。 　　3、各参与者向协调者反馈Ack完成的消息。 　　4、协调者收到所有参与者反馈的Ack消息后，即完成事务提交。 中断事务：（任何一个参与者反馈NO） 　　1、协调者向所有参与者发出回滚请求（即Rollback请求）。 　　2、参与者使用阶段1中的Undo信息执行回滚操作，并释放整个事务期间占用的资源。 　　3、各参与者向协调者反馈Ack完成的消息。 　　4、协调者收到所有参与者反馈的Ack消息后，即完成事务中断。 2PC的缺陷 　　1、同步阻塞：最大的问题即同步阻塞，即：所有参与事务的逻辑均处于阻塞状态。 　　2、单点：协调者存在单点问题，如果协调者出现故障，参与者将一直处于锁定状态。 　　3、脑裂：在阶段2中，如果只有部分参与者接收并执行了Commit请求，会导致节点数据不一致。 　　由于2PC存在如上同步阻塞、单点、脑裂问题，因此又出现了2PC的改进方案，即3PC。 3PC（Three-Phase Commit 三阶段提交协议） 　　3PC，三阶段提交协议，是2PC的改进版本，即将事务的提交过程分为CanCommit、PreCommit、do Commit三个阶段来进行处理。 阶段一：CanCommit 1、协调者向所有参与者发出包含事务内容的CanCommit请求，询问是否可以提交事务，并等待所有参与者答复。 2、参与者收到CanCommit请求后，如果认为可以执行事务操作，则反馈YES并进入预备状态，否则反馈NO。 阶段二：PreCommit 此阶段分为两种情况： 1.所有参与者均受到请求并返回YES。 2.有任何一个参与者返回NO，或者有任何一个参与者超时，协调者无法收到反馈，则事务中断 事务预提交：（所有参与者均反馈YES时） 　　1、协调者向所有参与者发出PreCommit请求，进入准备阶段。 　　2、参与者收到PreCommit请求后，执行事务操作，将Undo和Redo信息记入事务日志中（但不提交事务）。 　　3、各参与者向协调者反馈Ack响应或No响应，并等待最终指令。 中断事务：（任何一个参与者反馈NO，或者等待超时后协调者尚无法收到所有参与者的反馈时） 　　1、协调者向所有参与者发出abort请求。 　　2、无论收到协调者发出的abort请求，或者在等待协调者请求过程中出现超时，参与者均会中断事务。 阶段3：do Commit 此阶段也存在两种情况： 　　1、所有参与者均反馈Ack响应，即执行真正的事务提交。 　　2、任何一个参与者反馈NO，或者等待超时后协调者尚无法收到所有参与者的反馈，即中断事务。 　　提交事务：（所有参与者均反馈Ack响应时） 　　1、如果协调者处于工作状态，则向所有参与者发出do Commit请求。 　　2、参与者收到do Commit请求后，会正式执行事务提交，并释放整个事务期间占用的资源。 　　3、各参与者向协调者反馈Ack完成的消息。 　　4、协调者收到所有参与者反馈的Ack消息后，即完成事务提交。 　　中断事务：（任何一个参与者反馈NO，或者等待超时后协调者尚无法收到所有参与者的反馈时） 　　1、如果协调者处于工作状态，向所有参与者发出abort请求。 　　2、参与者使用阶段1中的Undo信息执行回滚操作，并释放整个事务期间占用的资源。 　　3、各参与者向协调者反馈Ack完成的消息。 　　4、协调者收到所有参与者反馈的Ack消息后，即完成事务中断。 　　注意：进入阶段三后，无论协调者出现问题，或者协调者与参与者网络出现问题，都会导致参与者无法接收到协调者发出的 do Commit请求或abort请求。此时，参与者都会在等待超时之后，继续执行事务提交。 3PC的优点和缺陷 　　优点：降低了阻塞范围，在等待超时后协调者或参与者会中断事务。避免了协调者单点问题，阶段3中协调者出现问题时，参与者会继续提交事务。 　　缺陷：脑裂问题依然存在，即在参与者收到PreCommit请求后等待最终指令，如果此时协调者无法与参与者正常通信，会导致参与者继续提交事务，造成数据不一致。 后记 　　无论2PC或3PC，均无法彻底解决分布式一致性问题。 　　解决一致性问题，唯有Paxos，后续将单独总结。 "},"docs/分布式/分布式理论.html":{"url":"docs/分布式/分布式理论.html","title":"分布式理论","keywords":"","body":"CAP理论： CAP原则 一致性（Consistency） - 对某个指定的客户端来说，读操作保证能够返回最新的写操作结果。 可用性（Availability） - 非故障的节点在合理的时间内返回合理的响应（不是错误和超时的响应）。 分区容错性（Partition Tolerance） - 当出现网络分区后，系统能够继续履行职责。 CAP关注的粒度是数据，而不是整个系统 ACID 是数据库事务完整性的理论，CAP 是分布式系统设计理论，BASE 是 CAP 理论中 AP 方案的延伸。 网络分区： 网络分区指由于网络设备的failure，造成网络分裂为多个独立的组 网络分区的原因即有Network failure又有Node failure 二阶段提交： 2PC顾名思义分为两个阶段，其实施思路可概括为： （1）投票阶段（voting phase）：参与者将操作结果通知协调者； （2）提交阶段（commit phase）：收到参与者的通知后，协调者再向参与者发出通知，根据反馈情况决定各参与者是否要提交还是回滚； eg： 五、举例 甲乙丙丁四人要组织一个会议，需要确定会议时间，不妨设甲是协调者，乙丙丁是参与者。 投票阶段： （1）甲发邮件给乙丙丁，周二十点开会是否有时间； （2）甲回复有时间； （3）乙回复有时间； （4）丙迟迟不回复，此时对于这个活动，甲乙丙均处于阻塞状态，算法无法继续进行； （5）丙回复有时间（或者没有时间）； 提交阶段： （1）协调者甲将收集到的结果反馈给乙丙丁（什么时候反馈，以及反馈结果如何，在此例中取决与丙的时间与决定）； （2）乙收到； （3）丙收到； （4）丁收到； 六、结论 2PC效率很低，分布式事务很难做。 "},"docs/分布式/架构设计.html":{"url":"docs/分布式/架构设计.html","title":"架构设计","keywords":"","body":"一、有状态，无状态 「有状态」和「无状态」 N.Wirth曾经在它1984年出版的书中将程序的定义经典的概括为：程序=数据结构+算法。（这个概括也是这本书的书名） 程序做的事情本质就是“数据的移动和组合”，以此来达到我们所期望的结果。而如何移动、如何组合是由“算法”来定的。 通过程序处理所得到的“成果”其实和你平时生活中完成的任何事情所得到的“成果”是一样的。任何一个“成果”都是你通过一系列的“行动”将最开始的“原料”进行加工、转化，最终得到你所期望的“成果”。 比如，你将常温的水，通过“倒入水壶”、“通电加热”等工作后变成了100度的水，就是这样一个过程。 正如烧水的例子，大多数时候得到一个“成果”往往需要好几道“行动”才能完成。 这个时候如果想降低这几道“行动”总的成本（如：时间）该怎么办呢？ 自然就是提炼出反复要做的事情，让其只做一次。而这个事情在程序中，就是将一部分“数据”放到一个「暂存区」（一般就是本地内存），以提供给相关的“行动”共用。 image 但是如此一来，就导致了需要增加一道关系，以表示每一个“行动”与哪一个「暂存区」关联。因为在程序里，“行动”可能是「多线程」的。 这时，这个“行动”就变成「有状态」的了。 题外话：共用同一个「暂存区」的多个“行动”所处的环境经常被称作「上下文」。 我们再来深入聊聊「有状态」。 「暂存区」里存的是「数据」，所以可以理解为“有数据”就等价于“有状态”。 「数据」在程序中的作用范围分为「局部」和「全局」（对应局部变量和全局变量），因此「状态」其实也可以分为两种，一种是局部的「会话状态」，一种是全局的「资源状态」。 题外话：因为有些服务端不单单负责运算，还会提供其自身范围内的「数据」出去，这些「数据」属于服务端完整的一部分，被称作「资源」。所以，理论上「资源」可以被每个「会话」来使用，因此是全局的状态。 与「有状态」相反的是「无状态」，「无状态」意味着每次“加工”的所需的“原料”全部由外界提供，服务端内部不做任何的「暂存区」。并且请求可以提交到服务端的任意副本节点上，处理结果都是完全一样的。 有一类方法天生是「无状态」，就是负责表达移动和组合的“算法”。因为它的本质就是： 接收“原料”（入参） “加工”并返回“成果”（出参） 为什么网上主流的观点都在说要将方法多做成「无状态」的呢？ 因为我们更习惯于编写「有状态」的代码，但是「有状态」不利于系统的易伸缩性和可维护性。 在分布式系统中，「有状态」意味着一个用户的请求必须被提交到保存有其相关状态信息的服务器上，否则这些请求可能无法被理解，导致服务器端无法对用户请求进行自由调度（例如双11的时候临时加再多的机器都没用）。 同时也导致了容错性不好，倘若保有用户信息的服务器宕机，那么该用户最近的所有交互操作将无法被透明地移送至备用服务器上，除非该服务器时刻与主服务器同步全部用户的状态信息。 但是如果想获得更好的伸缩性，就需要尽量将「有状态」的处理机制改造成「无状态」的处理机制。 「无状态」化处理 将「有状态」的处理过程改造成「无状态」的，思路比较简单，内容不多。 首先，状态信息前置，丰富入参，将处理需要的数据尽可能都通过上游的客户端放到入参中传过来。 当然，这个方案的弊端也很明显：网络数据包的大小会更大一些。 另外，客户端与服务端的交互中如果涉及到多次交互，则需要来回传递后续服务端处理中所需的数据，以避免需要在服务端暂存。 ▲橙色请求，绿色响应 这些改造的目的都是为了尽量少出现类似下面的代码。 func(){ return i++; } 而是变成： func(i){ return i+1; } 要更好的做好这个「无状态」化的工作，依赖于你在架构设计或者项目设计中的合理分层。 尽量将会话状态相关的处理上浮到最前面的层，因为只有最前面的层才与系统使用者接触，如此一来，其它的下层就可以将「无状态」作为一个普遍性的标准去做。 与此同时，由于会话状态集中在最前面的层，所以哪怕真的状态丢失了，重建状态的成本相对也小很多。 比如三层架构的话，保证BLL和DAL都不要有状态，代码的可维护性大大提高。 如果是分布式系统的话，保证那些被服务化的程序都不要有状态。除了能提高可维护性，也大大有利于做灰度发布、A/B测试。 IO密集型程序和CPU密集型程 题外话：在这里，提到做分层的目的是为了说明，只有将IO密集型程序和CPU密集型程序分离，才是通往「无状态」真正的出路。一旦分离后，CPU密集型的程序自然就是「无状态」了。 如此也能更好的做「弹性扩容」。因为常见的需要「弹性扩容」的场景一般指的就是CPU负荷过大的时候。 最后，如果前面的都不合适，可以将共享存储作为降级预案来运用，如远程缓存、数据库等。然后当状态丢失的时候可以从这些共享存储中恢复。 所以，最理想的状态存放点。要么在最前端，要么在最底层的存储层。 任何事物都是有两面性的，正如前面提到的，我们并不是要所有的业务处理都改造成「无状态」，而只是挑其中的一部分。最终还是看“价值”，看“性价比”。 比如，将一个以“状态”为核心的即时聊天工具的所有处理过程都改造成「无状态」的，就有点得不偿失了。 CAP理论 CAP理论的意思是说，一个分布式系统无法同时满足三个条件 ： 一致性、可用性、分区容忍性。 CAP分别代表： C:consistency,数据在多个副本中能保持一致的状态。 A:Availability，整个系统在任何时刻都能提供可用的服务 P：Partition tolerance，分区容错性，在出现分区的情况下依然能提供服务。 CAP 猜想就是说在C，A，P之间最多只能存在两个。 Lynch在2002年发表论文证明了这个猜想，将它上升到定理的层面。 一致性，数据要保证一致，保证准确性 可用性，我们的服务要保证24小时可用 分区容忍性，访问量太大了，要扩容，体现为系统的可伸缩性了，部署多个实例或副本 但是呢，扩容了，保证了可用性，数据一致性怎么保证？ 副本这么多，同步机制太难做好了。 互联网公司一般会选择保证AP，保证高可用，但是一致性呢，该怎么办？CAP理论并不完全适用于指导实际的工程开发，所以对于一致性，一般会这样去考虑： 强一致性，必须保证一致性，任意时刻都能读到最新值。 弱一致性，写入新值后，在副本上可能读出来，也可能读不出来。 最终一致性，在某个时间后，能够读到最新的值。 有个经典有趣的问题：拜占庭将军问题。 拜占庭将军问题 (Byzantine Generals Problem)，其故事背景是这样的：拜占庭位于现在土耳其的伊斯坦布尔，是东罗马帝国的首都。由于当时拜占庭罗马帝国国土辽阔，为了防御目的，因此每个军队都分隔很远，将军与将军之间只能靠信差传消息。 在战争的时候，拜占庭军队内所有将军必需达成一致的共识，决定是否有赢的机会才去攻打敌人的阵营。但是，军队可能有叛徒和敌军间谍，这些叛徒将军们会扰乱或左右决策的过程。这时候，在已知有成员谋反的情况下，其余忠诚的将军在不受叛徒的影响下如何达成一致的协议，这就是拜占庭将军问题。 从单机服务到集群化 构建单机服务非常简单，但如果单机服务可靠性或性能不足，就需要多机器共同承担某项服务。集群化包含以下三种情况： 无状态主备集群 仅有一台主机完成任务，且没有本地状态，其余从机机器待命，一旦主机宕机，从机选主成为主机。 有状态主备集群 仅有一台主机完成任务，有本地状态，其余从机机器待命，一旦主机宕机，从机选主成为主机。 无状态的主从集群 所有机器没有本地状态，理论上机器可以无限叠加，共同向外界提供同一服务。解决方案就是dubbo+zookeeper。 4.有状态的主从集群 所有机器都有本地状态，共同向外界提供同一服务。一旦某台机器宕机，需要主机协调其他从机代理其本地状态的任务。Paxos、raft和ZAB等一众分布式一致性算法的终极目标就是解决该问题。 "},"docs/分布式/消息代理对比.html":{"url":"docs/分布式/消息代理对比.html","title":"消息代理对比","keywords":"","body":" 综上所述，各种对比之后，建议： 一般的业务系统要引入MQ，最早大家都用ActiveMQ，但是现在确实大家用的不多了，没经过大规模吞吐量场景的验证，社区也不是很活跃，所以大家还是算了吧，我个人不推荐用这个了； 后来大家开始用RabbitMQ，但是确实erlang语言阻止了大量的java工程师去深入研究和掌控他，对公司而言，几乎处于不可控的状态，但是确实人是开源的，比较稳定的支持，活跃度也高； 不过现在确实越来越多的公司，会去用RocketMQ，确实很不错，但是我提醒一下自己想好社区万一突然黄掉的风险，对自己公司技术实力有绝对自信的，我推荐用RocketMQ，否则回去老老实实用RabbitMQ吧，对应的活跃开源社区，一般不会黄； "},"docs/参考产品/运维监控软件wgcloud.html":{"url":"docs/参考产品/运维监控软件wgcloud.html","title":"运维监控软件Wgcloud","keywords":"","body":"演示地址： http://39.106.55.224/wgcloud/login/toLogin github： https://github.com/tianshiyeben/wgcloud 官网： https://www.wgstart.com/ agent实现方式 java go 通过：sigar 接口监控 wgcloud-agent 负责收集服务器内存， cpu， 进程状态， 系统和磁盘指标。 如果 不需要监控此类指标 "},"docs/开发工具/chrome常用插件.html":{"url":"docs/开发工具/chrome常用插件.html","title":"Chrome常用插件","keywords":"","body":"Infinity：标签美观 AdBlock：广告拦截 OneTab ：将无数Tab合并在一个页面 "},"docs/开发工具/sublime破解.html":{"url":"docs/开发工具/sublime破解.html","title":"Sublime破解","keywords":"","body":"sublime破解 步骤 下载sublimeText3的安装包并安装（已经安装的可以忽略） 安装包安装 host文件：127.0.0.1 license.sublimehq.com （hosts文件地址:C:\\Windows\\System32\\drivers\\etc） 破解文件复制到sublime安装目录 管理员运行破解文件，复制注册码 打开sublime -> help -> enterlicense 输入注册码 恭喜你完成破解 sublimeText3安装包和破解文件，下载地址 链接：https://pan.baidu.com/s/1XslTm_cBav8sTncFuS4CzA 提取码：ayth 关闭更新步骤： 在sublime text3中，选择Preferences -> Settings 在代码中中添加:\"update_check\":false 这样就实现了自动更新的关闭 "},"docs/开发工具/好工具.html":{"url":"docs/开发工具/好工具.html","title":"好工具","keywords":"","body":"好用工具 aliyun java initializr 阿里springboot初始化 magicalcoder 代码生成器 Cloud Toolkit Cloud Toolkit提供轻量级devops的idea plugin（Alibaba Cloud Toolkit），可以让你快速部署远程服务期（支持ssh、docker）、可以配置跳板机，让你在idea在本地一键部署、同时可以通过shell来管理远程主机。 在线框架搭建 懒猴子：http://cg.lazy-monkey.com/ 前端代码生成神器-ibootstrap http://www.ibootstrap.cn/ 文图 https://www.wentu.io/ 文图可以根据excel里的数据，自动生成对应的统计图形，样式可以自由切换，生成PDF、JPG等格式。 在线比对 www.diffchecker.com/ 前后端教程 https://roadmap.sh/watch 工具： https://balsamiq.com/wireframes/desktop/ 学习路线中文版 https://github.com/kamranahmedse/developer-roadmap/tree/master/translations/chinese 面试题 https://snailclimb.gitee.io/javaguide-interview/ "},"docs/开发工具/客户端http连接工具.html":{"url":"docs/开发工具/客户端http连接工具.html","title":"客户端Http连接工具","keywords":"","body":"https://www.jianshu.com/p/afc96b7de90c HttpClient、OkHttp、RestTemplate、WebClient的基本使用 "},"docs/开发工具/数据库管理工具/navicat破解.html":{"url":"docs/开发工具/数据库管理工具/navicat破解.html","title":"Navicat破解","keywords":"","body":"参考：https://www.jb51.net/article/199496.htm 网盘下载地址： 链接: https://pan.baidu.com/s/11PH7oGOaegG00e8x-bx_aQ 提取码: 3y6d 第一步：先安装程序 第二步：开始激活（激活时必须断网） （激活时必须断网） （激活时必须断网） （激活时必须断网） 使用注册机，先退出所有杀毒软件，再打开注册机，否则会一直报错的 在激活工具的第一个选项(1.Patch)里选择Backup，Host，Navicat 是那个版本就选那个版本，这里就选择Navicat V 15 就好了，然后点击，Patch按钮，选择Navicat的安装位置中的navicat.exe文件 如图： 出现以下提示说明Patch成功了。 License. Product and Language License里选中Enterprise、在Produce里选择Premium、在Languages里选择Simplified Chinese(简体中文) Resale License 选择Site License Keygen / Offline Activation 点击Generate按钮就会生成一个许可证秘钥，将许可证秘钥复制后就打开Navicat Premium 15 打开Navicat Premium 15，点击注册 粘贴秘钥，然后点击激活按钮 在弹出的界面选择手动激活 将请求码粘贴到注册机Request Code框中（完整过程看图） 点击激活页面的激活弹出（说明激活成功） 恭喜，激活成功啦！！如果经济允许，还是希望可以支持正版！！ "},"docs/开发工具/画图工具.html":{"url":"docs/开发工具/画图工具.html","title":"画图工具","keywords":"","body":"画图工具 processon 官网 账号 draw.io 官网 xmind 网盘工具中有破解版 链接: https://pan.baidu.com/s/19rAR1DAo98uB3R4foR2EbA 提取码: x97n 安装后，替换里面的文件 帮助-->序列号-输入序列号 邮箱随便，序列号下边 XAka34A2rVRYJ4XBIU35UZMUEEF64CMMIYZCK2FZZUQNODEKUHGJLFMSLIQMQUCUBXRENLK6NZL37JXP4PZXQFILMQ2RG5R7G4QNDO3PSOEUBOCDRYSSXZGRARV6MGA33TN2AMUBHEL4FXMWYTTJDEINJXUAV4BAYKBDCZQWVF3LWYXSDCXY546U3NBGOI3ZPAP2SO3CSQFNB7VVIY123456789012345 关闭自动更新 编辑--首选项--常规--启动时检查更新好消息关闭 另外也可以参考： https://www.jianshu.com/p/a22c78866ce3 百度脑图 https://naotu.baidu.com/ "},"docs/开发工具/网址生成exe文件.html":{"url":"docs/开发工具/网址生成exe文件.html","title":"网址生成Exe文件","keywords":"","body":"网址生成exe文件流程 第一步：安装nativefier (基于electron) 1、安装node 2、安装 nativefile npm install nativefier -g --registry=https://registry.npm.taobao.org 3、生成exe文件 nativefier --name \"YouForever\" \"http://www.baidu.cn\" 或 nativefier -n \"yunpan\" -p \"windows\" -a \"ia32\" -i \"e:\\\\yunpan\\favicon.ico\" \"http://10.1.5.98\" --file-download-options \"{\\\"saveAs\\\": true}\" nativefier -n \"yunpan\" -p \"windows\" -a \"x64\" -i \"e:\\\\yunpan\\favicon.ico\" \"http://10.1.5.98\" --file-download-options \"{\\\"saveAs\\\": true}\" 注解：第一次时间有点长，耐心等待 --file-download-options \"{\\\"saveAs\\\": true}\" 是保存文件的 说明：1、路径默认放在 cd路径下 2、nativefier参数配置：https://github.com/nativefier/nativefier/blob/HEAD/docs/api.md 3、logo必须用.ico格式 转换工具：http://www.ico8.net/ 第二步：exe生成 exe可安装文件 工具：Inno Setup Compiler 默认安装没有中文 url：http://www.jrsoftware.org/isdl.php 中文语言包：https://gitee.com/jiuyong/Lunar-Markdown-Editor/blob/master/ChineseSimplified.isl 放到安装路径语言包中 或：https://jrsoftware.org/files/istrans/ 1、使用操作流程： file 选择所需的exe程序，注意添加全部的依赖文件 然后直接finish，这就会在桌面（你选择的生成位置）生成安装的XXsetup.exe 备注： 其中--platform是配置打包成什么平台的安装文件，下面是可选的值 win系统： win或者win32，即--platform=win或者--platform=win32 mac系统：mac或者darwin，即--platform=mac或者--platform=darwin Linux系统：linux， 即--platform=linux 所有平台：all， 即--platform=all 其中--arch是指定系统是什么架构的，常见的例如32位和64位操作系统，这个参数的可选值有 ia32， 即--arch=ia32， 32位操作系统，也可以在64位操作系统中安装 x64， 即--arch=x64， 64位操作系统，使用本架构打包无法再32位操作系统中安装 armv7l， 即--arch=armv7l， 使用比较少 arm64， 即--arch=arm64， 使用比较少 参数--platform和--arch已经被标志为过期，新的写法如下 "},"docs/开发工具/远程连接工具.html":{"url":"docs/开发工具/远程连接工具.html","title":"远程连接工具","keywords":"","body":"ZeroTier 工具 官网 文档： https://zerotier.atlassian.net/wiki/spaces/SD/pages/8454145/Getting+Started+with+ZeroTier 参考： https://www.cnblogs.com/chenjx85/p/12270229.html "},"docs/扬州project/docker二阶段部署.html":{"url":"docs/扬州project/docker二阶段部署.html","title":"Docker二阶段部署","keywords":"","body":"多阶段构建 "},"docs/扬州project/jar整合流程.html":{"url":"docs/扬州project/jar整合流程.html","title":"Jar整合流程","keywords":"","body":"前端打包 npm run build /dist 生成包 #整体复制到 idc-services/ resource/static/static 修改对应的后端地址 maven 打包 上传 192.168.210.80 /usr/local/bin 运行 $nohup java -jar idc-services-1.0.0.jar > log.file 2>&1 & 地址 http://192.168.210.80:8081/idc-services/static/index.html#/login "},"docs/扬州project/nginx配置.html":{"url":"docs/扬州project/nginx配置.html","title":"Nginx配置","keywords":"","body":" #user nobody; worker_processes 1; #error_log logs/error.log; #error_log logs/error.log notice; #error_log logs/error.log info; #pid logs/nginx.pid; events { worker_connections 1024; } http { include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; server { listen 8087; server_name localhost; location / { root D:/GreenSoft/nginx-1.19.10/vue-project; #站点根目录，即网页文件存放的根目录, 默认主页目录在nginx安装目录的html子目录。 index index.html index.htm; #目录内的默认打开文件,如果没有匹配到index.html,则搜索index.htm,依次类推 } location /api { rewrite ^/api/(.*)$ /$1 break; proxy_pass http://127.0.0.1:8080/idc-services; #node api server 即需要代理的IP地址 add_header Access-Control-Allow-Origin *; add_header Access-Control-Allow-Credentials true; } error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } } } "},"docs/扬州project/vue开发笔记.html":{"url":"docs/扬州project/vue开发笔记.html","title":"Vue开发笔记","keywords":"","body":"table-的expend 手风琴效果 https://blog.csdn.net/sinat_33312523/article/details/78928236 父子组件传值 #父组件 export default { name: 'index', components: { 'children-components': childrenComponents }, data(){ dcamera_option: { input_value: 6 } } } #子组件 export default { name: 'ChildrenComponents', props: { options: { type: Object, required: true }, } } vue中created、mounted、activated的区别 created：在模板渲染成html之前调用，即通常初始化某些属性值，然后再渲染成视图；但是注意，只会触发一次 mounted：在渲染成html之后调用，通常是初始化页面完成后，再对html的dom节点进行一些需要的操作。是挂载vue实例后的钩子函数，钩子在主页挂载时执行一次，如果没有缓存的话，再次回到主页时，此函数还会执行。 activated：是组件被激活后的钩子函数，每次回到页面都会执行 执行顺序：created => mounted => activated this.$message.error(data.msg) echart和v-chart相关 官方文档：https://v-charts.js.org/#/ 百度：https://echarts.apache.org/zh/option.html#title npm i v-charts echarts -S 报错： --save echarts/lib/visual/dataColor 解决： npm i v-charts echarts@4.9.0 -S 如不行用下面 npm install v-echarts echarts --save Vue项目中，Cannot find module 'node-sass' 报错找不到解决 cnpm install node-sass@latest -S 问题： vue2引入v-charts为什么需要f12才会显示 解决：组件加入宽度和高度 父子加载顺序 https://blog.csdn.net/weixin_43878906/article/details/108274025 折线图例子： https://www.oschina.net/p/v-charts https://www.cnblogs.com/cina33blogs/p/10750169.html 参考例子 vchart ：https://blog.csdn.net/weixin_44824839/article/details/103140933 拓展参考： https://echarts.apache.org/zh/option.html#title y轴固定内容滚动 https://blog.csdn.net/qq_42714690/article/details/103655087 时区转换 https://blog.csdn.net/sinat_32849897/article/details/110848673 vue中的数据格式化filters、formatter https://blog.csdn.net/messicr7/article/details/105435314/?utm_medium=distribute.pc_relevant.none-task-blog-baidujs_baidulandingword-1&spm=1001.2101.3001.4242 {{ message | filterA | filterB }} 这个 写法的功能是，把message 传递给filterA 返回值传递给filterB最后返回显示结果到页面上，可以看出是按函数的先后顺序调用下去最后返回结果显示。 {{ mobile | formatmobile}} 跨域解决： https://blog.csdn.net/lindali1115/article/details/108096631 json 格式的问题 js保留两位小数 https://www.jb51.net/article/134067.htm 页面不跳转：，vue-springboot整包部署 在controller层应该用@Controller注解，不能用@ResController注解，如果使用@ResController注解，此注解是将json转换成字符串,那么就无法转到html页面，只会返回字符串 或者用 @RestController @RequestMapping(\"rmsLogin\") 多加个RequestMapping 整包部署： dist包放在了 /static/static/目录下 shiro配置中加入 filterMap.put(\"/static/**\", \"anon\"); 访问地址 http://localhost:8080/idc-services/static/index.html application.properties 中加入 spring.web.resource.static-locations=classpath:/ spring.mvc.view.suffix=.html SysLoginController添加 @RequestMapping(\"\") 启动命令 $nohup java -jar idc-services-1.0.0.jar > log.file 2>&1 & vue自定义全局方法 https://www.cnblogs.com/conglvse/p/10062449.html 全局过滤器 https://blog.csdn.net/weixin_33749131/article/details/93396673 js保留两位小数 https://www.jb51.net/article/134067.htm docker启动错误 ERROR: for prometheus Cannot restart container 950af762c9501a7ee07db430d92da45a8a515980bace5a04192496f6173b1369: driver failed programming external connectivity on endpoint prometheus (ffec7c8009254b20c7605546ed2b03be313596b2f9fd81108bf1b3e3d40951e0): (iptables failed: iptables --wait -t nat -A DOCKER -p tcp -d 0/0 --dport 9090 -j DNAT --to-destination 172.17.0.8:9090 ! -i br-e69a795d182b: iptables: No chain/target/match by that name. 解决：https://blog.csdn.net/u013948858/article/details/83115388 https://blog.51cto.com/17099933344/1929664 极端解决： systemctl stop firewalld systemctl stop iptables 泛型接口实例化 https://blog.csdn.net/weixin_34075551/article/details/86132595 https://blog.csdn.net/aiyaya_/article/details/79212852 仪表盘 https://www.cnblogs.com/pqblog/p/8478865.html 　https://antv.alipay.com/ 图标工具 https://www.bilibili.com/read/cv6183470/ Gauge和Bar Gauge使用 http://echarts.baidu.com/ 教程：http://www.cnblogs.com/jerehedu/p/4538459.html prometheus 函数https://www.cnblogs.com/wayne-liu/p/9273492.html "},"docs/扬州project/前端打包.html":{"url":"docs/扬州project/前端打包.html","title":"前端打包","keywords":"","body":"构建生成的资源文件保存在/dist目录下，可通过config/index.js目录文件修改相关配置信息 #打包 npm run build "},"docs/数据库/arangodb/windows安装.html":{"url":"docs/数据库/arangodb/windows安装.html","title":"Windows安装","keywords":"","body":"https://www.pianshen.com/article/1441964765/ 下载 a. 进入Arangodb官网:https://www.arangodb.com/ 选择社区版本 下载zip版本 安装教程 https://www.arangodb.com/docs/stable/installation-windows.html 在D:\\GreenSoft\\ArangoDB3-3.7.10\\usr\\bin 目录下运行 $arangod --install-service 成功 接着，在bin目录下点击arangod.exe,出现如下havefun！，说明服务开启。 http://127.0.0.1:8529/ 默认用户root 密码空 修改密码 左侧 user中 123456 导出: #!/bin/sh arangodump --server.endpoint tcp://192.168.1.171:8902 --server.username root --server.password vangoo123 --server.database vangoo --output-directory /home/ago/dump-$(date \"+%Y%m%d-%H:%M:%S\") find /home/ago/ -mtime +7 -name \"dump-*\" -exec rm -rf {} \\; > /dev/null​ 导入： 在D:\\GreenSoft\\ArangoDB3-3.7.10\\usr\\bin 执行 arangorestore --server.endpoint tcp://localhost:8529 --server.username root --server.password 123456 --server.database vangoo --input-directory E:\\dump --overwrite true "},"docs/数据库/influxdb/telegraf.html":{"url":"docs/数据库/influxdb/telegraf.html","title":"Telegraf","keywords":"","body":"https://github.com/influxdata/telegraf 配置文件修改 注释去掉,不然报错 # ip_range = [] ip_range = [] (前面的空格去掉) "},"docs/数据库/influxdb/数据类型.html":{"url":"docs/数据库/influxdb/数据类型.html","title":"数据类型","keywords":"","body":"series/point/tag/field tag tag key/value: 字符串类型 有索引 tag进行查询效率比单纯的基于field进行查询是要高 #查询语法 show tag keys on from eg: show tag values from currency_rate with key=\"base\" with key 后面带上查询条件，必须存在，如查询汇率表中，base_symbol有哪些 连接符号可以为：等于 =, 不等于：!=, <>, 正则：=~, !~ field 类型可以为：浮点，字符串，整形 没有索引 show field keys on from show field keys from yhh point https://docs.influxdata.com/influxdb/v1.7/concepts/glossary/#point 在influxdb中，你可以将一条mysql中的记录简单的理解为一个point，它由四个组件 measurement tag set field set timestamp 每个point是根据 timestamp + series 来保证唯一性 series show series on from 就是tag 的 列表值 ，就是tag的select * 可以过滤： show series from yhh where \"name\" = '一灰灰' 是查询全部 包括 tag和field SELECT * FROM \"cpu\" WHERE time > now() - 5m "},"docs/架构设计/API接口设计.html":{"url":"docs/架构设计/API接口设计.html","title":"API接口设计","keywords":"","body":"接口设计 json格式 { #返回状态码 code:integer, #返回信息描述 message:string, #返回值 data:object } code状态码 分类 区间 1** #1000～1999 区间表示参数错误 2** #2000～2999 区间表示用户错误 3** #3000～3999 区间表示接口异常 "},"docs/监控/SSH监控/java监控ssh.html":{"url":"docs/监控/SSH监控/java监控ssh.html","title":"Java监控Ssh","keywords":"","body":"https://gitee.com/shadowedge/ssh-batch?_from=gitee_search 纯java实现的ssh协议(jsch) "},"docs/监控/SSH监控/监控shell脚本linux.html":{"url":"docs/监控/SSH监控/监控shell脚本linux.html","title":"监控Shell脚本Linux","keywords":"","body":"代码: https://github.com/atarallo/TECMINT_MONITOR 参考文章: https://linux.cn/article-5604-1.html?share_token=980a6610-1123-4977-a866-1a61816ed02d 运行: /usr/local/bin 安装： chmod 755 tecmint_monitor.sh ./tecmint_monitor.sh -i 任何地方执行 $ monitor "},"docs/监控/SSH监控/相关工具.html":{"url":"docs/监控/SSH监控/相关工具.html","title":"相关工具","keywords":"","body":"rtop：https://github.com/rapidloop/rtop "},"docs/运维监控/运维产品.html":{"url":"docs/运维监控/运维产品.html","title":"运维产品","keywords":"","body":"http://docs.bigops.com/ "},"docs/重装系统流程.html":{"url":"docs/重装系统流程.html","title":"重装系统流程","keywords":"","body":"重装系统流程 第一步 老毛桃 pe安装，先分区 MBR和GPT 选GPT分区 第二步 KMSpico 激活系统 第三步 安装 typora 可以在搜索框找到 创建快捷键放到 C:\\Users\\Administrator\\AppData\\Roaming\\Microsoft\\Windows\\Start Menu\\Programs 工具篇 idea 插件：jrebel，lombok， 测试流程 "}}